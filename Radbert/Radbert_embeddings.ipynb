{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RadBert Embeddings #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/users/pranav.rao/miniconda3/envs/TutorialCuda/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from itertools import product\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "torch.set_printoptions(linewidth=200)\n",
    "\n",
    "import transformers\n",
    "from transformers import AutoTokenizer, AutoModel, AutoModelForMaskedLM, AutoModelForCausalLM\n",
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model and Tokenizer ##\n",
    "Using model and weights from https://huggingface.co/StanfordAIMI/RadBERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at zzxslp/RadBERT-RoBERTa-4m and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "#checkpoint1 = \"UCSD-VA-health/RadBERT-RoBERTa-4m\"\n",
    "checkpoint1 = \"zzxslp/RadBERT-RoBERTa-4m\"\n",
    "tokenizer1 = AutoTokenizer.from_pretrained(checkpoint1)\n",
    "full_model1 = AutoModelForMaskedLM.from_pretrained(checkpoint1)\n",
    "base_model1 = AutoModel.from_pretrained(checkpoint1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentences ##\n",
    "Checking the embeddings obtained from reports.\n",
    "Consider the 9 Sentences:\n",
    " 1. \"The report shows small right-sided pleural effusion\"\n",
    " 2. \"The report shows small left-sided pleural effusion\"\n",
    " 3. \"The report shows large right-sided pleural effusion\"\n",
    " 4. \"The report shows large left-sided pleural effusion\"\n",
    " 5. \"There are no abnormalities in the report\"\n",
    " 6. \"There is severe consolidation in the left side\"\n",
    " 7. \"There is severe consolidation in the right side\"\n",
    " 8. \"There is mild consolidation in the right side\"\n",
    " 9. \"There is mild consolidation in the left side\"\n",
    " \n",
    "Checking the cosine similarities Matrix between the embeddings of above 9 sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_list = [\"The report shows small right-sided pleural effusion\", \"The report shows small left-sided pleural effusion\",\\\n",
    "    \"The report shows large right-sided pleural effusion\", \"The report shows large left-sided pleural effusion\",\\\n",
    "    \"There are no abnormalities in the report\",\\\n",
    "    \"There is severe consolidation in the left side\",\"There is severe consolidation in the right side\",\\\n",
    "    \"There is mild consolidation in the right side\", \"There is mild consolidation in the left side\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sanity checks ##\n",
    "Testing the RadBert model on masked language modelling, to test if weights are loaded correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there is diffuse consolidation in the right lung, indicative of <mask>\n",
      "{'input_ids': tensor([[    0,  8585,    16, 41118, 13581,    11,     5,   235, 10665,     6, 22206,     9, 50264,     2]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n",
      "MaskedLMOutput(loss=None, logits=tensor([[[ 0.5278, -3.7901, -0.3916,  ..., -5.2278, -4.5390, -3.9142],\n",
      "         [ 0.4206, -2.5342,  0.7946,  ..., -2.0640, -0.8946, -2.7140],\n",
      "         [ 0.4204, -3.2287,  0.0934,  ..., -0.0249, -1.7986, -2.1001],\n",
      "         ...,\n",
      "         [-0.1570, -4.3633, -0.6012,  ..., -3.5548, -3.3828,  0.3929],\n",
      "         [ 2.9478, -3.4692,  5.5250,  ..., -4.2230, -5.3847,  1.3726],\n",
      "         [ 0.4920, -3.7886, -0.3946,  ..., -5.2342, -4.5446, -3.9283]]]), hidden_states=(tensor([[[ 0.1158, -0.0210, -0.0104,  ..., -0.0483,  0.0827,  0.0521],\n",
      "         [-0.4306, -0.0558,  0.1098,  ..., -0.1587, -0.4074,  0.0425],\n",
      "         [ 0.0046,  0.2573,  0.0362,  ...,  0.0495, -0.2659, -0.1285],\n",
      "         ...,\n",
      "         [-0.2312,  0.0555,  0.2483,  ...,  0.3986, -0.2374,  0.0566],\n",
      "         [ 0.2261,  0.0857,  0.0040,  ...,  0.1546,  0.0412, -0.0404],\n",
      "         [ 0.0558, -0.0134, -0.0724,  ...,  0.5332,  0.0852, -0.1484]]]), tensor([[[-0.0218,  0.0695,  0.0231,  ..., -0.0269, -0.0057, -0.0818],\n",
      "         [-0.3924, -0.4355,  0.2002,  ...,  0.3924, -0.4305,  0.3145],\n",
      "         [ 0.2973,  0.3577,  0.1379,  ..., -0.4846, -0.5413,  0.1360],\n",
      "         ...,\n",
      "         [-0.5379,  0.0612,  0.2827,  ...,  0.6514, -0.2578, -0.0061],\n",
      "         [ 0.1076, -0.0645,  0.1764,  ...,  0.3574, -0.4102, -0.3680],\n",
      "         [-0.1843,  0.2735,  0.1209,  ...,  0.8322,  0.1417, -0.4186]]]), tensor([[[ 4.2579e-02,  3.1432e-02,  7.9266e-03,  ...,  1.6278e-02,  2.9532e-04, -3.8240e-02],\n",
      "         [-2.1595e-01, -3.3796e-01,  6.7505e-02,  ...,  3.5598e-01, -8.7171e-02,  6.4941e-01],\n",
      "         [-2.7493e-01,  6.4224e-01,  9.0504e-02,  ..., -6.4757e-01,  8.2689e-02,  8.2795e-02],\n",
      "         ...,\n",
      "         [-3.3573e-01,  2.4251e-01,  3.2705e-01,  ...,  6.3524e-01, -1.2517e-01, -1.5854e-01],\n",
      "         [-5.3536e-01,  4.0272e-01, -2.2110e-01,  ..., -1.6521e-01, -9.4228e-01, -2.8441e-01],\n",
      "         [-4.3038e-01,  5.8205e-01,  1.6502e-01,  ...,  9.6123e-01,  1.0210e-01, -4.8925e-01]]]), tensor([[[ 0.0565,  0.0121, -0.0297,  ...,  0.0272,  0.0084,  0.0512],\n",
      "         [ 0.1472, -0.3180,  0.5166,  ...,  0.1374, -0.5074,  0.2382],\n",
      "         [-0.2505,  0.4020,  0.2973,  ..., -0.6564, -0.0788,  0.2735],\n",
      "         ...,\n",
      "         [-0.1702,  0.0346,  0.0821,  ...,  0.4252, -0.3321, -0.1844],\n",
      "         [-0.1799,  0.3102,  0.2286,  ..., -0.4141, -0.4304,  0.0332],\n",
      "         [-0.1253,  0.4467,  0.1434,  ...,  0.5160,  0.2090, -0.1407]]]), tensor([[[ 0.0552, -0.0265,  0.0353,  ...,  0.0215, -0.0758, -0.0246],\n",
      "         [ 0.0325, -0.5868,  0.4179,  ...,  0.0228, -0.4010,  0.2328],\n",
      "         [-0.0899,  0.3373,  0.1495,  ..., -0.7370,  0.0839,  0.2206],\n",
      "         ...,\n",
      "         [-0.0098,  0.0076,  0.0603,  ...,  0.1157, -0.0770,  0.0868],\n",
      "         [-0.4365, -0.1513, -0.1006,  ..., -0.0709, -0.1617,  0.1980],\n",
      "         [ 0.1150,  0.0647,  0.0385,  ...,  0.0685,  0.0544, -0.0828]]]), tensor([[[ 0.0378,  0.0015,  0.0215,  ...,  0.0059, -0.0518, -0.0487],\n",
      "         [-0.4551, -0.5958,  0.9621,  ...,  0.0012, -0.2525, -0.6202],\n",
      "         [-0.1998,  0.5110,  0.2616,  ..., -0.8074,  0.0342, -0.2717],\n",
      "         ...,\n",
      "         [ 0.1361, -0.2137, -0.2031,  ...,  0.3923, -0.1486, -0.1138],\n",
      "         [-0.8388, -0.3875, -0.2164,  ..., -0.2039, -0.3631, -0.0287],\n",
      "         [ 0.0060, -0.0020,  0.0430,  ...,  0.0372, -0.0290, -0.0134]]]), tensor([[[ 0.0134,  0.0446,  0.0654,  ...,  0.0060, -0.0675, -0.0307],\n",
      "         [-0.5122, -0.4204,  0.6948,  ..., -0.2578, -0.3472, -0.3779],\n",
      "         [-0.3590,  0.5762, -0.0472,  ..., -0.7445, -0.0435,  0.0103],\n",
      "         ...,\n",
      "         [-0.0793, -0.3013, -0.0501,  ...,  0.3361,  0.3068, -0.0206],\n",
      "         [-0.6638, -0.6119,  0.0178,  ..., -0.3954,  0.4266, -0.0624],\n",
      "         [ 0.0037,  0.0473,  0.0283,  ...,  0.0049, -0.0100, -0.0246]]]), tensor([[[-0.0365,  0.0920,  0.0539,  ...,  0.0553, -0.0320, -0.0101],\n",
      "         [-0.0237, -0.6099,  0.7536,  ..., -0.1323, -0.2277, -0.6421],\n",
      "         [ 0.0640,  0.5283, -0.0550,  ..., -0.7937,  0.0062, -0.0692],\n",
      "         ...,\n",
      "         [ 0.0435, -0.4564, -0.0441,  ...,  0.1757,  0.1455,  0.1776],\n",
      "         [-0.5521, -0.6591,  0.0249,  ..., -0.2202, -0.6218,  0.1709],\n",
      "         [-0.0045,  0.0540,  0.0035,  ...,  0.0164, -0.0055, -0.0054]]]), tensor([[[ 1.8679e-02,  1.0689e-01,  1.4877e-02,  ...,  2.0360e-04, -2.0135e-02, -8.1524e-03],\n",
      "         [-4.6305e-02, -5.2606e-01,  8.0521e-01,  ...,  6.7559e-02, -7.9432e-02, -2.3432e-01],\n",
      "         [ 4.4450e-01,  7.2763e-01,  2.1008e-01,  ..., -8.5907e-01,  6.8090e-02, -1.4022e-01],\n",
      "         ...,\n",
      "         [-5.6521e-02, -7.0568e-01,  2.0837e-02,  ..., -1.3252e-02,  3.6322e-01,  6.3361e-01],\n",
      "         [-2.5515e-01, -9.5288e-01,  2.6821e-01,  ..., -5.0390e-02,  8.8467e-03, -6.1191e-02],\n",
      "         [ 3.4017e-03,  1.3953e-02,  5.9620e-03,  ..., -1.1174e-02, -1.6405e-02,  7.5799e-03]]]), tensor([[[-0.0303,  0.0257,  0.0153,  ..., -0.0304,  0.0189, -0.0443],\n",
      "         [ 0.1684, -0.5049,  0.1966,  ..., -0.1097, -0.2916, -0.0144],\n",
      "         [ 0.1961,  0.5819,  0.0418,  ..., -0.7930,  0.0358, -0.1037],\n",
      "         ...,\n",
      "         [ 0.4882, -0.4584,  0.0262,  ...,  0.2271,  0.0624,  0.1663],\n",
      "         [ 0.5655, -0.9209,  0.4594,  ...,  0.2037,  0.1548,  0.4042],\n",
      "         [-0.0087,  0.0071,  0.0059,  ...,  0.0136,  0.0189, -0.0308]]]), tensor([[[ 0.0061,  0.0256, -0.0168,  ...,  0.0137,  0.0172, -0.0228],\n",
      "         [ 0.6624, -0.6505,  0.2580,  ..., -0.1033, -0.0456, -0.5846],\n",
      "         [-0.0222,  0.6373,  0.0094,  ..., -0.5997, -0.0641,  0.0785],\n",
      "         ...,\n",
      "         [ 0.4867, -0.5942, -0.0818,  ...,  0.1161,  0.1056,  0.1449],\n",
      "         [ 0.3849, -1.0808,  0.4841,  ..., -0.0522, -0.7031,  0.2864],\n",
      "         [ 0.0026,  0.0267, -0.0119,  ...,  0.0152,  0.0187, -0.0144]]]), tensor([[[ 1.5555e-02,  3.0836e-02, -1.7643e-02,  ...,  5.5252e-03, -1.5104e-02,  4.3583e-04],\n",
      "         [ 7.9497e-01, -1.0041e+00, -1.7727e-01,  ...,  8.7520e-02,  4.5326e-02, -3.2727e-01],\n",
      "         [ 9.9108e-02,  6.6493e-01,  1.9181e-01,  ..., -4.5561e-01, -2.6125e-01, -4.1855e-03],\n",
      "         ...,\n",
      "         [ 4.0451e-01, -5.1785e-01, -1.3570e-01,  ..., -6.2594e-03,  3.0886e-01,  7.9285e-02],\n",
      "         [ 4.3908e-01, -5.5374e-01,  2.5925e-01,  ..., -3.0764e-01, -6.3025e-01,  4.4357e-01],\n",
      "         [ 1.4228e-02,  3.0646e-02, -1.6883e-02,  ...,  5.0867e-03, -1.5145e-02,  7.3135e-04]]]), tensor([[[-0.1256,  0.0642, -0.0674,  ..., -0.2878, -0.0828, -0.0428],\n",
      "         [ 0.2194, -0.1838,  0.1381,  ..., -0.0063, -0.1952,  0.0487],\n",
      "         [ 0.0841,  0.3627,  0.2097,  ..., -0.4123, -0.0723, -0.0095],\n",
      "         ...,\n",
      "         [ 0.1294, -0.0459,  0.1020,  ..., -0.1478,  0.1431,  0.0026],\n",
      "         [ 0.2263, -0.1205,  0.0422,  ..., -0.4867, -0.1622,  0.1561],\n",
      "         [-0.1260,  0.0641, -0.0675,  ..., -0.2884, -0.0831, -0.0429]]])), attentions=None)\n",
      "BaseModelOutputWithPoolingAndCrossAttentions(last_hidden_state=tensor([[[-0.1256,  0.0642, -0.0674,  ..., -0.2878, -0.0828, -0.0428],\n",
      "         [ 0.2194, -0.1838,  0.1381,  ..., -0.0063, -0.1952,  0.0487],\n",
      "         [ 0.0841,  0.3627,  0.2097,  ..., -0.4123, -0.0723, -0.0095],\n",
      "         ...,\n",
      "         [ 0.1294, -0.0459,  0.1020,  ..., -0.1478,  0.1431,  0.0026],\n",
      "         [ 0.2263, -0.1205,  0.0422,  ..., -0.4867, -0.1622,  0.1561],\n",
      "         [-0.1260,  0.0641, -0.0675,  ..., -0.2884, -0.0831, -0.0429]]]), pooler_output=tensor([[-4.6088e-02, -1.5783e-01, -8.2374e-03, -7.2609e-02,  5.8824e-02, -1.1566e-01, -1.1566e-01,  1.3144e-01, -1.5785e-01, -3.1952e-01,  2.6574e-01,  5.1535e-01, -1.0708e-01,  1.7523e-01,\n",
      "         -1.7902e-01,  1.8814e-01, -2.2922e-02, -2.1890e-01,  1.4751e-01,  1.9520e-01, -3.5947e-02,  7.6749e-02,  5.2095e-02,  1.5785e-01,  2.4291e-01,  4.6253e-02,  2.4246e-01, -1.5744e-01,\n",
      "          3.2235e-01,  5.2055e-02, -1.4395e-01,  2.1910e-01,  1.1104e-01,  2.7010e-01,  1.7429e-01,  6.9037e-03,  1.4250e-01, -4.0527e-01, -1.2528e-01, -2.0557e-01, -3.5117e-01, -1.2058e-01,\n",
      "         -2.2372e-01,  9.0875e-02, -1.8481e-01, -1.0632e-02, -9.2374e-02, -8.4945e-02, -4.0853e-02, -2.5694e-01,  4.6951e-01, -1.3875e-01, -1.5101e-02, -9.5100e-02,  1.1399e-01,  2.1505e-01,\n",
      "          9.7208e-02, -3.2022e-02,  1.2102e-01, -6.2144e-02, -3.0381e-01,  2.3392e-01, -1.2315e-01, -9.2943e-02, -7.8649e-02,  1.3184e-02, -2.9138e-02,  1.5312e-01, -1.6946e-01,  1.9523e-01,\n",
      "          4.0200e-01, -5.4221e-02, -1.9038e-01,  2.9709e-03,  9.2885e-02, -1.8513e-01,  1.0841e-01, -5.0590e-02, -3.7005e-01,  3.4018e-01, -2.6218e-01,  1.6216e-02,  2.6026e-01, -2.0996e-01,\n",
      "          1.5628e-01, -9.8342e-02, -1.1408e-02,  3.0846e-02, -3.2460e-01,  8.7410e-02, -1.9327e-01, -2.6380e-01, -3.9365e-02,  8.7184e-02,  9.4669e-02,  1.7068e-01, -1.3086e-01,  1.6269e-01,\n",
      "          1.1479e-01, -1.5832e-01, -2.2583e-01, -1.3501e-01, -4.8475e-01, -1.5073e-01,  2.7680e-02,  2.3953e-01, -2.3134e-01, -4.8275e-01, -3.0061e-01, -3.7961e-01,  2.8217e-01,  1.9273e-01,\n",
      "          2.3552e-01,  3.8774e-01,  2.7632e-02,  9.2343e-02,  1.9058e-01, -1.2102e-01,  4.0256e-02,  1.0074e-01,  2.5117e-01,  2.3082e-02, -2.9744e-01, -1.4825e-01, -3.9286e-02,  7.8141e-02,\n",
      "         -1.7510e-01, -8.5625e-02,  2.4334e-01, -1.4337e-01,  9.8444e-03,  1.0834e-01, -2.4499e-01,  5.0505e-02, -1.6882e-01,  3.4958e-01, -1.5431e-01, -6.8769e-02,  1.2661e-01,  7.9059e-02,\n",
      "          2.2347e-01, -1.1552e-02, -7.3008e-02,  2.7846e-01, -3.5289e-01,  9.0213e-02,  1.8341e-01, -3.9943e-02,  1.7017e-01, -4.7286e-02,  1.7932e-01, -4.8452e-02,  2.4672e-01, -2.5419e-02,\n",
      "         -2.5199e-02, -2.6127e-01, -1.4269e-01, -3.0978e-02, -4.1345e-02, -1.7567e-01, -1.7348e-01, -2.9817e-01,  1.5815e-01,  1.7465e-01,  7.4219e-02, -9.7752e-02,  1.2271e-01,  1.3234e-01,\n",
      "         -4.4525e-01, -1.5495e-01, -2.0945e-01,  7.9315e-02, -7.4406e-03,  2.8930e-01,  3.1207e-01,  3.0245e-02, -1.4092e-01,  4.5508e-02, -1.2618e-02,  1.6346e-01, -1.5299e-01,  2.2646e-01,\n",
      "          1.8747e-01, -1.3983e-01, -4.1886e-01, -6.8477e-02, -1.0461e-01, -4.2043e-02, -1.3427e-01,  2.1372e-01, -1.0364e-01,  1.2160e-01,  1.4164e-01, -4.2436e-01, -1.0808e-01, -4.0390e-01,\n",
      "          1.2909e-02,  7.5219e-02,  1.6115e-01,  3.0564e-01, -1.2340e-01, -2.1923e-01, -1.5728e-02,  1.5535e-01,  3.7285e-01, -5.0502e-03, -3.1712e-01, -1.3354e-01, -2.7999e-01, -2.9731e-01,\n",
      "         -1.7649e-01, -2.1599e-01, -2.9444e-01, -4.8983e-02, -3.9395e-02, -8.6864e-02,  3.8414e-01,  2.8822e-02, -1.2243e-03, -1.1643e-01, -1.6474e-01, -9.9999e-02, -5.9026e-01,  1.7078e-02,\n",
      "         -1.2901e-01, -5.0607e-01, -6.1500e-03, -1.5653e-02,  9.7750e-02,  2.4042e-01,  2.2161e-01,  5.4048e-02, -1.2397e-01,  3.1213e-01, -3.4228e-01,  3.8163e-01,  2.2501e-01, -4.7709e-02,\n",
      "          4.3270e-01, -1.3888e-01,  5.3101e-02, -3.0212e-02,  2.0587e-01,  1.3789e-01,  2.4379e-01,  4.9102e-01, -1.2972e-01,  9.4664e-02,  1.0163e-01, -3.5093e-01,  1.9449e-01,  2.8264e-02,\n",
      "         -2.2781e-02, -1.4945e-01, -4.7276e-02, -4.2905e-01, -1.4028e-01,  2.0326e-01, -1.6825e-01,  1.0292e-01,  1.8181e-01,  1.1329e-01, -1.3364e-01,  2.1393e-01,  1.0841e-01,  2.2677e-01,\n",
      "         -2.3299e-01, -1.4246e-01,  9.6019e-02,  3.7466e-01, -1.2398e-01, -4.1147e-03, -3.9152e-02,  4.1011e-02,  2.6237e-01, -2.0180e-01, -1.2613e-01,  8.5614e-02,  4.8856e-02, -4.4529e-01,\n",
      "          9.9226e-02,  3.8760e-02,  1.0165e-01,  3.3157e-01,  3.7720e-01,  3.7572e-01, -5.7910e-02, -1.3113e-02, -1.4213e-02,  1.3364e-01,  3.5825e-01, -1.4576e-01,  4.1317e-01, -1.6115e-01,\n",
      "         -1.8621e-02, -6.6816e-01,  5.6205e-02,  2.0712e-01, -2.4322e-01,  2.1934e-01, -2.1120e-01, -2.2570e-02, -3.7985e-01, -8.4744e-02, -3.6458e-01, -2.3060e-01,  2.0916e-02, -4.0539e-01,\n",
      "          5.0992e-01, -2.7353e-01, -3.0095e-01, -1.8021e-01,  6.7976e-02, -8.1715e-02,  5.2184e-02, -4.2390e-02,  8.8043e-02,  9.3577e-02,  1.2287e-01, -1.0541e-01, -8.4312e-02,  1.5351e-01,\n",
      "         -1.6038e-01,  9.6346e-02, -1.1376e-01,  2.7167e-01, -1.0106e-01,  2.1471e-02,  8.6226e-02,  1.8402e-01,  1.1724e-01,  3.1523e-01,  9.7173e-02, -1.7325e-01, -4.7052e-01,  4.3728e-02,\n",
      "          4.5927e-01, -2.9587e-02,  2.4395e-01, -3.2674e-01, -2.4106e-01, -1.1329e-01, -1.9501e-01, -9.1584e-02,  1.2342e-01, -6.1323e-02,  9.1988e-02, -2.2697e-01, -2.2193e-01, -2.6414e-01,\n",
      "          2.6310e-02, -1.7385e-01, -1.4077e-02, -3.2906e-02, -8.3391e-02, -4.4803e-02,  1.1763e-02, -1.0927e-01, -2.3887e-01, -1.6613e-01, -4.0487e-02,  1.3618e-01, -2.3140e-01, -3.5172e-01,\n",
      "         -1.5212e-01,  7.7663e-02, -2.7113e-01,  1.1974e-01,  3.1699e-01,  1.2518e-01,  1.1273e-01, -1.7275e-02,  2.8627e-01,  7.0196e-02,  1.1680e-01,  2.3439e-01, -6.9115e-02, -9.3465e-02,\n",
      "          3.2737e-01,  2.5893e-01,  1.2255e-01, -1.1298e-01,  9.2095e-02, -2.7819e-01, -1.7233e-01,  8.0975e-02,  3.3476e-01, -3.7390e-02, -2.8687e-01, -1.3473e-01, -5.8798e-03,  3.3592e-01,\n",
      "         -5.6540e-02,  1.9181e-01,  7.4205e-02,  2.3378e-02, -2.3472e-01,  2.2243e-01,  1.7317e-01, -7.2267e-02,  1.9650e-01,  1.1350e-01,  7.9955e-02,  2.1883e-01, -1.4956e-01,  1.9569e-01,\n",
      "          1.5780e-01, -4.9774e-01,  1.3149e-01,  2.5541e-02,  2.7730e-02,  2.9256e-01,  4.5563e-01,  1.5916e-01, -3.3632e-01, -5.1662e-02, -1.8825e-01,  1.5614e-01,  2.5075e-01,  2.8154e-01,\n",
      "         -1.9837e-01, -1.8357e-01, -1.5430e-01, -2.0160e-01, -3.5631e-02,  8.7875e-03,  1.0125e-01,  2.7664e-01,  2.5068e-01, -7.0824e-02,  2.2636e-01, -1.4215e-01, -2.0600e-02, -1.4519e-01,\n",
      "         -1.1474e-02, -1.6583e-01, -8.8498e-02,  1.3318e-01,  2.5946e-01, -2.1593e-01,  8.1983e-02, -1.3517e-01,  3.5019e-01, -1.9532e-03,  3.6221e-01, -1.5558e-04, -2.3040e-02, -2.3602e-01,\n",
      "          2.9974e-01,  1.8470e-02,  1.8521e-01, -2.8171e-01, -1.5714e-02, -2.6386e-01, -3.8700e-01,  3.0069e-01,  2.0974e-01,  1.1803e-01, -3.8949e-02, -2.0081e-01, -5.7998e-02,  4.4427e-01,\n",
      "          9.5449e-02, -1.5237e-02, -1.4564e-01, -9.5095e-02, -2.0443e-01,  1.5372e-01, -2.1798e-02,  3.9822e-01,  7.1879e-02,  6.1977e-02,  5.7139e-03, -2.1511e-01,  2.4228e-01, -1.8289e-01,\n",
      "          1.6097e-01,  7.4174e-02,  1.1004e-01, -4.0477e-02,  3.8255e-02,  6.4634e-02,  4.3284e-01,  1.0069e-01, -3.7238e-02, -3.4454e-02, -3.5521e-01, -9.8749e-02, -4.9052e-02,  2.7303e-01,\n",
      "         -1.2486e-01,  2.2833e-01, -8.2038e-02, -2.5038e-01, -7.6889e-02,  6.5757e-02, -2.3133e-01,  1.0695e-01, -2.0961e-02,  2.6505e-02,  3.5188e-01,  1.1258e-02, -1.9883e-01,  6.1423e-02,\n",
      "         -1.6197e-01,  2.6162e-01, -1.3023e-01, -2.3336e-01, -4.6297e-02,  2.4880e-01, -8.6099e-02,  1.2807e-01, -1.1029e-01, -3.7904e-02, -7.5704e-02,  2.1128e-02,  2.4717e-01,  6.2910e-02,\n",
      "         -5.2672e-01, -2.6526e-01, -1.4528e-01,  2.1776e-01, -2.2960e-01, -2.6788e-01, -9.6398e-02,  8.7313e-02,  4.7622e-01, -3.9760e-01,  6.2913e-02,  3.9423e-02, -1.5674e-02, -2.5447e-01,\n",
      "         -1.4152e-01,  9.6599e-02,  2.1118e-01, -1.7682e-01, -1.2359e-01,  3.2504e-01,  1.8627e-01,  3.2598e-02, -4.0518e-01,  1.1404e-01,  6.5401e-02,  8.8549e-02,  3.8775e-01,  5.6711e-02,\n",
      "          1.9563e-01,  1.5577e-01,  4.7629e-02,  1.0255e-01,  5.5361e-02,  2.3458e-01, -3.9990e-01, -3.1245e-02, -1.1640e-01,  1.6848e-01,  2.2152e-01, -8.3164e-02,  4.8247e-01,  8.1681e-02,\n",
      "          1.7511e-01,  2.1459e-01, -3.7665e-01,  6.7009e-02,  1.6586e-01, -2.2373e-01,  9.9170e-02, -3.8073e-02, -3.3241e-01,  8.8397e-02,  2.6053e-01, -3.4812e-01,  1.4753e-01, -1.1252e-01,\n",
      "          2.5954e-01, -2.3806e-01, -3.4967e-01, -1.3657e-01,  1.1751e-01,  2.4649e-01,  4.2120e-01,  2.9965e-01,  2.4503e-01, -1.3023e-01,  1.6471e-01, -1.5019e-01,  7.0115e-02,  6.3879e-02,\n",
      "         -2.9453e-01,  2.4645e-01,  2.7022e-01,  1.0710e-01,  3.4153e-02,  1.3618e-01, -3.4693e-01, -2.1860e-01, -9.4138e-02,  1.1686e-01, -1.3690e-01,  2.9707e-02, -2.6083e-01, -3.8520e-01,\n",
      "         -5.1709e-02, -1.8275e-02,  2.2097e-01,  3.9724e-02, -6.0334e-02, -3.8967e-02,  7.5755e-02,  1.8230e-01, -1.8433e-01, -7.6850e-02, -2.2849e-01,  1.3150e-02,  4.7208e-01,  1.3172e-01,\n",
      "         -1.4540e-01, -2.5336e-01, -2.9590e-04,  1.3674e-01,  5.0710e-02,  6.8239e-02, -4.3241e-02,  1.1720e-01, -7.1422e-02, -3.5954e-01, -1.3654e-01, -2.5995e-01,  4.1473e-02,  4.7211e-01,\n",
      "         -2.7187e-01,  1.5539e-01,  1.0218e-01,  1.7209e-01,  4.7038e-02,  1.3817e-01, -2.0228e-01, -1.3951e-01,  1.6936e-01,  2.9535e-01, -7.5642e-02, -3.3735e-01, -3.5632e-01, -2.2284e-01,\n",
      "         -2.8329e-01, -1.5552e-01,  1.0609e-01, -1.7845e-01, -8.4504e-02,  3.0871e-01, -1.8063e-01, -4.2682e-02,  1.9950e-01,  3.7616e-02,  4.4312e-01,  7.1783e-02, -2.7974e-01,  9.8317e-02,\n",
      "         -1.9993e-01,  8.3518e-02,  3.9450e-01,  3.3530e-01,  4.1713e-02,  1.5860e-01,  2.7776e-02, -2.2160e-01, -3.5423e-01, -1.9874e-01, -3.2112e-01,  1.2965e-01, -1.7896e-01, -1.0715e-01,\n",
      "          2.2010e-01,  1.5087e-01,  5.9126e-02, -1.0823e-01, -4.2534e-01,  1.9153e-02,  4.6518e-02, -2.6610e-03,  2.8012e-02,  9.0242e-02, -1.8027e-01, -2.4705e-01, -1.3288e-02,  3.4114e-02,\n",
      "         -4.1079e-01,  5.5320e-01, -1.0467e-01,  1.5111e-01, -2.7230e-01,  4.0517e-02,  1.5578e-01,  2.1885e-01,  1.9130e-01,  2.3438e-01,  2.0000e-01,  3.8841e-02,  1.9818e-01,  2.6661e-02,\n",
      "         -3.1179e-01,  6.9622e-02, -2.5309e-01, -2.0849e-01, -2.1032e-01, -1.9370e-01,  2.5660e-01,  3.8301e-01,  1.7758e-02, -1.0887e-01,  1.3435e-01,  1.0580e-01,  5.7796e-01,  3.0273e-01,\n",
      "          2.1157e-01, -1.3673e-01, -1.1504e-02,  3.4144e-01, -3.6506e-01,  1.2407e-01,  2.3877e-02,  1.8042e-01,  3.4266e-01,  9.5418e-02,  2.0526e-02, -2.6827e-01, -9.0708e-03,  1.1262e-01,\n",
      "         -3.6705e-02, -2.8790e-01, -2.4694e-01,  1.2681e-01, -2.0450e-01, -9.8535e-02,  9.7532e-02,  1.2161e-01,  1.9760e-01,  2.6857e-01, -7.7196e-02, -5.9085e-02,  1.3712e-01,  1.4404e-01,\n",
      "         -2.4680e-01,  6.6524e-02,  4.1295e-02,  5.7614e-02, -2.2533e-02,  2.7598e-01, -1.0386e-01,  2.2046e-01, -8.5514e-02,  3.3672e-01,  1.4476e-01, -1.5011e-01, -3.6688e-01,  6.5578e-02,\n",
      "         -3.1150e-01, -9.6392e-02, -7.0784e-02,  5.1465e-02, -1.5845e-01,  1.4332e-01, -2.5945e-01,  2.3594e-01,  3.4506e-02,  2.8839e-01,  4.6165e-02, -3.8158e-01]]), hidden_states=(tensor([[[ 0.1158, -0.0210, -0.0104,  ..., -0.0483,  0.0827,  0.0521],\n",
      "         [-0.4306, -0.0558,  0.1098,  ..., -0.1587, -0.4074,  0.0425],\n",
      "         [ 0.0046,  0.2573,  0.0362,  ...,  0.0495, -0.2659, -0.1285],\n",
      "         ...,\n",
      "         [-0.2312,  0.0555,  0.2483,  ...,  0.3986, -0.2374,  0.0566],\n",
      "         [ 0.2261,  0.0857,  0.0040,  ...,  0.1546,  0.0412, -0.0404],\n",
      "         [ 0.0558, -0.0134, -0.0724,  ...,  0.5332,  0.0852, -0.1484]]]), tensor([[[-0.0218,  0.0695,  0.0231,  ..., -0.0269, -0.0057, -0.0818],\n",
      "         [-0.3924, -0.4355,  0.2002,  ...,  0.3924, -0.4305,  0.3145],\n",
      "         [ 0.2973,  0.3577,  0.1379,  ..., -0.4846, -0.5413,  0.1360],\n",
      "         ...,\n",
      "         [-0.5379,  0.0612,  0.2827,  ...,  0.6514, -0.2578, -0.0061],\n",
      "         [ 0.1076, -0.0645,  0.1764,  ...,  0.3574, -0.4102, -0.3680],\n",
      "         [-0.1843,  0.2735,  0.1209,  ...,  0.8322,  0.1417, -0.4186]]]), tensor([[[ 4.2579e-02,  3.1432e-02,  7.9266e-03,  ...,  1.6278e-02,  2.9532e-04, -3.8240e-02],\n",
      "         [-2.1595e-01, -3.3796e-01,  6.7505e-02,  ...,  3.5598e-01, -8.7171e-02,  6.4941e-01],\n",
      "         [-2.7493e-01,  6.4224e-01,  9.0504e-02,  ..., -6.4757e-01,  8.2689e-02,  8.2795e-02],\n",
      "         ...,\n",
      "         [-3.3573e-01,  2.4251e-01,  3.2705e-01,  ...,  6.3524e-01, -1.2517e-01, -1.5854e-01],\n",
      "         [-5.3536e-01,  4.0272e-01, -2.2110e-01,  ..., -1.6521e-01, -9.4228e-01, -2.8441e-01],\n",
      "         [-4.3038e-01,  5.8205e-01,  1.6502e-01,  ...,  9.6123e-01,  1.0210e-01, -4.8925e-01]]]), tensor([[[ 0.0565,  0.0121, -0.0297,  ...,  0.0272,  0.0084,  0.0512],\n",
      "         [ 0.1472, -0.3180,  0.5166,  ...,  0.1374, -0.5074,  0.2382],\n",
      "         [-0.2505,  0.4020,  0.2973,  ..., -0.6564, -0.0788,  0.2735],\n",
      "         ...,\n",
      "         [-0.1702,  0.0346,  0.0821,  ...,  0.4252, -0.3321, -0.1844],\n",
      "         [-0.1799,  0.3102,  0.2286,  ..., -0.4141, -0.4304,  0.0332],\n",
      "         [-0.1253,  0.4467,  0.1434,  ...,  0.5160,  0.2090, -0.1407]]]), tensor([[[ 0.0552, -0.0265,  0.0353,  ...,  0.0215, -0.0758, -0.0246],\n",
      "         [ 0.0325, -0.5868,  0.4179,  ...,  0.0228, -0.4010,  0.2328],\n",
      "         [-0.0899,  0.3373,  0.1495,  ..., -0.7370,  0.0839,  0.2206],\n",
      "         ...,\n",
      "         [-0.0098,  0.0076,  0.0603,  ...,  0.1157, -0.0770,  0.0868],\n",
      "         [-0.4365, -0.1513, -0.1006,  ..., -0.0709, -0.1617,  0.1980],\n",
      "         [ 0.1150,  0.0647,  0.0385,  ...,  0.0685,  0.0544, -0.0828]]]), tensor([[[ 0.0378,  0.0015,  0.0215,  ...,  0.0059, -0.0518, -0.0487],\n",
      "         [-0.4551, -0.5958,  0.9621,  ...,  0.0012, -0.2525, -0.6202],\n",
      "         [-0.1998,  0.5110,  0.2616,  ..., -0.8074,  0.0342, -0.2717],\n",
      "         ...,\n",
      "         [ 0.1361, -0.2137, -0.2031,  ...,  0.3923, -0.1486, -0.1138],\n",
      "         [-0.8388, -0.3875, -0.2164,  ..., -0.2039, -0.3631, -0.0287],\n",
      "         [ 0.0060, -0.0020,  0.0430,  ...,  0.0372, -0.0290, -0.0134]]]), tensor([[[ 0.0134,  0.0446,  0.0654,  ...,  0.0060, -0.0675, -0.0307],\n",
      "         [-0.5122, -0.4204,  0.6948,  ..., -0.2578, -0.3472, -0.3779],\n",
      "         [-0.3590,  0.5762, -0.0472,  ..., -0.7445, -0.0435,  0.0103],\n",
      "         ...,\n",
      "         [-0.0793, -0.3013, -0.0501,  ...,  0.3361,  0.3068, -0.0206],\n",
      "         [-0.6638, -0.6119,  0.0178,  ..., -0.3954,  0.4266, -0.0624],\n",
      "         [ 0.0037,  0.0473,  0.0283,  ...,  0.0049, -0.0100, -0.0246]]]), tensor([[[-0.0365,  0.0920,  0.0539,  ...,  0.0553, -0.0320, -0.0101],\n",
      "         [-0.0237, -0.6099,  0.7536,  ..., -0.1323, -0.2277, -0.6421],\n",
      "         [ 0.0640,  0.5283, -0.0550,  ..., -0.7937,  0.0062, -0.0692],\n",
      "         ...,\n",
      "         [ 0.0435, -0.4564, -0.0441,  ...,  0.1757,  0.1455,  0.1776],\n",
      "         [-0.5521, -0.6591,  0.0249,  ..., -0.2202, -0.6218,  0.1709],\n",
      "         [-0.0045,  0.0540,  0.0035,  ...,  0.0164, -0.0055, -0.0054]]]), tensor([[[ 1.8679e-02,  1.0689e-01,  1.4877e-02,  ...,  2.0360e-04, -2.0135e-02, -8.1524e-03],\n",
      "         [-4.6305e-02, -5.2606e-01,  8.0521e-01,  ...,  6.7559e-02, -7.9432e-02, -2.3432e-01],\n",
      "         [ 4.4450e-01,  7.2763e-01,  2.1008e-01,  ..., -8.5907e-01,  6.8090e-02, -1.4022e-01],\n",
      "         ...,\n",
      "         [-5.6521e-02, -7.0568e-01,  2.0837e-02,  ..., -1.3252e-02,  3.6322e-01,  6.3361e-01],\n",
      "         [-2.5515e-01, -9.5288e-01,  2.6821e-01,  ..., -5.0390e-02,  8.8467e-03, -6.1191e-02],\n",
      "         [ 3.4017e-03,  1.3953e-02,  5.9620e-03,  ..., -1.1174e-02, -1.6405e-02,  7.5799e-03]]]), tensor([[[-0.0303,  0.0257,  0.0153,  ..., -0.0304,  0.0189, -0.0443],\n",
      "         [ 0.1684, -0.5049,  0.1966,  ..., -0.1097, -0.2916, -0.0144],\n",
      "         [ 0.1961,  0.5819,  0.0418,  ..., -0.7930,  0.0358, -0.1037],\n",
      "         ...,\n",
      "         [ 0.4882, -0.4584,  0.0262,  ...,  0.2271,  0.0624,  0.1663],\n",
      "         [ 0.5655, -0.9209,  0.4594,  ...,  0.2037,  0.1548,  0.4042],\n",
      "         [-0.0087,  0.0071,  0.0059,  ...,  0.0136,  0.0189, -0.0308]]]), tensor([[[ 0.0061,  0.0256, -0.0168,  ...,  0.0137,  0.0172, -0.0228],\n",
      "         [ 0.6624, -0.6505,  0.2580,  ..., -0.1033, -0.0456, -0.5846],\n",
      "         [-0.0222,  0.6373,  0.0094,  ..., -0.5997, -0.0641,  0.0785],\n",
      "         ...,\n",
      "         [ 0.4867, -0.5942, -0.0818,  ...,  0.1161,  0.1056,  0.1449],\n",
      "         [ 0.3849, -1.0808,  0.4841,  ..., -0.0522, -0.7031,  0.2864],\n",
      "         [ 0.0026,  0.0267, -0.0119,  ...,  0.0152,  0.0187, -0.0144]]]), tensor([[[ 1.5555e-02,  3.0836e-02, -1.7643e-02,  ...,  5.5252e-03, -1.5104e-02,  4.3583e-04],\n",
      "         [ 7.9497e-01, -1.0041e+00, -1.7727e-01,  ...,  8.7520e-02,  4.5326e-02, -3.2727e-01],\n",
      "         [ 9.9108e-02,  6.6493e-01,  1.9181e-01,  ..., -4.5561e-01, -2.6125e-01, -4.1855e-03],\n",
      "         ...,\n",
      "         [ 4.0451e-01, -5.1785e-01, -1.3570e-01,  ..., -6.2594e-03,  3.0886e-01,  7.9285e-02],\n",
      "         [ 4.3908e-01, -5.5374e-01,  2.5925e-01,  ..., -3.0764e-01, -6.3025e-01,  4.4357e-01],\n",
      "         [ 1.4228e-02,  3.0646e-02, -1.6883e-02,  ...,  5.0867e-03, -1.5145e-02,  7.3135e-04]]]), tensor([[[-0.1256,  0.0642, -0.0674,  ..., -0.2878, -0.0828, -0.0428],\n",
      "         [ 0.2194, -0.1838,  0.1381,  ..., -0.0063, -0.1952,  0.0487],\n",
      "         [ 0.0841,  0.3627,  0.2097,  ..., -0.4123, -0.0723, -0.0095],\n",
      "         ...,\n",
      "         [ 0.1294, -0.0459,  0.1020,  ..., -0.1478,  0.1431,  0.0026],\n",
      "         [ 0.2263, -0.1205,  0.0422,  ..., -0.4867, -0.1622,  0.1561],\n",
      "         [-0.1260,  0.0641, -0.0675,  ..., -0.2884, -0.0831, -0.0429]]])), past_key_values=None, attentions=None, cross_attentions=None)\n"
     ]
    }
   ],
   "source": [
    "#masked_sentence = sentence_list[0].replace('report', '[MASK]')\n",
    "masked_sentence = \"there is diffuse consolidation in the right lung, indicative of <mask>\"\n",
    "print(masked_sentence)\n",
    "tokens = tokenizer1(masked_sentence, padding=True, truncation=True, return_tensors='pt')\n",
    "print(tokens)\n",
    "with torch.no_grad():\n",
    "    output_full = full_model1(**tokens, output_hidden_states=True)\n",
    "    output_base = base_model1(**tokens, output_hidden_states=True)\n",
    "print(output_full)\n",
    "print(output_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 14, 50265])\n",
      "tensor([    4,  8585,    16, 41118, 13581,    11,     5,   235, 10665,     6, 22206,     9,  1437,     4])\n",
      ".there is diffuse consolidation in the right lung, indicative of.\n"
     ]
    }
   ],
   "source": [
    "logits_before_softmax = output_full.logits\n",
    "print(logits_before_softmax.size())\n",
    "prediction = logits_before_softmax[0].argmax(axis=-1)\n",
    "print(prediction)\n",
    "print(tokenizer1.decode(prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13\n",
      "tensor([[[-0.1256,  0.0642, -0.0674,  ..., -0.2878, -0.0828, -0.0428],\n",
      "         [ 0.2194, -0.1838,  0.1381,  ..., -0.0063, -0.1952,  0.0487],\n",
      "         [ 0.0841,  0.3627,  0.2097,  ..., -0.4123, -0.0723, -0.0095],\n",
      "         ...,\n",
      "         [ 0.1294, -0.0459,  0.1020,  ..., -0.1478,  0.1431,  0.0026],\n",
      "         [ 0.2263, -0.1205,  0.0422,  ..., -0.4867, -0.1622,  0.1561],\n",
      "         [-0.1260,  0.0641, -0.0675,  ..., -0.2884, -0.0831, -0.0429]]])\n",
      "torch.Size([1, 768])\n",
      "tensor([-1.2561e-01,  6.4220e-02, -6.7388e-02, -4.8061e-02,  2.7138e-01, -1.4991e-01,  7.8765e-03, -1.2044e-02,  4.6624e-02, -1.3837e-01,  2.4973e-02, -2.1923e-02, -3.7160e-02, -1.3059e-01,\n",
      "        -7.0208e-02, -9.2608e-03,  4.4490e-02,  3.9585e-02, -1.6303e-02, -2.8625e-02, -1.0248e-01,  1.2490e-01,  1.0356e-01,  9.4474e-02,  9.8920e-02,  3.5897e-02,  1.1930e-01,  3.1564e-02,\n",
      "         1.5390e-01, -3.1594e-02, -1.0037e-01, -2.5524e-02,  7.7781e-02, -5.3618e-02, -2.0454e-02, -5.1781e-02,  7.0981e-02, -1.2935e-02, -1.3886e-02,  2.6556e-02, -1.0963e-01,  1.0161e-02,\n",
      "         1.6596e-01, -4.2970e-02,  3.6664e-02, -2.6050e-02,  1.3326e-01,  4.8544e-02,  3.9688e-02, -4.8335e-02, -5.6778e-02, -1.1131e-02,  1.2971e-03, -1.9836e-02, -1.9066e-02,  1.0597e-01,\n",
      "         4.3873e-02,  2.4308e-01,  2.7675e-02,  8.7192e-02,  2.3574e-02, -1.2971e-01, -7.8483e-03,  1.0572e-01,  7.4622e-02,  2.7052e-03, -1.0930e-02, -6.6157e-02,  1.1290e-02,  2.8398e-03,\n",
      "         9.0367e-02,  2.7806e-02, -8.4877e-03, -9.3641e-02,  2.0758e-03, -2.6427e-02,  1.7260e-01,  2.2790e-01, -8.1002e-02,  1.0034e-01,  3.4622e-03, -7.3401e-02,  6.3887e-02,  1.3918e-01,\n",
      "         1.0534e-01, -6.9255e-02,  7.7194e-02,  2.8370e-02, -9.0844e-02,  7.5746e-02,  8.4847e-03,  1.0973e-01,  5.5260e-02,  1.0798e-01,  3.4147e-02, -3.7161e-02,  1.8096e-02, -2.1346e-01,\n",
      "         6.9416e-03,  4.1262e-02, -6.4646e-02, -1.4369e-02, -1.6615e-01, -6.0585e-02,  3.8496e-02,  4.3554e-02,  7.9220e-02,  2.3147e-02,  5.9264e-02,  2.5323e-03, -8.3112e-02,  4.5580e-02,\n",
      "        -1.9686e-02,  4.9914e-02,  8.4036e-02, -6.1818e-02, -1.0028e-02,  4.2213e-02,  8.9947e-02,  3.8140e-02,  3.6039e-02, -3.8893e-02,  1.2256e-01,  7.7372e-02, -8.1787e-03,  1.4850e-01,\n",
      "         6.8547e-02, -8.6604e-03, -4.1924e-02,  5.7174e-02,  2.7339e-02, -3.0813e-01,  1.1763e-01, -5.2001e-04,  9.2581e-02,  5.5880e-02, -9.2308e-02,  1.6311e-02, -7.4921e-02, -3.6655e-02,\n",
      "         9.7446e-02, -1.4870e-02,  1.6436e-03, -5.2025e-02,  5.0011e-02,  9.4717e-02, -1.2191e-02,  9.9752e-02, -1.5758e-01, -7.4526e-02,  1.0590e-01, -3.9466e-02,  4.4856e-02,  6.9870e-02,\n",
      "        -1.4387e-01,  2.8584e-01,  1.5835e-01, -2.4891e-02, -8.8630e-02,  6.1002e-02,  3.6352e-02, -4.4550e-02, -5.2457e-02,  6.8653e-02, -1.8391e-04, -6.8920e-02, -2.9444e-02,  4.4202e-02,\n",
      "         7.4168e-02, -1.7757e-02,  9.2454e-02, -3.5568e-02, -1.8902e-02,  2.7169e-02,  5.3885e-02,  8.9838e-02, -7.8488e-02,  4.1575e-02, -1.2383e-01, -1.3853e-02,  3.0094e-02,  6.0834e-02,\n",
      "        -8.7729e-02, -1.1178e-02,  9.3983e-02, -3.1431e-02,  4.1545e-02, -4.4264e-02,  8.0739e-02, -1.1525e-01,  2.1352e-02,  1.8986e-02,  9.3989e-02, -5.7919e-02,  2.8327e-02,  1.6643e-01,\n",
      "        -3.6497e-02, -6.6986e-02,  1.4525e-01,  1.7288e-02, -8.7046e-02, -6.3948e-02,  3.7024e-02, -3.7406e-03,  1.6563e-01,  7.3864e-02, -1.2177e-01, -2.4376e-02, -7.1526e-02, -1.3532e-02,\n",
      "        -1.1381e-02,  9.8037e-02, -3.2202e-03, -6.8434e-02,  5.6444e-02, -1.0579e-01, -7.8224e-02,  7.0013e-03, -3.6798e-02, -6.6206e-02,  1.2337e-01,  5.6120e-02, -1.2230e-01, -3.7817e-02,\n",
      "         4.1857e-02,  9.4285e-02,  8.3879e-02,  1.1263e-01, -3.2199e-02, -1.0553e-02, -7.1826e-02,  4.5615e-02, -1.1825e-01,  7.1215e-02,  9.7945e-02, -2.4661e-01,  8.2822e-02, -3.3409e-02,\n",
      "         6.2087e-02, -8.4748e-02, -2.0098e-02,  6.1469e-03,  5.7424e-02,  2.0892e-02,  1.1189e-02,  7.1262e-02,  7.6718e-02,  1.7053e-01, -7.4395e-02,  1.1755e-03, -8.5287e-02, -7.6746e-02,\n",
      "        -7.1738e-02,  2.5097e-02,  1.1338e-02,  4.3051e-02,  2.8913e-02, -3.0663e-02, -5.4471e-02,  5.9123e-02, -3.7471e-02,  2.5504e-02, -6.3021e-02,  8.6789e-02, -3.6142e-02, -1.7533e-01,\n",
      "        -1.4904e-02, -2.9742e-02,  4.0262e-02,  6.7817e-02,  2.6416e-02, -6.2689e-02,  4.1674e-02,  3.8667e-02, -2.1125e-02,  5.6780e-02, -1.1297e-01, -1.8737e-02,  3.6520e-03, -5.4233e-02,\n",
      "        -1.1799e-02,  1.0831e-01, -1.4497e-01,  9.7390e-02,  1.5160e-02, -1.3258e-01,  2.9608e-02,  1.5261e-02,  8.8005e-03,  4.3482e-02, -2.1975e-02,  7.2674e-02, -5.1952e-02,  6.0339e-02,\n",
      "         2.0072e-02,  2.5544e-02,  1.3880e-02, -6.1862e-02, -2.2230e-02, -1.0108e-01, -1.3697e-02, -1.8401e-01,  3.6349e-02, -1.0606e-01,  8.5618e-02, -4.0340e-02,  6.8986e-02,  7.3010e-02,\n",
      "         1.3704e-01, -3.8567e-02, -3.0645e-02,  7.4490e-02, -6.6295e-02, -1.3615e-02, -5.1519e-02,  8.2460e-02, -1.5771e-01,  4.8277e-02, -5.4230e-02,  6.0272e-02,  2.0507e-02,  6.3568e-02,\n",
      "         5.2063e-02, -9.8458e-02, -4.7142e-02,  1.7081e-01,  9.2742e-02, -5.1218e-02, -1.7084e-02,  2.7112e-01, -2.3142e-01,  2.3359e-02, -1.5011e-02,  3.9575e-02,  1.2654e-01, -3.4547e-02,\n",
      "         1.2127e-01,  2.5677e-02,  1.5923e-01,  1.3203e-01,  3.0054e-02, -3.3376e-02, -8.0926e-02, -6.2358e-03, -3.7252e-02, -1.3034e-02,  7.5594e-02, -6.3456e-02, -2.1194e-02,  1.4446e-02,\n",
      "        -8.5137e-02,  1.2790e-01, -7.4891e-02, -1.0509e-01, -2.3497e-03,  1.5493e-01, -4.4070e-02,  3.3732e-02,  1.2789e-02,  2.5793e-02, -1.2267e-01,  1.0794e-01, -3.7477e-02, -1.2325e-01,\n",
      "         2.5254e-01, -2.6772e-01, -1.6652e-01,  2.8346e-02, -2.1083e-02,  8.5740e-02,  1.0446e-01,  1.5200e-01,  3.1595e-02, -8.1541e-02, -2.9721e-02,  2.3119e-02, -3.9852e-02,  1.0675e-01,\n",
      "         5.2988e-02,  8.7091e-02,  3.2217e-02,  7.7747e-02,  1.0481e-01,  1.1206e-01,  1.2998e-01, -9.5548e-02,  5.6087e-02,  6.1189e-02,  7.6704e-02,  7.9029e-02,  8.1829e-02, -3.2880e-02,\n",
      "         4.2828e-02,  9.4280e-03,  4.8050e-02,  7.1810e-02, -8.8858e-03,  1.3521e-01, -1.9118e-01, -4.6091e-02, -2.3566e-02,  4.0528e-02, -3.2613e-02,  5.9110e-04,  7.2834e-02,  1.0309e-01,\n",
      "        -6.2965e-02, -1.2821e-02,  2.4113e-02, -1.2174e-01, -3.1291e-02,  8.8717e-02, -1.6478e-02, -5.9320e-04,  4.0747e-02, -3.0884e-02, -1.7169e-02, -1.1514e-01, -4.1734e-02,  3.0668e-02,\n",
      "         1.2128e-01,  1.0020e-01, -5.9221e-02, -1.8233e-02, -5.8121e-02,  6.4737e-02, -8.1459e-02, -1.2952e-01, -5.8291e-02,  7.2784e-02, -4.2963e-02, -1.2245e-02, -6.3936e-02,  5.1041e-02,\n",
      "         7.2444e-02, -9.0671e-02, -2.0174e-03,  3.6588e-02, -1.8958e-02, -1.0264e-01,  3.0564e-02, -8.9183e-02, -6.9523e-02,  1.2685e-01,  4.9744e-02, -1.1890e-01,  1.7179e-01, -2.7233e-02,\n",
      "        -1.8490e-02,  9.5125e-02, -1.3248e-01,  8.3115e-02,  1.6006e-01, -4.6312e-01,  1.2618e-01,  6.7407e-02,  2.9819e-02, -2.3923e-02, -3.0265e-02, -8.4570e-02,  1.4786e-02,  3.4606e-02,\n",
      "        -1.5361e-03, -1.8844e-02,  7.2624e-02,  3.8389e-02, -9.9869e-03, -5.5871e-02,  5.9000e-02,  6.4766e-03,  1.4821e-01,  8.7043e-02, -4.2831e-02, -9.8632e-02, -3.9914e-02,  2.3059e-02,\n",
      "        -7.5571e-02, -1.6423e-01,  1.9970e-02, -9.0852e-02, -1.0849e-01,  6.6586e-02,  7.5310e-02,  2.3831e-02, -2.7932e-02,  3.1204e-02, -2.8647e-02, -1.5150e-02,  9.1875e-03, -2.1511e-02,\n",
      "        -1.6924e-01,  2.8379e-02, -7.3528e-02,  7.2112e-02,  2.3345e-01,  6.8459e-02, -4.4876e-02,  4.0558e-02,  8.1368e-02, -7.7817e-02,  7.6657e-02,  4.3375e-02,  5.2491e-02, -6.5650e-02,\n",
      "         3.2093e-02,  4.1517e-02, -9.3381e-02,  6.3770e-02, -1.0847e-01,  2.6474e-02,  3.3146e-02, -5.5776e-03,  5.8358e-02,  8.1348e-02,  5.4787e-02, -1.9482e-02,  2.2621e-02,  5.2654e-02,\n",
      "         3.0112e-02, -4.9402e-02,  5.3808e-02, -4.5289e-02,  1.0431e-02, -3.8338e-02,  2.5026e-02,  4.7596e-02,  1.4157e-02, -8.1961e-02,  1.4629e-01, -2.7041e-03,  1.3985e-02,  1.3077e-02,\n",
      "         2.6311e-02,  4.5221e-02, -6.5630e-02,  8.6341e-02,  1.1703e-01, -1.5055e-02,  5.6898e-02, -1.1409e-01,  8.5660e-03, -3.5479e-02,  1.1773e-01,  3.1110e-02,  9.7058e-02,  6.0990e-02,\n",
      "         5.4847e-02, -2.6571e-02,  7.8362e-02,  7.3627e-03,  1.5912e-02, -4.1622e-01, -4.4379e-02,  1.0611e-01,  2.9762e-02,  4.3324e-02,  8.0062e-02,  8.6399e-02,  3.8354e-02,  1.6854e-01,\n",
      "        -9.5772e-02,  8.4035e-02,  5.2190e-02,  5.7484e-02, -4.6717e-02,  3.3642e-02,  9.4944e-02, -7.7576e-02,  1.2651e-02, -3.1911e-02, -7.9055e-02,  5.7620e-02, -4.6454e-02,  2.6334e-01,\n",
      "         8.8280e-02, -1.2504e-02,  9.7939e-02, -9.1085e-02,  5.5468e-02,  5.9136e-02,  1.5058e-01,  1.1404e-01,  4.1960e-02, -1.4000e-01,  4.1437e-02, -5.5095e-03,  2.2243e-01,  2.4677e-02,\n",
      "         1.0423e+01, -4.2721e-02,  1.0860e-02, -7.9421e-02,  3.7225e-02, -5.4816e-02, -4.5615e-05, -4.4459e-03,  2.0231e-02,  2.4728e-02,  3.7172e-02, -1.5552e-01, -1.2585e-01,  5.8835e-02,\n",
      "        -8.3248e-03,  4.4401e-02,  1.1227e-01, -1.8520e-02,  7.3574e-02,  4.8693e-03, -3.6056e-02,  8.4783e-02,  9.2403e-02, -1.8632e-01, -6.4643e-02,  1.5356e-01, -4.7148e-02, -7.5012e-02,\n",
      "        -9.4610e-02,  1.5172e-01, -1.1955e-02,  7.1790e-02,  1.3812e-01, -6.6647e-03,  1.6252e-01, -1.1316e-01, -2.0946e-01,  1.0556e-01,  1.2561e-01, -1.1813e-01,  9.0876e-02,  1.5716e-03,\n",
      "         1.5161e-01,  7.8103e-02,  9.5999e-02,  3.6204e-02,  6.6614e-02,  9.8751e-02,  5.2806e-02, -2.0812e-02,  7.9664e-02,  1.8470e-02,  1.9483e-01, -9.2232e-02, -2.6532e-02, -9.8148e-03,\n",
      "         6.3250e-02,  4.8448e-02, -4.9115e-02,  9.9563e-02,  1.9621e-02, -1.0672e-01,  5.8954e-02, -3.0112e-03, -9.6185e-02,  1.8287e-01,  1.0816e-01,  1.5211e-01,  5.1686e-02,  3.3887e-02,\n",
      "         1.7737e-02, -1.5400e-01,  1.5080e-01, -5.7652e-02,  6.0698e-03,  1.3134e-01,  1.5263e-01, -6.3129e-03,  8.8666e-02, -7.6744e-02,  1.1663e-02,  1.1873e-01, -9.3543e-03, -9.7288e-03,\n",
      "        -8.1738e-02,  4.9543e-02, -1.7560e-02,  5.1502e-02,  9.3698e-02, -2.1093e-02, -1.3293e-01, -4.0178e-02, -1.5470e-01, -1.7965e-02,  1.1631e-01, -1.1902e-01,  6.3610e-02, -3.4325e-02,\n",
      "         1.8225e-02, -6.6585e-02, -1.9633e-02,  3.0487e-02,  4.0960e-02,  8.8895e-02, -1.2072e-01,  1.9095e-02, -1.1991e-02,  1.3929e-01, -9.8033e-02,  9.6598e-02, -1.1384e-02,  1.6048e-01,\n",
      "         3.4678e-02, -1.1458e-03,  7.1371e-02,  1.4089e-02,  9.7237e-03, -2.6687e-02,  1.6664e-01,  1.1269e-01,  3.5696e-02, -2.1476e-02, -8.3595e-02,  2.9526e-02,  9.5355e-02, -4.5823e-02,\n",
      "        -1.5604e-02,  7.6677e-02, -8.7963e-02,  9.0646e-02,  3.7090e-02,  3.3457e-02,  6.5844e-02,  4.0435e-02,  1.8841e-02,  3.9890e-02, -1.2439e-02, -9.2604e-03, -4.8872e-03,  1.4263e-01,\n",
      "        -1.3133e-01,  6.7275e-02,  8.2379e-02, -5.0277e-02, -1.3553e-02,  1.2167e-01,  9.1748e-02, -7.2375e-02, -1.4750e-03,  3.9871e-02,  1.9422e-01,  2.1114e-01, -1.1403e-01,  4.5873e-02,\n",
      "        -5.5657e-02, -1.7446e-02, -5.9875e-02,  1.4626e-01,  7.5713e-02, -9.0242e-02,  1.5045e-01, -1.1802e-01, -1.2373e-02, -9.3856e-02, -9.4686e-02, -1.6879e-02, -4.0193e-02,  7.9508e-02,\n",
      "         9.1418e-02,  7.4102e-02,  1.7432e-03,  1.3287e-02, -2.8284e-01, -5.1969e-02, -3.6114e-02,  3.5864e-02,  1.9246e-01, -2.8780e-01, -8.2830e-02, -4.2792e-02])\n"
     ]
    }
   ],
   "source": [
    "print(len(output_full.hidden_states))\n",
    "last_hidden_state = output_full.hidden_states[-1]\n",
    "print(last_hidden_state)\n",
    "print(last_hidden_state.mean(dim=1).size())\n",
    "print(last_hidden_state.squeeze()[0, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_pipeline = pipeline('feature-extraction', tokenizer=tokenizer1, model=base_model1)\n",
    "embedding_output = embeddings_pipeline(masked_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.12561452388763428, 0.06421953439712524, -0.06738809496164322, -0.04806055873632431, 0.2713826298713684, -0.14991183578968048, 0.007876463234424591, -0.01204390823841095, 0.046623922884464264, -0.13837450742721558, 0.024972612038254738, -0.021923096850514412, -0.0371602401137352, -0.13058960437774658, -0.0702078714966774, -0.00926084816455841, 0.044490233063697815, 0.03958526998758316, -0.016303004696965218, -0.02862510457634926, -0.10248009860515594, 0.12489702552556992, 0.10355852544307709, 0.09447358548641205, 0.09892034530639648, 0.03589686378836632, 0.11930345743894577, 0.03156440705060959, 0.15389728546142578, -0.03159384801983833, -0.1003681942820549, -0.025524117052555084, 0.07778114080429077, -0.053618062287569046, -0.02045433409512043, -0.05178115889430046, 0.0709814578294754, -0.012935377657413483, -0.01388633158057928, 0.026556264609098434, -0.10963022708892822, 0.010161401703953743, 0.1659633368253708, -0.042969826608896255, 0.0366642102599144, -0.026049578562378883, 0.13325564563274384, 0.04854358360171318, 0.03968823701143265, -0.04833490401506424, -0.05677831918001175, -0.011130583472549915, 0.0012971283867955208, -0.019836440682411194, -0.019065655767917633, 0.10596657544374466, 0.043872565031051636, 0.2430846244096756, 0.02767486870288849, 0.08719152212142944, 0.023574277758598328, -0.12970511615276337, -0.00784826185554266, 0.10571624338626862, 0.0746217668056488, 0.0027052401565015316, -0.01093009952455759, -0.06615670025348663, 0.011290215887129307, 0.002839768538251519, 0.09036663919687271, 0.027806362137198448, -0.008487737737596035, -0.09364058822393417, 0.0020758050959557295, -0.026427431032061577, 0.17259913682937622, 0.22790105640888214, -0.08100169897079468, 0.10034145414829254, 0.0034622307866811752, -0.07340077310800552, 0.06388679146766663, 0.13917779922485352, 0.10533510893583298, -0.06925490498542786, 0.07719376683235168, 0.028369884938001633, -0.090843565762043, 0.07574566453695297, 0.008484652265906334, 0.10973339527845383, 0.055259522050619125, 0.10798183083534241, 0.03414737805724144, -0.03716142848134041, 0.018095839768648148, -0.21345889568328857, 0.006941578816622496, 0.04126199707388878, -0.06464584171772003, -0.014369243755936623, -0.16614621877670288, -0.06058520823717117, 0.038496363908052444, 0.04355411231517792, 0.0792195126414299, 0.023147141560912132, 0.059264104813337326, 0.002532264683395624, -0.08311176300048828, 0.04558023065328598, -0.01968603953719139, 0.049914415925741196, 0.08403611928224564, -0.061818450689315796, -0.010028486140072346, 0.04221301153302193, 0.08994672447443008, 0.03814011067152023, 0.03603910282254219, -0.03889330476522446, 0.1225639209151268, 0.07737232744693756, -0.008178667165338993, 0.14849872887134552, 0.06854734569787979, -0.008660363033413887, -0.04192425310611725, 0.057173945009708405, 0.027339298278093338, -0.3081282377243042, 0.11763045191764832, -0.0005200072773732245, 0.09258052706718445, 0.055879857391119, -0.09230805188417435, 0.016310812905430794, -0.07492099702358246, -0.03665488585829735, 0.09744580090045929, -0.014870419166982174, 0.0016435618745163083, -0.05202506482601166, 0.05001078173518181, 0.09471733868122101, -0.012191440910100937, 0.099752277135849, -0.15757879614830017, -0.07452615350484848, 0.10589732229709625, -0.039465729147195816, 0.04485560581088066, 0.0698702335357666, -0.14386700093746185, 0.285842627286911, 0.15834927558898926, -0.024890705943107605, -0.08863011002540588, 0.06100182235240936, 0.03635160252451897, -0.04455038532614708, -0.05245717242360115, 0.06865336000919342, -0.00018390518380329013, -0.06892033666372299, -0.029444457963109016, 0.044202253222465515, 0.07416784763336182, -0.01775684580206871, 0.09245357662439346, -0.03556804358959198, -0.01890186220407486, 0.027169127017259598, 0.0538853220641613, 0.08983767032623291, -0.07848789542913437, 0.041575223207473755, -0.12382553517818451, -0.013852963224053383, 0.03009391389787197, 0.06083420664072037, -0.08772912621498108, -0.011178145185112953, 0.0939825177192688, -0.03143085911870003, 0.04154462739825249, -0.04426370561122894, 0.08073873817920685, -0.11525387316942215, 0.021352389827370644, 0.01898553967475891, 0.09398870915174484, -0.05791871249675751, 0.02832723967730999, 0.16642875969409943, -0.0364973321557045, -0.06698589771986008, 0.1452479362487793, 0.01728816330432892, -0.08704598248004913, -0.06394844502210617, 0.03702417388558388, -0.0037406301125884056, 0.16563157737255096, 0.07386359572410583, -0.12177382409572601, -0.024375729262828827, -0.07152550667524338, -0.013532251119613647, -0.011381249874830246, 0.0980365127325058, -0.0032202156726270914, -0.06843362003564835, 0.056443631649017334, -0.10578911006450653, -0.07822368294000626, 0.007001291960477829, -0.03679824620485306, -0.06620591878890991, 0.12337365001440048, 0.05612049624323845, -0.12229671329259872, -0.037816550582647324, 0.041857145726680756, 0.09428517520427704, 0.08387899398803711, 0.11263017356395721, -0.032199427485466, -0.010553257539868355, -0.07182644307613373, 0.045614760369062424, -0.11825333535671234, 0.07121460884809494, 0.09794462472200394, -0.24661344289779663, 0.0828217938542366, -0.03340904042124748, 0.06208688020706177, -0.08474771678447723, -0.02009761892259121, 0.006146934814751148, 0.057423919439315796, 0.020891906693577766, 0.011188646778464317, 0.07126174867153168, 0.07671783119440079, 0.17053265869617462, -0.07439496368169785, 0.0011755148880183697, -0.08528700470924377, -0.07674607634544373, -0.07173795998096466, 0.02509668469429016, 0.01133777853101492, 0.04305073618888855, 0.02891308069229126, -0.030662668868899345, -0.05447103828191757, 0.05912269651889801, -0.03747135400772095, 0.025504151359200478, -0.06302079558372498, 0.08678949624300003, -0.036141566932201385, -0.17533211410045624, -0.014903739094734192, -0.02974240668118, 0.04026170074939728, 0.06781734526157379, 0.026416219770908356, -0.06268914043903351, 0.041673555970191956, 0.0386672168970108, -0.02112519182264805, 0.056780241429805756, -0.11297089606523514, -0.018736977130174637, 0.003652028739452362, -0.05423303693532944, -0.011798689141869545, 0.10831466317176819, -0.14496612548828125, 0.09739033877849579, 0.015160362236201763, -0.13258479535579681, 0.02960810251533985, 0.01526139210909605, 0.008800484240055084, 0.043482083827257156, -0.02197512425482273, 0.07267404347658157, -0.05195166543126106, 0.0603388249874115, 0.02007182128727436, 0.025544125586748123, 0.013879528269171715, -0.061861760914325714, -0.022230325266718864, -0.10108300298452377, -0.013697216287255287, -0.1840115785598755, 0.036348890513181686, -0.10605507344007492, 0.08561763167381287, -0.040340159088373184, 0.06898613274097443, 0.07301017642021179, 0.13703849911689758, -0.03856749087572098, -0.030644938349723816, 0.0744900032877922, -0.06629542261362076, -0.01361503079533577, -0.05151857063174248, 0.08245958387851715, -0.1577148139476776, 0.0482773520052433, -0.05423036590218544, 0.06027238443493843, 0.020506825298070908, 0.0635676234960556, 0.052062999457120895, -0.09845836460590363, -0.047141727060079575, 0.17080898582935333, 0.09274215996265411, -0.051218431442976, -0.017083823680877686, 0.27111658453941345, -0.23142477869987488, 0.02335905097424984, -0.015011277981102467, 0.039574865251779556, 0.12654073536396027, -0.03454744815826416, 0.1212691217660904, 0.025676684454083443, 0.15923458337783813, 0.13203422725200653, 0.03005392476916313, -0.033375851809978485, -0.08092603832483292, -0.0062358141876757145, -0.0372517891228199, -0.013033523224294186, 0.07559429854154587, -0.06345628201961517, -0.021193597465753555, 0.014446008019149303, -0.08513698726892471, 0.12790299952030182, -0.07489071786403656, -0.10509025305509567, -0.002349747810512781, 0.154926598072052, -0.044070467352867126, 0.033731646835803986, 0.012788851745426655, 0.02579258568584919, -0.12267433851957321, 0.10794194787740707, -0.03747744485735893, -0.12325314432382584, 0.2525426149368286, -0.2677246928215027, -0.16652260720729828, 0.028346246108412743, -0.021082967519760132, 0.08574001491069794, 0.10445870459079742, 0.15200096368789673, 0.03159521892666817, -0.08154083788394928, -0.02972109615802765, 0.02311893366277218, -0.03985197842121124, 0.10674526542425156, 0.05298805609345436, 0.0870911180973053, 0.03221675381064415, 0.07774697244167328, 0.1048119068145752, 0.11205901205539703, 0.12998303771018982, -0.09554756432771683, 0.056087326258420944, 0.06118942052125931, 0.0767037570476532, 0.07902895659208298, 0.08182880282402039, -0.03288036584854126, 0.042827922850847244, 0.009427979588508606, 0.048049647361040115, 0.07181036472320557, -0.008885799907147884, 0.13521426916122437, -0.19117921590805054, -0.046090688556432724, -0.023566409945487976, 0.04052845388650894, -0.03261329606175423, 0.0005910988547839224, 0.07283433526754379, 0.10308714210987091, -0.06296546012163162, -0.012820576317608356, 0.024113137274980545, -0.12173962593078613, -0.03129057586193085, 0.08871699124574661, -0.016477935016155243, -0.0005932015483267605, 0.040747128427028656, -0.03088417463004589, -0.01716945692896843, -0.11513539403676987, -0.041734419763088226, 0.030668385326862335, 0.12127742171287537, 0.10019980370998383, -0.05922123044729233, -0.01823282241821289, -0.05812091380357742, 0.06473726779222488, -0.08145920932292938, -0.12952031195163727, -0.05829058960080147, 0.07278414070606232, -0.04296348616480827, -0.01224549487233162, -0.06393556296825409, 0.05104120820760727, 0.07244358211755753, -0.0906708762049675, -0.0020173892844468355, 0.03658780828118324, -0.018958136439323425, -0.10264404118061066, 0.03056393563747406, -0.08918342739343643, -0.06952336430549622, 0.12684836983680725, 0.04974355176091194, -0.11890493333339691, 0.17179261147975922, -0.027233337983489037, -0.01849016733467579, 0.09512469917535782, -0.13247831165790558, 0.08311522006988525, 0.16005969047546387, -0.4631173014640808, 0.12617619335651398, 0.06740742921829224, 0.02981850504875183, -0.023923184722661972, -0.030264850705862045, -0.08457033336162567, 0.014786387793719769, 0.034605734050273895, -0.0015361227560788393, -0.018843641504645348, 0.07262388616800308, 0.03838949650526047, -0.009986888617277145, -0.055871058255434036, 0.05899958685040474, 0.006476603448390961, 0.14821411669254303, 0.08704280108213425, -0.042831409722566605, -0.09863243252038956, -0.03991399332880974, 0.023059407249093056, -0.07557066529989243, -0.16423244774341583, 0.01996978372335434, -0.09085196256637573, -0.10849027335643768, 0.0665857195854187, 0.07531038671731949, 0.023831307888031006, -0.027932479977607727, 0.031203530728816986, -0.028646551072597504, -0.015150351449847221, 0.009187540039420128, -0.02151091955602169, -0.16924142837524414, 0.02837921865284443, -0.07352769374847412, 0.07211196422576904, 0.23344916105270386, 0.06845920532941818, -0.044876132160425186, 0.04055839404463768, 0.08136750012636185, -0.07781735807657242, 0.07665650546550751, 0.04337511211633682, 0.05249122902750969, -0.06565004587173462, 0.03209254890680313, 0.04151733219623566, -0.09338116645812988, 0.06376976519823074, -0.10847494751214981, 0.02647395059466362, 0.033146098256111145, -0.005577552132308483, 0.05835750326514244, 0.08134835213422775, 0.05478714779019356, -0.019482260569930077, 0.022621402516961098, 0.05265431851148605, 0.03011232055723667, -0.04940182715654373, 0.0538083016872406, -0.045289281755685806, 0.010430987924337387, -0.03833836689591408, 0.02502552606165409, 0.047595635056495667, 0.01415656041353941, -0.08196058124303818, 0.14629314839839935, -0.0027041451539844275, 0.013985303230583668, 0.013077259063720703, 0.02631109394133091, 0.045220840722322464, -0.06563017517328262, 0.08634136617183685, 0.11702810227870941, -0.015054845251142979, 0.05689821019768715, -0.11408776044845581, 0.008566021919250488, -0.0354786291718483, 0.11773239821195602, 0.031109608709812164, 0.09705779701471329, 0.06099044904112816, 0.05484660342335701, -0.026571443304419518, 0.07836160063743591, 0.0073626539669930935, 0.01591203734278679, -0.41622039675712585, -0.044378966093063354, 0.10610739141702652, 0.02976166643202305, 0.04332415759563446, 0.08006183058023453, 0.08639879524707794, 0.03835363686084747, 0.16853971779346466, -0.09577206522226334, 0.08403541147708893, 0.05219037085771561, 0.057484447956085205, -0.04671730473637581, 0.03364247828722, 0.0949440598487854, -0.07757590711116791, 0.01265070028603077, -0.031910933554172516, -0.07905452698469162, 0.0576203316450119, -0.04645417630672455, 0.26333898305892944, 0.08828013390302658, -0.012503623962402344, 0.0979386493563652, -0.0910850465297699, 0.05546789988875389, 0.05913625657558441, 0.15057730674743652, 0.1140417829155922, 0.04195962846279144, -0.13999530673027039, 0.04143723472952843, -0.005509537179023027, 0.22242894768714905, 0.024677233770489693, 10.422829627990723, -0.042720772325992584, 0.010859541594982147, -0.07942108064889908, 0.03722494840621948, -0.05481649190187454, -4.561505193123594e-05, -0.004445859231054783, 0.020231183618307114, 0.02472797967493534, 0.03717225790023804, -0.15551555156707764, -0.12585479021072388, 0.05883505940437317, -0.008324849419295788, 0.04440082237124443, 0.11226987838745117, -0.0185195691883564, 0.07357432693243027, 0.004869319032877684, -0.03605647012591362, 0.0847829282283783, 0.0924028754234314, -0.1863216906785965, -0.06464343518018723, 0.15355949103832245, -0.04714787006378174, -0.07501183450222015, -0.09460977464914322, 0.15171955525875092, -0.011954781599342823, 0.0717904269695282, 0.138118177652359, -0.006664672400802374, 0.16252192854881287, -0.11316292732954025, -0.20945923030376434, 0.10556238144636154, 0.12560628354549408, -0.11812566220760345, 0.09087588638067245, 0.0015716011403128505, 0.1516074389219284, 0.07810258120298386, 0.09599942713975906, 0.03620360046625137, 0.06661427021026611, 0.0987514853477478, 0.05280551686882973, -0.02081179991364479, 0.0796637311577797, 0.01846986822783947, 0.19482778012752533, -0.09223204106092453, -0.026531673967838287, -0.009814782999455929, 0.06325004249811172, 0.048447832465171814, -0.049115460366010666, 0.09956292062997818, 0.019620588049292564, -0.10671981424093246, 0.05895416811108589, -0.003011200111359358, -0.09618515521287918, 0.18286579847335815, 0.10816075652837753, 0.1521121859550476, 0.05168609693646431, 0.033887360244989395, 0.017737163230776787, -0.15399642288684845, 0.15079915523529053, -0.05765226110816002, 0.006069807801395655, 0.13133631646633148, 0.15262851119041443, -0.006312881596386433, 0.0886659324169159, -0.07674390077590942, 0.011662609875202179, 0.11873185634613037, -0.009354334324598312, -0.009728820994496346, -0.08173806965351105, 0.04954295977950096, -0.017560329288244247, 0.051502250134944916, 0.09369760006666183, -0.021092504262924194, -0.13293206691741943, -0.040177732706069946, -0.15470360219478607, -0.017964866012334824, 0.11630856990814209, -0.11901627480983734, 0.06361034512519836, -0.034324560314416885, 0.018225213512778282, -0.0665847435593605, -0.019633380696177483, 0.030487455427646637, 0.040959760546684265, 0.0888945534825325, -0.12072238326072693, 0.019094865769147873, -0.011990517377853394, 0.13928692042827606, -0.09803277999162674, 0.09659764170646667, -0.011383505538105965, 0.16047944128513336, 0.03467836230993271, -0.0011457710061222315, 0.07137086987495422, 0.014088841155171394, 0.00972374901175499, -0.0266871377825737, 0.16664449870586395, 0.1126883327960968, 0.03569589927792549, -0.021476278081536293, -0.08359524607658386, 0.029526440426707268, 0.09535524994134903, -0.045822687447071075, -0.015604455024003983, 0.0766773372888565, -0.0879632979631424, 0.09064574539661407, 0.037089765071868896, 0.033456772565841675, 0.06584393233060837, 0.04043500870466232, 0.018840519711375237, 0.03988976031541824, -0.012438824400305748, -0.009260383434593678, -0.004887188319116831, 0.1426273137331009, -0.1313297152519226, 0.06727529317140579, 0.08237870037555695, -0.0502774752676487, -0.013552814722061157, 0.12167003750801086, 0.09174845367670059, -0.0723753497004509, -0.001474956632591784, 0.03987102210521698, 0.19422440230846405, 0.2111361175775528, -0.1140318512916565, 0.045873213559389114, -0.05565734580159187, -0.017445605248212814, -0.05987457558512688, 0.14625535905361176, 0.07571305334568024, -0.09024166315793991, 0.15044642984867096, -0.11802367120981216, -0.012373060919344425, -0.0938556045293808, -0.09468629956245422, -0.01687915436923504, -0.04019320756196976, 0.07950843870639801, 0.09141755104064941, 0.074101522564888, 0.0017431628657504916, 0.013286896049976349, -0.282839834690094, -0.0519685298204422, -0.03611407056450844, 0.03586350008845329, 0.19246236979961395, -0.28780072927474976, -0.08283014595508575, -0.04279191046953201]\n",
      "tensor([-1.2561e-01,  6.4220e-02, -6.7388e-02, -4.8061e-02,  2.7138e-01, -1.4991e-01,  7.8765e-03, -1.2044e-02,  4.6624e-02, -1.3837e-01,  2.4973e-02, -2.1923e-02, -3.7160e-02, -1.3059e-01,\n",
      "        -7.0208e-02, -9.2608e-03,  4.4490e-02,  3.9585e-02, -1.6303e-02, -2.8625e-02, -1.0248e-01,  1.2490e-01,  1.0356e-01,  9.4474e-02,  9.8920e-02,  3.5897e-02,  1.1930e-01,  3.1564e-02,\n",
      "         1.5390e-01, -3.1594e-02, -1.0037e-01, -2.5524e-02,  7.7781e-02, -5.3618e-02, -2.0454e-02, -5.1781e-02,  7.0981e-02, -1.2935e-02, -1.3886e-02,  2.6556e-02, -1.0963e-01,  1.0161e-02,\n",
      "         1.6596e-01, -4.2970e-02,  3.6664e-02, -2.6050e-02,  1.3326e-01,  4.8544e-02,  3.9688e-02, -4.8335e-02, -5.6778e-02, -1.1131e-02,  1.2971e-03, -1.9836e-02, -1.9066e-02,  1.0597e-01,\n",
      "         4.3873e-02,  2.4308e-01,  2.7675e-02,  8.7192e-02,  2.3574e-02, -1.2971e-01, -7.8483e-03,  1.0572e-01,  7.4622e-02,  2.7052e-03, -1.0930e-02, -6.6157e-02,  1.1290e-02,  2.8398e-03,\n",
      "         9.0367e-02,  2.7806e-02, -8.4877e-03, -9.3641e-02,  2.0758e-03, -2.6427e-02,  1.7260e-01,  2.2790e-01, -8.1002e-02,  1.0034e-01,  3.4622e-03, -7.3401e-02,  6.3887e-02,  1.3918e-01,\n",
      "         1.0534e-01, -6.9255e-02,  7.7194e-02,  2.8370e-02, -9.0844e-02,  7.5746e-02,  8.4847e-03,  1.0973e-01,  5.5260e-02,  1.0798e-01,  3.4147e-02, -3.7161e-02,  1.8096e-02, -2.1346e-01,\n",
      "         6.9416e-03,  4.1262e-02, -6.4646e-02, -1.4369e-02, -1.6615e-01, -6.0585e-02,  3.8496e-02,  4.3554e-02,  7.9220e-02,  2.3147e-02,  5.9264e-02,  2.5323e-03, -8.3112e-02,  4.5580e-02,\n",
      "        -1.9686e-02,  4.9914e-02,  8.4036e-02, -6.1818e-02, -1.0028e-02,  4.2213e-02,  8.9947e-02,  3.8140e-02,  3.6039e-02, -3.8893e-02,  1.2256e-01,  7.7372e-02, -8.1787e-03,  1.4850e-01,\n",
      "         6.8547e-02, -8.6604e-03, -4.1924e-02,  5.7174e-02,  2.7339e-02, -3.0813e-01,  1.1763e-01, -5.2001e-04,  9.2581e-02,  5.5880e-02, -9.2308e-02,  1.6311e-02, -7.4921e-02, -3.6655e-02,\n",
      "         9.7446e-02, -1.4870e-02,  1.6436e-03, -5.2025e-02,  5.0011e-02,  9.4717e-02, -1.2191e-02,  9.9752e-02, -1.5758e-01, -7.4526e-02,  1.0590e-01, -3.9466e-02,  4.4856e-02,  6.9870e-02,\n",
      "        -1.4387e-01,  2.8584e-01,  1.5835e-01, -2.4891e-02, -8.8630e-02,  6.1002e-02,  3.6352e-02, -4.4550e-02, -5.2457e-02,  6.8653e-02, -1.8391e-04, -6.8920e-02, -2.9444e-02,  4.4202e-02,\n",
      "         7.4168e-02, -1.7757e-02,  9.2454e-02, -3.5568e-02, -1.8902e-02,  2.7169e-02,  5.3885e-02,  8.9838e-02, -7.8488e-02,  4.1575e-02, -1.2383e-01, -1.3853e-02,  3.0094e-02,  6.0834e-02,\n",
      "        -8.7729e-02, -1.1178e-02,  9.3983e-02, -3.1431e-02,  4.1545e-02, -4.4264e-02,  8.0739e-02, -1.1525e-01,  2.1352e-02,  1.8986e-02,  9.3989e-02, -5.7919e-02,  2.8327e-02,  1.6643e-01,\n",
      "        -3.6497e-02, -6.6986e-02,  1.4525e-01,  1.7288e-02, -8.7046e-02, -6.3948e-02,  3.7024e-02, -3.7406e-03,  1.6563e-01,  7.3864e-02, -1.2177e-01, -2.4376e-02, -7.1526e-02, -1.3532e-02,\n",
      "        -1.1381e-02,  9.8037e-02, -3.2202e-03, -6.8434e-02,  5.6444e-02, -1.0579e-01, -7.8224e-02,  7.0013e-03, -3.6798e-02, -6.6206e-02,  1.2337e-01,  5.6120e-02, -1.2230e-01, -3.7817e-02,\n",
      "         4.1857e-02,  9.4285e-02,  8.3879e-02,  1.1263e-01, -3.2199e-02, -1.0553e-02, -7.1826e-02,  4.5615e-02, -1.1825e-01,  7.1215e-02,  9.7945e-02, -2.4661e-01,  8.2822e-02, -3.3409e-02,\n",
      "         6.2087e-02, -8.4748e-02, -2.0098e-02,  6.1469e-03,  5.7424e-02,  2.0892e-02,  1.1189e-02,  7.1262e-02,  7.6718e-02,  1.7053e-01, -7.4395e-02,  1.1755e-03, -8.5287e-02, -7.6746e-02,\n",
      "        -7.1738e-02,  2.5097e-02,  1.1338e-02,  4.3051e-02,  2.8913e-02, -3.0663e-02, -5.4471e-02,  5.9123e-02, -3.7471e-02,  2.5504e-02, -6.3021e-02,  8.6789e-02, -3.6142e-02, -1.7533e-01,\n",
      "        -1.4904e-02, -2.9742e-02,  4.0262e-02,  6.7817e-02,  2.6416e-02, -6.2689e-02,  4.1674e-02,  3.8667e-02, -2.1125e-02,  5.6780e-02, -1.1297e-01, -1.8737e-02,  3.6520e-03, -5.4233e-02,\n",
      "        -1.1799e-02,  1.0831e-01, -1.4497e-01,  9.7390e-02,  1.5160e-02, -1.3258e-01,  2.9608e-02,  1.5261e-02,  8.8005e-03,  4.3482e-02, -2.1975e-02,  7.2674e-02, -5.1952e-02,  6.0339e-02,\n",
      "         2.0072e-02,  2.5544e-02,  1.3880e-02, -6.1862e-02, -2.2230e-02, -1.0108e-01, -1.3697e-02, -1.8401e-01,  3.6349e-02, -1.0606e-01,  8.5618e-02, -4.0340e-02,  6.8986e-02,  7.3010e-02,\n",
      "         1.3704e-01, -3.8567e-02, -3.0645e-02,  7.4490e-02, -6.6295e-02, -1.3615e-02, -5.1519e-02,  8.2460e-02, -1.5771e-01,  4.8277e-02, -5.4230e-02,  6.0272e-02,  2.0507e-02,  6.3568e-02,\n",
      "         5.2063e-02, -9.8458e-02, -4.7142e-02,  1.7081e-01,  9.2742e-02, -5.1218e-02, -1.7084e-02,  2.7112e-01, -2.3142e-01,  2.3359e-02, -1.5011e-02,  3.9575e-02,  1.2654e-01, -3.4547e-02,\n",
      "         1.2127e-01,  2.5677e-02,  1.5923e-01,  1.3203e-01,  3.0054e-02, -3.3376e-02, -8.0926e-02, -6.2358e-03, -3.7252e-02, -1.3034e-02,  7.5594e-02, -6.3456e-02, -2.1194e-02,  1.4446e-02,\n",
      "        -8.5137e-02,  1.2790e-01, -7.4891e-02, -1.0509e-01, -2.3497e-03,  1.5493e-01, -4.4070e-02,  3.3732e-02,  1.2789e-02,  2.5793e-02, -1.2267e-01,  1.0794e-01, -3.7477e-02, -1.2325e-01,\n",
      "         2.5254e-01, -2.6772e-01, -1.6652e-01,  2.8346e-02, -2.1083e-02,  8.5740e-02,  1.0446e-01,  1.5200e-01,  3.1595e-02, -8.1541e-02, -2.9721e-02,  2.3119e-02, -3.9852e-02,  1.0675e-01,\n",
      "         5.2988e-02,  8.7091e-02,  3.2217e-02,  7.7747e-02,  1.0481e-01,  1.1206e-01,  1.2998e-01, -9.5548e-02,  5.6087e-02,  6.1189e-02,  7.6704e-02,  7.9029e-02,  8.1829e-02, -3.2880e-02,\n",
      "         4.2828e-02,  9.4280e-03,  4.8050e-02,  7.1810e-02, -8.8858e-03,  1.3521e-01, -1.9118e-01, -4.6091e-02, -2.3566e-02,  4.0528e-02, -3.2613e-02,  5.9110e-04,  7.2834e-02,  1.0309e-01,\n",
      "        -6.2965e-02, -1.2821e-02,  2.4113e-02, -1.2174e-01, -3.1291e-02,  8.8717e-02, -1.6478e-02, -5.9320e-04,  4.0747e-02, -3.0884e-02, -1.7169e-02, -1.1514e-01, -4.1734e-02,  3.0668e-02,\n",
      "         1.2128e-01,  1.0020e-01, -5.9221e-02, -1.8233e-02, -5.8121e-02,  6.4737e-02, -8.1459e-02, -1.2952e-01, -5.8291e-02,  7.2784e-02, -4.2963e-02, -1.2245e-02, -6.3936e-02,  5.1041e-02,\n",
      "         7.2444e-02, -9.0671e-02, -2.0174e-03,  3.6588e-02, -1.8958e-02, -1.0264e-01,  3.0564e-02, -8.9183e-02, -6.9523e-02,  1.2685e-01,  4.9744e-02, -1.1890e-01,  1.7179e-01, -2.7233e-02,\n",
      "        -1.8490e-02,  9.5125e-02, -1.3248e-01,  8.3115e-02,  1.6006e-01, -4.6312e-01,  1.2618e-01,  6.7407e-02,  2.9819e-02, -2.3923e-02, -3.0265e-02, -8.4570e-02,  1.4786e-02,  3.4606e-02,\n",
      "        -1.5361e-03, -1.8844e-02,  7.2624e-02,  3.8389e-02, -9.9869e-03, -5.5871e-02,  5.9000e-02,  6.4766e-03,  1.4821e-01,  8.7043e-02, -4.2831e-02, -9.8632e-02, -3.9914e-02,  2.3059e-02,\n",
      "        -7.5571e-02, -1.6423e-01,  1.9970e-02, -9.0852e-02, -1.0849e-01,  6.6586e-02,  7.5310e-02,  2.3831e-02, -2.7932e-02,  3.1204e-02, -2.8647e-02, -1.5150e-02,  9.1875e-03, -2.1511e-02,\n",
      "        -1.6924e-01,  2.8379e-02, -7.3528e-02,  7.2112e-02,  2.3345e-01,  6.8459e-02, -4.4876e-02,  4.0558e-02,  8.1368e-02, -7.7817e-02,  7.6657e-02,  4.3375e-02,  5.2491e-02, -6.5650e-02,\n",
      "         3.2093e-02,  4.1517e-02, -9.3381e-02,  6.3770e-02, -1.0847e-01,  2.6474e-02,  3.3146e-02, -5.5776e-03,  5.8358e-02,  8.1348e-02,  5.4787e-02, -1.9482e-02,  2.2621e-02,  5.2654e-02,\n",
      "         3.0112e-02, -4.9402e-02,  5.3808e-02, -4.5289e-02,  1.0431e-02, -3.8338e-02,  2.5026e-02,  4.7596e-02,  1.4157e-02, -8.1961e-02,  1.4629e-01, -2.7041e-03,  1.3985e-02,  1.3077e-02,\n",
      "         2.6311e-02,  4.5221e-02, -6.5630e-02,  8.6341e-02,  1.1703e-01, -1.5055e-02,  5.6898e-02, -1.1409e-01,  8.5660e-03, -3.5479e-02,  1.1773e-01,  3.1110e-02,  9.7058e-02,  6.0990e-02,\n",
      "         5.4847e-02, -2.6571e-02,  7.8362e-02,  7.3627e-03,  1.5912e-02, -4.1622e-01, -4.4379e-02,  1.0611e-01,  2.9762e-02,  4.3324e-02,  8.0062e-02,  8.6399e-02,  3.8354e-02,  1.6854e-01,\n",
      "        -9.5772e-02,  8.4035e-02,  5.2190e-02,  5.7484e-02, -4.6717e-02,  3.3642e-02,  9.4944e-02, -7.7576e-02,  1.2651e-02, -3.1911e-02, -7.9055e-02,  5.7620e-02, -4.6454e-02,  2.6334e-01,\n",
      "         8.8280e-02, -1.2504e-02,  9.7939e-02, -9.1085e-02,  5.5468e-02,  5.9136e-02,  1.5058e-01,  1.1404e-01,  4.1960e-02, -1.4000e-01,  4.1437e-02, -5.5095e-03,  2.2243e-01,  2.4677e-02,\n",
      "         1.0423e+01, -4.2721e-02,  1.0860e-02, -7.9421e-02,  3.7225e-02, -5.4816e-02, -4.5615e-05, -4.4459e-03,  2.0231e-02,  2.4728e-02,  3.7172e-02, -1.5552e-01, -1.2585e-01,  5.8835e-02,\n",
      "        -8.3248e-03,  4.4401e-02,  1.1227e-01, -1.8520e-02,  7.3574e-02,  4.8693e-03, -3.6056e-02,  8.4783e-02,  9.2403e-02, -1.8632e-01, -6.4643e-02,  1.5356e-01, -4.7148e-02, -7.5012e-02,\n",
      "        -9.4610e-02,  1.5172e-01, -1.1955e-02,  7.1790e-02,  1.3812e-01, -6.6647e-03,  1.6252e-01, -1.1316e-01, -2.0946e-01,  1.0556e-01,  1.2561e-01, -1.1813e-01,  9.0876e-02,  1.5716e-03,\n",
      "         1.5161e-01,  7.8103e-02,  9.5999e-02,  3.6204e-02,  6.6614e-02,  9.8751e-02,  5.2806e-02, -2.0812e-02,  7.9664e-02,  1.8470e-02,  1.9483e-01, -9.2232e-02, -2.6532e-02, -9.8148e-03,\n",
      "         6.3250e-02,  4.8448e-02, -4.9115e-02,  9.9563e-02,  1.9621e-02, -1.0672e-01,  5.8954e-02, -3.0112e-03, -9.6185e-02,  1.8287e-01,  1.0816e-01,  1.5211e-01,  5.1686e-02,  3.3887e-02,\n",
      "         1.7737e-02, -1.5400e-01,  1.5080e-01, -5.7652e-02,  6.0698e-03,  1.3134e-01,  1.5263e-01, -6.3129e-03,  8.8666e-02, -7.6744e-02,  1.1663e-02,  1.1873e-01, -9.3543e-03, -9.7288e-03,\n",
      "        -8.1738e-02,  4.9543e-02, -1.7560e-02,  5.1502e-02,  9.3698e-02, -2.1093e-02, -1.3293e-01, -4.0178e-02, -1.5470e-01, -1.7965e-02,  1.1631e-01, -1.1902e-01,  6.3610e-02, -3.4325e-02,\n",
      "         1.8225e-02, -6.6585e-02, -1.9633e-02,  3.0487e-02,  4.0960e-02,  8.8895e-02, -1.2072e-01,  1.9095e-02, -1.1991e-02,  1.3929e-01, -9.8033e-02,  9.6598e-02, -1.1384e-02,  1.6048e-01,\n",
      "         3.4678e-02, -1.1458e-03,  7.1371e-02,  1.4089e-02,  9.7237e-03, -2.6687e-02,  1.6664e-01,  1.1269e-01,  3.5696e-02, -2.1476e-02, -8.3595e-02,  2.9526e-02,  9.5355e-02, -4.5823e-02,\n",
      "        -1.5604e-02,  7.6677e-02, -8.7963e-02,  9.0646e-02,  3.7090e-02,  3.3457e-02,  6.5844e-02,  4.0435e-02,  1.8841e-02,  3.9890e-02, -1.2439e-02, -9.2604e-03, -4.8872e-03,  1.4263e-01,\n",
      "        -1.3133e-01,  6.7275e-02,  8.2379e-02, -5.0277e-02, -1.3553e-02,  1.2167e-01,  9.1748e-02, -7.2375e-02, -1.4750e-03,  3.9871e-02,  1.9422e-01,  2.1114e-01, -1.1403e-01,  4.5873e-02,\n",
      "        -5.5657e-02, -1.7446e-02, -5.9875e-02,  1.4626e-01,  7.5713e-02, -9.0242e-02,  1.5045e-01, -1.1802e-01, -1.2373e-02, -9.3856e-02, -9.4686e-02, -1.6879e-02, -4.0193e-02,  7.9508e-02,\n",
      "         9.1418e-02,  7.4102e-02,  1.7432e-03,  1.3287e-02, -2.8284e-01, -5.1969e-02, -3.6114e-02,  3.5864e-02,  1.9246e-01, -2.8780e-01, -8.2830e-02, -4.2792e-02])\n",
      "768\n",
      "768\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "print(embedding_output[0][0])\n",
    "print(last_hidden_state.squeeze()[0, :])\n",
    "print(len(embedding_output[0][0]))\n",
    "print(len(last_hidden_state.squeeze()[0, :]))\n",
    "print(last_hidden_state.squeeze()[0, :] == embedding_output[0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cosine matrix ##\n",
    "Checking the cosine matrix between embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def last_hidden_layers(tokenizer, model, sentence_list):\n",
    "    last_hidden_states, sentence_embeddings = list(), list()\n",
    "    with torch.no_grad():\n",
    "        for s in sentence_list:\n",
    "            tokens = tokenizer(s, return_tensors='pt', padding=True, truncation=True)\n",
    "            output = model(**tokens, output_hidden_states=True)\n",
    "            last_hidden_state = output.hidden_states[-1]\n",
    "            last_hidden_states.append(last_hidden_state)\n",
    "            sentence_embeddings.append(last_hidden_state.squeeze()[0, :])\n",
    "    return last_hidden_states, sentence_embeddings\n",
    "\n",
    "def calc_cosine_sim_matrix(sentence_embeddings):\n",
    "    stacked_sentence_embeddings = torch.stack(sentence_embeddings)\n",
    "    # Calculate the cosine similarity matrix\n",
    "    cosine_sim_matrix = F.cosine_similarity(stacked_sentence_embeddings.unsqueeze(1), stacked_sentence_embeddings.unsqueeze(0), dim=2)\n",
    "    return stacked_sentence_embeddings, cosine_sim_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([9, 768])\n",
      "tensor([[1.0000, 0.9866, 0.9625, 0.9575, 0.3582, 0.5197, 0.5173, 0.5045, 0.4987],\n",
      "        [0.9866, 1.0000, 0.9430, 0.9640, 0.3649, 0.5329, 0.5076, 0.4981, 0.5171],\n",
      "        [0.9625, 0.9430, 1.0000, 0.9868, 0.3074, 0.5465, 0.5548, 0.4700, 0.4553],\n",
      "        [0.9575, 0.9640, 0.9868, 1.0000, 0.3147, 0.5630, 0.5479, 0.4679, 0.4772],\n",
      "        [0.3582, 0.3649, 0.3074, 0.3147, 1.0000, 0.2991, 0.2910, 0.3350, 0.3374],\n",
      "        [0.5197, 0.5329, 0.5465, 0.5630, 0.2991, 1.0000, 0.9799, 0.8998, 0.9070],\n",
      "        [0.5173, 0.5076, 0.5548, 0.5479, 0.2910, 0.9799, 1.0000, 0.9021, 0.8684],\n",
      "        [0.5045, 0.4981, 0.4700, 0.4679, 0.3350, 0.8998, 0.9021, 1.0000, 0.9764],\n",
      "        [0.4987, 0.5171, 0.4553, 0.4772, 0.3374, 0.9070, 0.8684, 0.9764, 1.0000]])\n"
     ]
    }
   ],
   "source": [
    "last_hidden_states, sentence_embeddings = last_hidden_layers(tokenizer1, full_model1, sentence_list)\n",
    "stacked_sentence_embeddings, cosine_sim_matrix = calc_cosine_sim_matrix(sentence_embeddings)\n",
    "print(stacked_sentence_embeddings.size())\n",
    "print(cosine_sim_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More tests ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence1_base = \"A <SizeModifier> <AbnormalReport> can be seen in the report in the <LocationModifier> part\"\n",
    "sentence2_base = \"The report shows a <SizeModifier> <LocationModifier> <AbnormalReport>\"\n",
    "size_modifiers = ['small', 'large']\n",
    "loc_modifiers = ['upper-left', 'lower-left', 'right-sided', 'left-sided']\n",
    "abnormal_report = ['pleural effusion']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "l1 = [sentence1_base.replace('<SizeModifier>', size_mod).replace('<LocationModifier>', loc_mod).replace('<AbnormalReport>', ab_rep) for size_mod, loc_mod, ab_rep in product(size_modifiers, loc_modifiers, abnormal_report)]\n",
    "l2 = [sentence2_base.replace('<SizeModifier>', size_mod).replace('<LocationModifier>', loc_mod).replace('<AbnormalReport>', ab_rep) for size_mod, loc_mod, ab_rep in product(size_modifiers, loc_modifiers, abnormal_report)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A small pleural effusion can be seen in the report in the upper-left part\n",
      "A small pleural effusion can be seen in the report in the lower-left part\n",
      "A small pleural effusion can be seen in the report in the right-sided part\n",
      "A small pleural effusion can be seen in the report in the left-sided part\n",
      "A large pleural effusion can be seen in the report in the upper-left part\n",
      "A large pleural effusion can be seen in the report in the lower-left part\n",
      "A large pleural effusion can be seen in the report in the right-sided part\n",
      "A large pleural effusion can be seen in the report in the left-sided part\n",
      "The report shows a small upper-left pleural effusion\n",
      "The report shows a small lower-left pleural effusion\n",
      "The report shows a small right-sided pleural effusion\n",
      "The report shows a small left-sided pleural effusion\n",
      "The report shows a large upper-left pleural effusion\n",
      "The report shows a large lower-left pleural effusion\n",
      "The report shows a large right-sided pleural effusion\n",
      "The report shows a large left-sided pleural effusion\n"
     ]
    }
   ],
   "source": [
    "print('\\n'.join(l1))\n",
    "print('\\n'.join(l2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 768])\n",
      "tensor([[1.0000, 0.9939, 0.9738, 0.9727, 0.9814, 0.9744, 0.9425, 0.9432, 0.8992, 0.8797, 0.8318, 0.8322, 0.8439, 0.8331, 0.7636, 0.7699],\n",
      "        [0.9939, 1.0000, 0.9759, 0.9767, 0.9770, 0.9818, 0.9459, 0.9482, 0.8996, 0.8961, 0.8391, 0.8415, 0.8439, 0.8480, 0.7703, 0.7784],\n",
      "        [0.9738, 0.9759, 1.0000, 0.9968, 0.9687, 0.9695, 0.9813, 0.9795, 0.8847, 0.8746, 0.8635, 0.8601, 0.8470, 0.8439, 0.8092, 0.8116],\n",
      "        [0.9727, 0.9767, 0.9968, 1.0000, 0.9668, 0.9695, 0.9773, 0.9818, 0.8878, 0.8799, 0.8624, 0.8694, 0.8481, 0.8477, 0.8057, 0.8180],\n",
      "        [0.9814, 0.9770, 0.9687, 0.9668, 1.0000, 0.9940, 0.9737, 0.9731, 0.8973, 0.8792, 0.8337, 0.8317, 0.8862, 0.8733, 0.8094, 0.8125],\n",
      "        [0.9744, 0.9818, 0.9695, 0.9695, 0.9940, 1.0000, 0.9754, 0.9765, 0.8964, 0.8942, 0.8399, 0.8401, 0.8845, 0.8870, 0.8148, 0.8199],\n",
      "        [0.9425, 0.9459, 0.9813, 0.9773, 0.9737, 0.9754, 1.0000, 0.9968, 0.8718, 0.8631, 0.8545, 0.8488, 0.8784, 0.8734, 0.8460, 0.8449],\n",
      "        [0.9432, 0.9482, 0.9795, 0.9818, 0.9731, 0.9765, 0.9968, 1.0000, 0.8762, 0.8696, 0.8547, 0.8591, 0.8804, 0.8780, 0.8432, 0.8521],\n",
      "        [0.8992, 0.8996, 0.8847, 0.8878, 0.8973, 0.8964, 0.8718, 0.8762, 1.0000, 0.9825, 0.9404, 0.9401, 0.9628, 0.9537, 0.8871, 0.8946],\n",
      "        [0.8797, 0.8961, 0.8746, 0.8799, 0.8792, 0.8942, 0.8631, 0.8696, 0.9825, 1.0000, 0.9332, 0.9351, 0.9441, 0.9671, 0.8789, 0.8877],\n",
      "        [0.8318, 0.8391, 0.8635, 0.8624, 0.8337, 0.8399, 0.8545, 0.8547, 0.9404, 0.9332, 1.0000, 0.9882, 0.9211, 0.9199, 0.9574, 0.9542],\n",
      "        [0.8322, 0.8415, 0.8601, 0.8694, 0.8317, 0.8401, 0.8488, 0.8591, 0.9401, 0.9351, 0.9882, 1.0000, 0.9162, 0.9183, 0.9403, 0.9592],\n",
      "        [0.8439, 0.8439, 0.8470, 0.8481, 0.8862, 0.8845, 0.8784, 0.8804, 0.9628, 0.9441, 0.9211, 0.9162, 1.0000, 0.9837, 0.9422, 0.9438],\n",
      "        [0.8331, 0.8480, 0.8439, 0.8477, 0.8733, 0.8870, 0.8734, 0.8780, 0.9537, 0.9671, 0.9199, 0.9183, 0.9837, 1.0000, 0.9348, 0.9388],\n",
      "        [0.7636, 0.7703, 0.8092, 0.8057, 0.8094, 0.8148, 0.8460, 0.8432, 0.8871, 0.8789, 0.9574, 0.9403, 0.9422, 0.9348, 1.0000, 0.9890],\n",
      "        [0.7699, 0.7784, 0.8116, 0.8180, 0.8125, 0.8199, 0.8449, 0.8521, 0.8946, 0.8877, 0.9542, 0.9592, 0.9438, 0.9388, 0.9890, 1.0000]])\n"
     ]
    }
   ],
   "source": [
    "last_hidden_states2, sentence_embeddings2 = last_hidden_layers(tokenizer1, full_model1, l1 + l2)\n",
    "stacked_sentence_embeddings2, cosine_sim_matrix2 = calc_cosine_sim_matrix(sentence_embeddings2)\n",
    "print(stacked_sentence_embeddings2.size())\n",
    "print(cosine_sim_matrix2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A small pleural effusion can be seen in the report in the upper-left part\n",
      "A small pleural effusion can be seen in the report in the lower-left part\n",
      "A small pleural effusion can be seen in the report in the right-sided part\n",
      "A small pleural effusion can be seen in the report in the left-sided part\n",
      "A large pleural effusion can be seen in the report in the upper-left part\n",
      "A large pleural effusion can be seen in the report in the lower-left part\n",
      "A large pleural effusion can be seen in the report in the right-sided part\n",
      "A large pleural effusion can be seen in the report in the left-sided part\n",
      "The report shows a small upper-left pleural effusion\n",
      "The report shows a small lower-left pleural effusion\n",
      "The report shows a small right-sided pleural effusion\n",
      "The report shows a small left-sided pleural effusion\n",
      "The report shows a large upper-left pleural effusion\n",
      "The report shows a large lower-left pleural effusion\n",
      "The report shows a large right-sided pleural effusion\n",
      "The report shows a large left-sided pleural effusion\n",
      "The report shows no pleural effusion\n",
      "The report shows no consolidation on any side\n",
      "There are no abnormalities in the report\n",
      "There is severe consolidation in the left side\n",
      "There is severe consolidation in the right side\n",
      "There is mild consolidation in the right side\n",
      "There is mild consolidation in the left side\n"
     ]
    }
   ],
   "source": [
    "negative_sentences = ['The report shows no pleural effusion', 'The report shows no consolidation on any side']\n",
    "all_sentence_list = l1 + l2 + negative_sentences + sentence_list[4:]\n",
    "print('\\n'.join(all_sentence_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([23, 768])\n",
      "tensor([[1.0000, 0.9939, 0.9738, 0.9727, 0.9814, 0.9744, 0.9425, 0.9432, 0.8992, 0.8797, 0.8318, 0.8322, 0.8439, 0.8331, 0.7636, 0.7699, 0.8136, 0.6586, 0.4369, 0.5004, 0.5003, 0.5375, 0.5245],\n",
      "        [0.9939, 1.0000, 0.9759, 0.9767, 0.9770, 0.9818, 0.9459, 0.9482, 0.8996, 0.8961, 0.8391, 0.8415, 0.8439, 0.8480, 0.7703, 0.7784, 0.8132, 0.6683, 0.4246, 0.5137, 0.5105, 0.5444, 0.5356],\n",
      "        [0.9738, 0.9759, 1.0000, 0.9968, 0.9687, 0.9695, 0.9813, 0.9795, 0.8847, 0.8746, 0.8635, 0.8601, 0.8470, 0.8439, 0.8092, 0.8116, 0.8138, 0.6488, 0.4411, 0.5290, 0.5307, 0.5475, 0.5339],\n",
      "        [0.9727, 0.9767, 0.9968, 1.0000, 0.9668, 0.9695, 0.9773, 0.9818, 0.8878, 0.8799, 0.8624, 0.8694, 0.8481, 0.8477, 0.8057, 0.8180, 0.8114, 0.6476, 0.4408, 0.5408, 0.5315, 0.5489, 0.5474],\n",
      "        [0.9814, 0.9770, 0.9687, 0.9668, 1.0000, 0.9940, 0.9737, 0.9731, 0.8973, 0.8792, 0.8337, 0.8317, 0.8862, 0.8733, 0.8094, 0.8125, 0.7998, 0.6732, 0.4113, 0.5479, 0.5546, 0.5371, 0.5188],\n",
      "        [0.9744, 0.9818, 0.9695, 0.9695, 0.9940, 1.0000, 0.9754, 0.9765, 0.8964, 0.8942, 0.8399, 0.8401, 0.8845, 0.8870, 0.8148, 0.8199, 0.7985, 0.6820, 0.3983, 0.5594, 0.5625, 0.5416, 0.5281],\n",
      "        [0.9425, 0.9459, 0.9813, 0.9773, 0.9737, 0.9754, 1.0000, 0.9968, 0.8718, 0.8631, 0.8545, 0.8488, 0.8784, 0.8734, 0.8460, 0.8449, 0.7927, 0.6565, 0.4108, 0.5689, 0.5780, 0.5380, 0.5190],\n",
      "        [0.9432, 0.9482, 0.9795, 0.9818, 0.9731, 0.9765, 0.9968, 1.0000, 0.8762, 0.8696, 0.8547, 0.8591, 0.8804, 0.8780, 0.8432, 0.8521, 0.7905, 0.6561, 0.4116, 0.5810, 0.5788, 0.5402, 0.5331],\n",
      "        [0.8992, 0.8996, 0.8847, 0.8878, 0.8973, 0.8964, 0.8718, 0.8762, 1.0000, 0.9825, 0.9404, 0.9401, 0.9628, 0.9537, 0.8871, 0.8946, 0.8474, 0.6004, 0.3772, 0.5114, 0.5069, 0.5136, 0.5091],\n",
      "        [0.8797, 0.8961, 0.8746, 0.8799, 0.8792, 0.8942, 0.8631, 0.8696, 0.9825, 1.0000, 0.9332, 0.9351, 0.9441, 0.9671, 0.8789, 0.8877, 0.8358, 0.6151, 0.3557, 0.5316, 0.5216, 0.5219, 0.5249],\n",
      "        [0.8318, 0.8391, 0.8635, 0.8624, 0.8337, 0.8399, 0.8545, 0.8547, 0.9404, 0.9332, 1.0000, 0.9882, 0.9211, 0.9199, 0.9574, 0.9542, 0.8025, 0.5280, 0.3656, 0.5281, 0.5283, 0.5294, 0.5198],\n",
      "        [0.8322, 0.8415, 0.8601, 0.8694, 0.8317, 0.8401, 0.8488, 0.8591, 0.9401, 0.9351, 0.9882, 1.0000, 0.9162, 0.9183, 0.9403, 0.9592, 0.8000, 0.5225, 0.3721, 0.5409, 0.5197, 0.5240, 0.5377],\n",
      "        [0.8439, 0.8439, 0.8470, 0.8481, 0.8862, 0.8845, 0.8784, 0.8804, 0.9628, 0.9441, 0.9211, 0.9162, 1.0000, 0.9837, 0.9422, 0.9438, 0.7925, 0.5721, 0.3280, 0.5514, 0.5567, 0.4876, 0.4754],\n",
      "        [0.8331, 0.8480, 0.8439, 0.8477, 0.8733, 0.8870, 0.8734, 0.8780, 0.9537, 0.9671, 0.9199, 0.9183, 0.9837, 1.0000, 0.9348, 0.9388, 0.7905, 0.5899, 0.3139, 0.5664, 0.5643, 0.4930, 0.4898],\n",
      "        [0.7636, 0.7703, 0.8092, 0.8057, 0.8094, 0.8148, 0.8460, 0.8432, 0.8871, 0.8789, 0.9574, 0.9403, 0.9422, 0.9348, 1.0000, 0.9890, 0.7427, 0.5037, 0.3163, 0.5592, 0.5705, 0.4918, 0.4732],\n",
      "        [0.7699, 0.7784, 0.8116, 0.8180, 0.8125, 0.8199, 0.8449, 0.8521, 0.8946, 0.8877, 0.9542, 0.9592, 0.9438, 0.9388, 0.9890, 1.0000, 0.7440, 0.5016, 0.3240, 0.5753, 0.5652, 0.4914, 0.4951],\n",
      "        [0.8136, 0.8132, 0.8138, 0.8114, 0.7998, 0.7985, 0.7927, 0.7905, 0.8474, 0.8358, 0.8025, 0.8000, 0.7925, 0.7905, 0.7427, 0.7440, 1.0000, 0.6408, 0.4393, 0.3999, 0.3991, 0.4104, 0.4076],\n",
      "        [0.6586, 0.6683, 0.6488, 0.6476, 0.6732, 0.6820, 0.6565, 0.6561, 0.6004, 0.6151, 0.5280, 0.5225, 0.5721, 0.5899, 0.5037, 0.5016, 0.6408, 1.0000, 0.4814, 0.5880, 0.5871, 0.5658, 0.5556],\n",
      "        [0.4369, 0.4246, 0.4411, 0.4408, 0.4113, 0.3983, 0.4108, 0.4116, 0.3772, 0.3557, 0.3656, 0.3721, 0.3280, 0.3139, 0.3163, 0.3240, 0.4393, 0.4814, 1.0000, 0.2991, 0.2910, 0.3350, 0.3374],\n",
      "        [0.5004, 0.5137, 0.5290, 0.5408, 0.5479, 0.5594, 0.5689, 0.5810, 0.5114, 0.5316, 0.5281, 0.5409, 0.5514, 0.5664, 0.5592, 0.5753, 0.3999, 0.5880, 0.2991, 1.0000, 0.9799, 0.8998, 0.9070],\n",
      "        [0.5003, 0.5105, 0.5307, 0.5315, 0.5546, 0.5625, 0.5780, 0.5788, 0.5069, 0.5216, 0.5283, 0.5197, 0.5567, 0.5643, 0.5705, 0.5652, 0.3991, 0.5871, 0.2910, 0.9799, 1.0000, 0.9021, 0.8684],\n",
      "        [0.5375, 0.5444, 0.5475, 0.5489, 0.5371, 0.5416, 0.5380, 0.5402, 0.5136, 0.5219, 0.5294, 0.5240, 0.4876, 0.4930, 0.4918, 0.4914, 0.4104, 0.5658, 0.3350, 0.8998, 0.9021, 1.0000, 0.9764],\n",
      "        [0.5245, 0.5356, 0.5339, 0.5474, 0.5188, 0.5281, 0.5190, 0.5331, 0.5091, 0.5249, 0.5198, 0.5377, 0.4754, 0.4898, 0.4732, 0.4951, 0.4076, 0.5556, 0.3374, 0.9070, 0.8684, 0.9764, 1.0000]])\n"
     ]
    }
   ],
   "source": [
    "last_hidden_states3, sentence_embeddings3 = last_hidden_layers(tokenizer1, full_model1, all_sentence_list)\n",
    "stacked_sentence_embeddings3, cosine_sim_matrix3 = calc_cosine_sim_matrix(sentence_embeddings3)\n",
    "print(stacked_sentence_embeddings3.size())\n",
    "print(cosine_sim_matrix3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysing Cleaned Report Dataset ##\n",
    "\n",
    "The cleaned data is stored in /models_common_e2e/data/cxr_data/text_reports_cleaned. A sample data is as follows:\n",
    "\n",
    "### File: ca.phase2.unit1.f1.ff5fe73b057f0093a1f5d32a281dd63c2255eaa60aa518c3b909e1a5.txt ###\n",
    "\n",
    "```\n",
    " xr- chest pa  view\n",
    " findings\n",
    " lungs: normal.\n",
    " trachea: normal.\n",
    " carina: normal.\n",
    " right and left main bronchi: normal.\n",
    " pleura: normal.\n",
    " heart: normal.\n",
    " right heart border: normal.\n",
    " left heart border: normal.\n",
    " pulmonary bay: normal.\n",
    " pulmonary hila: normal.\n",
    " aorta: normal.\n",
    " thoracic spine: normal.\n",
    " other visualized bones: normal.\n",
    " visualized soft tissues: normal.\n",
    " diaphragm: normal.\n",
    " visualized abdomen:  normal.\n",
    " visualized neck: normal.\n",
    "```\n",
    "\n",
    "### File max.dev3.106027018.txt ###\n",
    "\n",
    "```\n",
    "6191206|3862169|x-ray chest pa/ap view of 09-feb-2018:\n",
    "results:\n",
    "post cabg status.\n",
    "no focal lesion seen in the lung parenchyma.\n",
    "cp angles and domes of the diaphragm are normal.\n",
    "both hila are normal. pulmonary vasculature is normal.\n",
    "cardiac size and configuration is normal.\n",
    "trachea is central; no mediastinal shift is seen.\n",
    "bony thorax and soft tissues of the chest wall are normal.\n",
    "impression: no abnormality detected in the view obtained.\n",
    "```\n",
    "\n",
    "### File medall.1.2.826.0.1.3680043.8.437.1.2.2.0.7744.1446378402.18241.txt###\n",
    "```\n",
    "x-ray chest (pa view)\n",
    "the cardio thoracic ratio is normal.\n",
    "the heart size and configuration are within normal limits.\n",
    "the aortic arch is normal.\n",
    "the lung fields show normal broncho-vascular markings.\n",
    "both the pulmonary hila are normal in size.\n",
    "the costophrenic and cardiophrenic recesses and the domes of\n",
    "diaphragm are normal.\n",
    "the bones and soft tissues of the chest wall show no abnormality.\n",
    "impression : normal study.\n",
    "dr.shakthi kumar\n",
    "radiologist\n",
    "ss\n",
    "________________________________________________________\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset1_template = \"\"\"xr- chest pa  view\n",
    "findings\n",
    "lungs: normal.\n",
    "trachea: normal.\n",
    "carina: normal.\n",
    "right and left main bronchi: normal.\n",
    "pleura: normal.\n",
    "heart: normal.\n",
    "right heart border: normal.\n",
    "left heart border: normal.\n",
    "pulmonary bay: normal.\n",
    "pulmonary hila: normal.\n",
    "aorta: normal.\n",
    "thoracic spine: normal.\n",
    "other visualized bones: normal.\n",
    "visualized soft tissues: normal.\n",
    "diaphragm: normal.\n",
    "visualized abdomen:  normal.\n",
    "visualized neck: normal.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset1_pleural_issue=\"\"\"\n",
    "xr- chest pa view\n",
    "findings\n",
    "lungs: normal.\n",
    "trachea: normal.\n",
    "carina: normal.\n",
    "right and left main bronchi: normal.\n",
    "pleura: left costophrenic angle is blunted with thin stripe of homogenous opacity along left lateral chest wall.\n",
    "heart: normal.\n",
    "right heart border: normal.\n",
    "left heart border: normal.\n",
    "pulmonary bay: normal.\n",
    "pulmonary hila: normal.\n",
    "aorta: normal.\n",
    "thoracic spine: normal.\n",
    "other visualized bones: normal.\n",
    "visualized soft tissues: normal.\n",
    "diaphragm: normal.\n",
    "visualized abdomen:  normal.\n",
    "visualized neck: normal.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset2_template=\"\"\"6191206|3862169|x-ray chest pa/ap view of 09-feb-2018:\n",
    "results:\n",
    "post cabg status.\n",
    "no focal lesion seen in the lung parenchyma.\n",
    "cp angles and domes of the diaphragm are normal.\n",
    "both hila are normal. pulmonary vasculature is normal.\n",
    "cardiac size and configuration is normal.\n",
    "trachea is central; no mediastinal shift is seen.\n",
    "bony thorax and soft tissues of the chest wall are normal.\n",
    "impression: no abnormality detected in the view obtained.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset3_template=\"\"\"\n",
    "x-ray chest (pa view)\n",
    "the cardio thoracic ratio is normal.\n",
    "the heart size and configuration are within normal limits.\n",
    "the aortic arch is normal.\n",
    "the lung fields show normal broncho-vascular markings.\n",
    "both the pulmonary hila are normal in size.\n",
    "the costophrenic and cardiophrenic recesses and the domes of\n",
    "diaphragm are normal.\n",
    "the bones and soft tissues of the chest wall show no abnormality.\n",
    "impression : normal study.\n",
    "dr.shakthi kumar\n",
    "radiologist\n",
    "ss\n",
    "________________________________________________________\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 768])\n",
      "tensor([[1.0000, 0.9347, 0.5985, 0.5178],\n",
      "        [0.9347, 1.0000, 0.6101, 0.5002],\n",
      "        [0.5985, 0.6101, 1.0000, 0.5870],\n",
      "        [0.5178, 0.5002, 0.5870, 1.0000]])\n"
     ]
    }
   ],
   "source": [
    "last_hidden_states4, sentence_embeddings4 = last_hidden_layers(tokenizer1, full_model1, [dataset1_template, dataset1_pleural_issue, dataset2_template, dataset3_template])\n",
    "stacked_sentence_embeddings4, cosine_sim_matrix4 = calc_cosine_sim_matrix(sentence_embeddings4)\n",
    "print(stacked_sentence_embeddings4.size())\n",
    "print(cosine_sim_matrix4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New Embeddings ##\n",
    "Instead of taking sentence embedding to be the vector in final hidden layer corresponding to SOS or EOS, the embedding can be taken for MASK token in the promt \n",
    "```\n",
    "Given the following report: <REPORT>, the final diagnoisis of the patient is <MASK>\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "summarization_prompt = \"Report: <REPORT>. The report shows \" + \"[MASK] \" + \"on the right side\"\n",
    "\n",
    "def last_hidden_layers2(tokenizer, model, sentence_list):\n",
    "    last_hidden_states, sentence_embeddings = list(), list()\n",
    "    with torch.no_grad():\n",
    "        for s in sentence_list:\n",
    "            s = summarization_prompt.replace(\"<REPORT>\", s)\n",
    "            tokens = tokenizer(s, return_tensors='pt', padding=True, truncation=True)\n",
    "            output = model(**tokens, output_hidden_states=True)\n",
    "            last_hidden_state = output.hidden_states[-1]\n",
    "            last_hidden_states.append(last_hidden_state)\n",
    "            sentence_embeddings.append(last_hidden_state.squeeze()[-2, :])\n",
    "    return last_hidden_states, sentence_embeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report: The report shows small right-sided pleural effusion. The report shows [MASK] on the right side\n",
      "MaskedLMOutput(loss=None, logits=tensor([[[ -9.5234,  -7.7479,  -8.1387,  ...,  -8.9454,  -8.1242,  -8.0690],\n",
      "         [-10.7803,  -8.8624,  -9.1088,  ...,  -9.6556,  -9.7797,  -9.9205],\n",
      "         [-12.2636, -10.6406, -11.3034,  ..., -11.3265, -10.7345, -11.0552],\n",
      "         ...,\n",
      "         [-10.4796, -12.3347, -12.8499,  ..., -12.3471, -11.9310, -11.8114],\n",
      "         [-10.7115, -10.3418,  -9.7652,  ..., -10.3161, -10.3574, -10.0931],\n",
      "         [ -9.5234,  -7.7479,  -8.1387,  ...,  -8.9454,  -8.1242,  -8.0690]]]), hidden_states=None, attentions=None)\n",
      "p report : the report shows small right - sided pleural effusion. the report shows changes on the right side p\n"
     ]
    }
   ],
   "source": [
    "masked_prompt = summarization_prompt.replace(\"<REPORT>\", \"The report shows small right-sided pleural effusion\")\n",
    "print(masked_prompt)\n",
    "tokens = tokenizer1(masked_prompt, return_tensors='pt', padding=True, truncation=True)\n",
    "with torch.no_grad():\n",
    "    output = full_model1(**tokens)\n",
    "print(output)\n",
    "\n",
    "logits_before_softmax = output.logits\n",
    "prediction = logits_before_softmax[0].argmax(axis=-1)\n",
    "print(tokenizer1.decode(prediction))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 768])\n",
      "tensor([[1.0000, 0.9428, 0.8330, 0.8657],\n",
      "        [0.9428, 1.0000, 0.8673, 0.8997],\n",
      "        [0.8330, 0.8673, 1.0000, 0.9056],\n",
      "        [0.8657, 0.8997, 0.9056, 1.0000]])\n"
     ]
    }
   ],
   "source": [
    "last_hidden_states5, sentence_embeddings5 = last_hidden_layers2(tokenizer1, full_model1, [dataset1_template, dataset1_pleural_issue, dataset2_template, dataset3_template])\n",
    "stacked_sentence_embeddings5, cosine_sim_matrix5 = calc_cosine_sim_matrix(sentence_embeddings5)\n",
    "print(stacked_sentence_embeddings5.size())\n",
    "print(cosine_sim_matrix5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using BioMedLM ##\n",
    "Using BioMedLM instead of RadBert model for report embeddings\n",
    "\n",
    "https://huggingface.co/stanford-crfm/BioMedLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint2 = \"stanford-crfm/BioMedLM\"\n",
    "\n",
    "tokenizer2 = AutoTokenizer.from_pretrained(checkpoint2)\n",
    "full_model2 = AutoModelForCausalLM.from_pretrained(checkpoint2)\n",
    "base_model2 = AutoModel.from_pretrained(checkpoint2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sanity Checks for BioMedLM ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report: \n",
      "The report shows small right-sided pleural effusion\n",
      " Impression: \n",
      "{'input_ids': tensor([[ 4848,   607,    25,   220,   198,   714,  1492,  3410,  1409,  2497,    12, 12712,  9438,  9814,   198,  2472,   680,    25,   220]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n"
     ]
    }
   ],
   "source": [
    "summarization_prompt_gpt = \"Report: \\n<REPORT>\\n Impression: \"\n",
    "\n",
    "\n",
    "masked_sentence = summarization_prompt_gpt.replace('<REPORT>', sentence_list[0])\n",
    "print(masked_sentence)\n",
    "tokens = tokenizer2(masked_sentence, return_tensors='pt')\n",
    "print(tokens)\n",
    "with torch.no_grad():\n",
    "    output_full = full_model2(**tokens, output_hidden_states=True)\n",
    "    output_base = base_model2(**tokens, output_hidden_states=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CausalLMOutputWithCrossAttentions(loss=None, logits=tensor([[[  3.0114,   4.2856,   2.6358,  ...,  -1.1197,   0.0818,  -7.1363],\n",
      "         [ -5.8972,  -4.7492,  -6.2327,  ..., -18.1685, -13.5248, -19.9139],\n",
      "         [-11.4287,  -8.4990, -11.2120,  ..., -20.2264, -11.8382, -23.7235],\n",
      "         ...,\n",
      "         [  9.9027,   6.5636,   5.6208,  ...,  -0.8483,   0.8190,  -6.8225],\n",
      "         [ -1.3679,  -2.2083,  -5.4045,  ..., -10.0803,  -7.4748, -15.2467],\n",
      "         [  8.0426,   2.1764,   1.2141,  ...,  -6.7583,  -3.9359, -11.8822]]]), past_key_values=None, hidden_states=(tensor([[[ 0.0443,  0.0031, -0.0161,  ..., -0.0163,  0.0185, -0.0165],\n",
      "         [-0.0081,  0.0122,  0.0081,  ...,  0.0247, -0.0038,  0.0047],\n",
      "         [-0.0087,  0.0375, -0.0105,  ...,  0.0159, -0.0046,  0.0343],\n",
      "         ...,\n",
      "         [-0.0233,  0.0070,  0.0253,  ...,  0.0025, -0.0032, -0.0032],\n",
      "         [-0.0114,  0.0267, -0.0103,  ...,  0.0066,  0.0012,  0.0394],\n",
      "         [-0.0088,  0.0064,  0.0056,  ..., -0.0088,  0.0268,  0.0490]]]), tensor([[[ 0.1545,  0.2476,  0.0524,  ..., -0.1642, -0.1271, -0.1993],\n",
      "         [-0.1212,  0.0724,  0.1808,  ...,  0.1564,  0.0681, -0.0606],\n",
      "         [-0.0172,  0.3444, -0.2111,  ...,  0.0387,  0.1054,  0.3402],\n",
      "         ...,\n",
      "         [ 0.1992,  0.1806,  0.2010,  ...,  0.1518,  0.1326,  0.2183],\n",
      "         [-0.0987,  0.1853, -0.0549,  ..., -0.0544,  0.1056,  0.1626],\n",
      "         [-0.0580, -0.0073,  0.0162,  ...,  0.0389,  0.1163,  0.1690]]]), tensor([[[ 0.1953,  0.2595, -0.0098,  ..., -0.2849, -0.1581, -0.3054],\n",
      "         [-0.3893,  0.1761,  0.2804,  ...,  0.2782,  0.0035, -0.0924],\n",
      "         [-0.0863,  0.6194, -0.3349,  ..., -0.0672,  0.0833,  0.2251],\n",
      "         ...,\n",
      "         [ 0.1239,  0.0925,  0.1577,  ..., -0.0657,  0.0463,  0.1193],\n",
      "         [-0.2425,  0.3881, -0.0218,  ..., -0.1344,  0.1472,  0.1787],\n",
      "         [-0.1243,  0.0915, -0.0180,  ...,  0.1607,  0.1050,  0.1663]]]), tensor([[[ 0.2485,  0.2154, -0.0359,  ..., -0.3955, -0.1557, -0.3881],\n",
      "         [-0.4198,  0.3495,  0.2262,  ...,  0.2277, -0.0391, -0.1154],\n",
      "         [ 0.0272,  0.5499, -0.2681,  ...,  0.0040,  0.1058, -0.0644],\n",
      "         ...,\n",
      "         [ 0.0598,  0.0669,  0.1153,  ..., -0.0706,  0.0267,  0.1342],\n",
      "         [-0.2722,  0.2854, -0.1108,  ..., -0.1433,  0.0538,  0.1627],\n",
      "         [-0.4158,  0.1234, -0.2477,  ...,  0.1200, -0.0189,  0.1290]]]), tensor([[[ 0.2877,  0.2071, -0.1163,  ..., -0.4367, -0.1814, -0.5685],\n",
      "         [-0.2539,  0.2611,  0.0071,  ...,  0.3841,  0.1059, -0.2402],\n",
      "         [-0.0240,  0.8109, -0.3001,  ...,  0.2179,  0.0848, -0.1052],\n",
      "         ...,\n",
      "         [-0.0288,  0.0087,  0.0568,  ..., -0.1081,  0.0878,  0.0795],\n",
      "         [-0.3305,  0.2662,  0.0354,  ..., -0.0428,  0.1342,  0.1204],\n",
      "         [-0.5006,  0.3022, -0.0933,  ...,  0.2573,  0.0298,  0.4019]]]), tensor([[[ 0.3272,  0.2677, -0.1784,  ..., -0.5198, -0.2167, -0.6849],\n",
      "         [-0.3093,  0.5827,  0.0216,  ...,  0.4053,  0.2512, -0.4865],\n",
      "         [ 0.2643,  1.0073, -0.3394,  ...,  0.2218,  0.3669, -0.1921],\n",
      "         ...,\n",
      "         [-0.3161,  0.1718, -0.0829,  ..., -0.1149, -0.1315,  0.1582],\n",
      "         [-0.1426,  0.3416, -0.0715,  ..., -0.1740,  0.1681,  0.0703],\n",
      "         [-0.7730,  0.1779,  0.0737,  ...,  0.0838,  0.0518,  0.1773]]]), tensor([[[ 0.3792,  0.2207, -0.2643,  ..., -0.6296, -0.3252, -0.7316],\n",
      "         [-0.2598,  0.4684, -0.1542,  ...,  0.6748,  0.2904, -0.5484],\n",
      "         [ 0.2327,  1.1390, -0.5852,  ...,  0.3697,  0.2869, -0.2363],\n",
      "         ...,\n",
      "         [-0.3287, -0.0241, -0.3206,  ..., -0.0432, -0.0029,  0.2099],\n",
      "         [-0.3337,  0.4100, -0.1409,  ..., -0.2451,  0.0392, -0.0913],\n",
      "         [-0.9027,  0.2769,  0.1189,  ...,  0.1465, -0.0633,  0.0780]]]), tensor([[[ 0.4645,  0.1621, -0.3335,  ..., -0.6847, -0.3461, -0.8046],\n",
      "         [-0.4571,  0.6006, -0.2634,  ...,  0.6041,  0.3042, -0.6043],\n",
      "         [ 0.3512,  1.2185, -0.6075,  ...,  0.2188,  0.0789, -0.2796],\n",
      "         ...,\n",
      "         [-0.7274,  0.0381,  0.0056,  ...,  0.0771,  0.0218,  0.1983],\n",
      "         [-0.7001,  0.3306,  0.1496,  ..., -0.2085, -0.2233,  0.0482],\n",
      "         [-1.1654,  0.4371,  0.4934,  ..., -0.0167, -0.2826,  0.0904]]]), tensor([[[ 0.5664,  0.0674, -0.3584,  ..., -0.7502, -0.4068, -0.8713],\n",
      "         [-0.3402,  0.4779, -0.5471,  ...,  0.5565,  0.3579, -0.4274],\n",
      "         [ 0.4253,  1.1563, -0.8006,  ...,  0.0791,  0.3180, -0.1372],\n",
      "         ...,\n",
      "         [-0.7614, -0.0290,  0.1951,  ...,  0.0722,  0.1054, -0.0168],\n",
      "         [-0.8090,  0.3033,  0.3702,  ..., -0.4600, -0.2893,  0.0357],\n",
      "         [-1.2909,  0.4896,  0.3743,  ..., -0.1545, -0.4729,  0.1552]]]), tensor([[[ 0.5895,  0.0090, -0.4289,  ..., -0.7966, -0.4411, -0.9000],\n",
      "         [-0.2543,  0.5127, -0.6852,  ...,  0.6363,  0.3161, -0.5772],\n",
      "         [ 0.3517,  1.2699, -0.8511,  ...,  0.1894,  0.3118,  0.0262],\n",
      "         ...,\n",
      "         [-0.3321, -0.2472,  0.2790,  ..., -0.1643,  0.1205, -0.1617],\n",
      "         [-0.7978,  0.0164,  0.3338,  ..., -0.7110,  0.2226, -0.1536],\n",
      "         [-1.1146,  0.0501,  0.6714,  ..., -0.2622, -0.2595,  0.1954]]]), tensor([[[ 0.5924, -0.0546, -0.4769,  ..., -0.8501, -0.4749, -0.9405],\n",
      "         [-0.3172,  0.5419, -0.7157,  ...,  0.7157,  0.4191, -0.5163],\n",
      "         [ 0.3978,  1.3083, -0.9773,  ...,  0.1743,  0.2632,  0.2171],\n",
      "         ...,\n",
      "         [-0.1992, -0.3450,  0.4541,  ..., -0.3991,  0.3128, -0.0335],\n",
      "         [-0.6399,  0.2540, -0.0276,  ..., -1.1495,  0.0321, -0.0882],\n",
      "         [-1.0733,  0.2867,  0.2917,  ..., -0.7442, -0.3415,  0.2051]]]), tensor([[[ 0.6033, -0.1236, -0.5242,  ..., -0.8985, -0.4615, -0.9703],\n",
      "         [-0.3690,  0.3520, -0.8672,  ...,  0.4809,  0.6118, -0.5362],\n",
      "         [ 0.3440,  1.0754, -1.0663,  ...,  0.0996,  0.1760,  0.4245],\n",
      "         ...,\n",
      "         [-0.3842, -0.4659,  0.3712,  ..., -0.3190,  0.2017,  0.0037],\n",
      "         [-0.6801,  0.1684,  0.1066,  ..., -1.2693,  0.0505,  0.0687],\n",
      "         [-1.0628,  0.1368,  0.6784,  ..., -0.6483, -0.4906,  0.5539]]]), tensor([[[ 0.6273, -0.1395, -0.5196,  ..., -0.9521, -0.4597, -1.0241],\n",
      "         [-0.3915,  0.6762, -0.9998,  ...,  0.3560,  0.6542, -0.4683],\n",
      "         [ 0.3798,  1.0843, -0.9671,  ..., -0.1481,  0.1413,  0.4011],\n",
      "         ...,\n",
      "         [-0.2167, -0.4140,  0.5765,  ..., -0.4575,  0.3169, -0.1404],\n",
      "         [-0.1967,  0.2928,  0.6300,  ..., -1.4225, -0.1142,  0.1871],\n",
      "         [-0.8140,  0.2204,  1.0407,  ..., -0.8753, -0.8626,  0.4921]]]), tensor([[[ 0.6436, -0.1856, -0.5488,  ..., -0.9769, -0.4612, -1.0205],\n",
      "         [-0.5237,  0.7236, -0.3732,  ...,  0.5350,  0.8186, -0.2877],\n",
      "         [ 0.5335,  0.7953, -0.8031,  ..., -0.1673,  0.2261,  0.3425],\n",
      "         ...,\n",
      "         [-0.1261, -0.8114,  0.5303,  ..., -0.4430,  0.0881, -0.1952],\n",
      "         [ 0.0744,  0.2151,  0.6544,  ..., -1.2903, -0.0425,  0.4207],\n",
      "         [-0.6666,  0.4811,  0.9866,  ..., -0.5257, -0.8210,  0.7500]]]), tensor([[[ 6.1601e-01, -2.4688e-01, -5.2352e-01,  ..., -9.7285e-01, -4.5430e-01, -9.8687e-01],\n",
      "         [-7.8080e-01,  7.1645e-01, -5.4910e-01,  ...,  3.2086e-01,  8.4692e-01, -1.9187e-02],\n",
      "         [ 2.7722e-01,  7.7235e-01, -8.4578e-01,  ..., -2.8881e-02,  2.5247e-04,  5.8810e-01],\n",
      "         ...,\n",
      "         [-1.9799e-01, -9.3689e-01,  6.6376e-01,  ..., -2.9208e-01,  2.5218e-01, -1.3285e-01],\n",
      "         [ 1.2271e-01,  3.0282e-01,  8.5532e-01,  ..., -8.0716e-01,  1.0806e-01,  4.0614e-01],\n",
      "         [-8.7997e-01,  8.1418e-01,  1.1273e+00,  ...,  4.6729e-02, -3.1976e-01,  4.7015e-01]]]), tensor([[[ 0.5531, -0.3041, -0.4386,  ..., -0.9715, -0.4453, -0.9832],\n",
      "         [-0.9447,  0.3064, -0.4732,  ...,  0.1825,  1.1567,  0.0090],\n",
      "         [ 0.3225,  0.8066, -0.8233,  ...,  0.0379, -0.0642,  0.2968],\n",
      "         ...,\n",
      "         [-0.1399, -1.2011,  0.9743,  ..., -0.1786,  0.0445, -0.2570],\n",
      "         [ 0.0030,  0.7352,  1.4632,  ..., -0.4844, -0.0090,  0.5992],\n",
      "         [-1.0456,  1.1383,  1.5448,  ..., -0.0571, -0.5145,  0.9382]]]), tensor([[[ 0.5694, -0.3672, -0.4462,  ..., -1.0274, -0.4219, -0.9341],\n",
      "         [-0.8164,  0.7951, -0.4835,  ...,  0.1752,  1.3334, -0.0380],\n",
      "         [ 0.3682,  1.0980, -0.9158,  ...,  0.1504, -0.2340,  0.6263],\n",
      "         ...,\n",
      "         [-0.2252, -1.3390,  1.1847,  ..., -0.0965, -0.1083, -0.3673],\n",
      "         [-0.2456,  1.3911,  1.2556,  ..., -0.2398,  0.1260,  0.8295],\n",
      "         [-1.5466,  1.7153,  1.6071,  ...,  0.2897, -0.6586,  1.0661]]]), tensor([[[ 0.5355, -0.4142, -0.4619,  ..., -1.0490, -0.4211, -0.8710],\n",
      "         [-1.1266,  0.5584, -0.9086,  ...,  0.4570,  1.5818,  0.1772],\n",
      "         [ 0.6895,  1.0499, -0.8284,  ...,  0.3432, -0.1715,  0.6942],\n",
      "         ...,\n",
      "         [-0.4695, -1.2343,  1.1749,  ...,  0.0175, -0.1481,  0.1522],\n",
      "         [-0.2523,  1.3544,  1.4006,  ...,  0.0760,  0.2730,  1.2890],\n",
      "         [-1.8876,  1.6602,  1.5191,  ...,  0.2087, -0.6006,  1.0651]]]), tensor([[[ 0.5185, -0.4491, -0.4045,  ..., -1.0850, -0.4142, -0.8329],\n",
      "         [-1.0821,  0.6036, -0.9263,  ...,  0.4585,  1.5300,  0.0990],\n",
      "         [ 0.3874,  1.0231, -0.7241,  ...,  0.1803, -0.5225,  0.5205],\n",
      "         ...,\n",
      "         [-0.1389, -1.1447,  1.3785,  ..., -0.1923, -0.0340,  0.7110],\n",
      "         [-0.4184,  1.3534,  1.4905,  ..., -0.2908,  0.8468,  1.3624],\n",
      "         [-2.1795,  1.5079,  1.6343,  ...,  0.0404, -0.4509,  0.8754]]]), tensor([[[ 0.4646, -0.4520, -0.3730,  ..., -1.1176, -0.3899, -0.7951],\n",
      "         [-1.2422,  0.6048, -0.6863,  ...,  0.7793,  1.2077,  0.4856],\n",
      "         [-0.1863,  1.2026, -0.3613,  ...,  0.9130, -0.7690,  0.5780],\n",
      "         ...,\n",
      "         [-0.3124, -1.1407,  1.6474,  ..., -0.3500,  0.0453,  1.1313],\n",
      "         [-0.7857,  1.6697,  1.5050,  ..., -0.3877,  0.7924,  1.3830],\n",
      "         [-2.5342,  1.7999,  1.7464,  ..., -0.2446, -0.5714,  0.6273]]]), tensor([[[ 0.4113, -0.4135, -0.3705,  ..., -1.1222, -0.4213, -0.7392],\n",
      "         [-1.2189,  0.8284, -0.9213,  ...,  0.7040,  1.1984, -0.0164],\n",
      "         [-0.0915,  1.1878, -0.4566,  ...,  0.6848, -0.8635,  0.3946],\n",
      "         ...,\n",
      "         [-0.4274, -1.1064,  2.0628,  ..., -0.2977, -0.3443,  1.4659],\n",
      "         [-1.1305,  1.8726,  1.2963,  ..., -0.0941,  0.5425,  2.2683],\n",
      "         [-2.8216,  1.8966,  1.6261,  ..., -0.4234, -1.0036,  0.6145]]]), tensor([[[ 0.4665, -0.3856, -0.2801,  ..., -1.0653, -0.4870, -0.7071],\n",
      "         [-1.0191,  1.0338, -1.0804,  ...,  0.9274,  0.9668, -0.2065],\n",
      "         [-0.0795,  1.1791, -0.4090,  ...,  0.8387, -0.9909,  0.4088],\n",
      "         ...,\n",
      "         [-0.3740, -0.6761,  2.0363,  ..., -0.4554, -0.2252,  1.6372],\n",
      "         [-1.2165,  2.5437,  1.4601,  ...,  0.0247,  0.4163,  2.2084],\n",
      "         [-3.1356,  2.6259,  1.5362,  ..., -0.4144, -0.8221,  0.4976]]]), tensor([[[ 0.4380, -0.3690, -0.2143,  ..., -1.0441, -0.5109, -0.6815],\n",
      "         [-1.0059,  0.8333, -0.9452,  ...,  0.7462,  0.8251, -0.3869],\n",
      "         [-0.1358,  0.9013, -0.3396,  ...,  0.6605, -1.3128,  0.2145],\n",
      "         ...,\n",
      "         [-0.6299, -0.6855,  2.0412,  ..., -0.7380, -0.1087,  1.6366],\n",
      "         [-1.2041,  2.7214,  1.2331,  ...,  0.2546,  0.5940,  2.5343],\n",
      "         [-3.3043,  2.9765,  1.1937,  ..., -0.2248, -0.5597,  0.7004]]]), tensor([[[ 0.3947, -0.3959, -0.1702,  ..., -0.9990, -0.4851, -0.6581],\n",
      "         [-1.1465,  0.8647, -0.8450,  ...,  1.0216,  0.6336, -0.7103],\n",
      "         [ 0.0337,  1.0478, -0.4118,  ...,  0.8971, -1.4251, -0.0540],\n",
      "         ...,\n",
      "         [-0.5264, -0.2483,  1.9843,  ..., -0.6205, -0.3659,  1.8125],\n",
      "         [-1.1016,  3.4490,  1.1244,  ...,  0.5651, -0.0724,  2.4552],\n",
      "         [-3.0092,  2.8288,  1.2143,  ..., -0.1158, -0.7407,  0.4927]]]), tensor([[[ 0.3336, -0.4010, -0.1294,  ..., -0.9285, -0.4733, -0.6097],\n",
      "         [-0.9460,  0.3522, -0.8508,  ...,  0.9366,  0.3555, -0.8273],\n",
      "         [-0.0406,  0.9606, -0.4324,  ...,  0.8604, -1.5315, -0.3364],\n",
      "         ...,\n",
      "         [-0.7105, -0.3024,  1.6444,  ..., -0.4724, -0.5842,  2.2394],\n",
      "         [-0.8678,  3.7737,  1.5179,  ...,  0.2188, -0.4710,  2.7354],\n",
      "         [-3.0275,  3.4704,  1.2771,  ..., -0.3595, -0.6976,  0.3218]]]), tensor([[[ 0.3155, -0.2936, -0.1198,  ..., -0.8943, -0.4905, -0.6112],\n",
      "         [-0.7439,  0.2878, -0.7812,  ...,  0.7752,  0.3859, -0.6748],\n",
      "         [ 0.2346,  1.1099, -0.1232,  ...,  0.5148, -1.9971, -0.5763],\n",
      "         ...,\n",
      "         [-0.7667, -0.2285,  1.4495,  ..., -0.6375, -0.1695,  2.2832],\n",
      "         [-0.6792,  4.2544,  1.7221,  ..., -0.1358, -0.9903,  2.1325],\n",
      "         [-2.9606,  3.8299,  1.0755,  ..., -0.2449, -0.8048,  0.1021]]]), tensor([[[ 2.6900e-01, -1.8996e-01, -1.5917e-01,  ..., -8.3117e-01, -5.1293e-01, -5.5311e-01],\n",
      "         [-1.0174e+00,  2.5467e-01, -1.1530e+00,  ...,  5.0426e-01,  6.3954e-01, -5.9657e-01],\n",
      "         [ 3.4531e-01,  1.0850e+00,  6.7146e-02,  ...,  5.3003e-01, -2.1641e+00, -3.8127e-01],\n",
      "         ...,\n",
      "         [-8.3908e-01,  4.2479e-04,  1.3601e+00,  ..., -4.4470e-01, -1.8504e-01,  2.1330e+00],\n",
      "         [-1.0739e+00,  4.3629e+00,  2.2739e+00,  ..., -1.5456e-01, -1.4280e+00,  2.5366e+00],\n",
      "         [-3.0107e+00,  3.9630e+00,  1.3614e+00,  ..., -4.3711e-01, -1.0672e+00,  6.0940e-01]]]), tensor([[[ 0.2689, -0.1307, -0.2131,  ..., -0.6647, -0.5190, -0.4504],\n",
      "         [-1.2299,  0.1335, -1.0285,  ...,  0.1448,  0.7749, -0.6223],\n",
      "         [ 0.3408,  0.9619, -0.1713,  ...,  0.8906, -2.0026, -0.5520],\n",
      "         ...,\n",
      "         [-0.6844,  0.1477,  1.0435,  ..., -0.5704,  0.1739,  1.8928],\n",
      "         [-1.5199,  4.0063,  2.3372,  ..., -0.3483, -1.8184,  2.0491],\n",
      "         [-3.1792,  4.0364,  1.3641,  ..., -0.1785, -0.9574,  0.0111]]]), tensor([[[ 0.1470, -0.0899, -0.1434,  ..., -0.5372, -0.6023, -0.4502],\n",
      "         [-0.8003,  0.1126, -0.9592,  ...,  0.2249,  0.4064, -0.4423],\n",
      "         [-0.0140,  0.9252, -0.0322,  ...,  1.1973, -2.3401, -0.8476],\n",
      "         ...,\n",
      "         [-0.3233, -0.1691,  1.2843,  ..., -0.3857,  0.2971,  1.5747],\n",
      "         [-1.4672,  3.4196,  2.0753,  ..., -0.2738, -1.6300,  2.2782],\n",
      "         [-2.4790,  3.3632,  0.9688,  ..., -0.3788, -0.9527,  0.4266]]]), tensor([[[ 0.0713, -0.0296, -0.1968,  ..., -0.3802, -0.5066, -0.3118],\n",
      "         [-0.5022,  0.0870, -0.6917,  ...,  0.7791,  0.3016, -0.2338],\n",
      "         [-0.2135,  0.5661,  0.2120,  ...,  1.3508, -2.4085, -0.9974],\n",
      "         ...,\n",
      "         [-0.1998,  0.1054,  1.3638,  ...,  0.0153,  0.6688,  1.3418],\n",
      "         [-1.9327,  3.2932,  2.3466,  ..., -0.6968, -1.9342,  2.5276],\n",
      "         [-1.5930,  3.2727,  1.2980,  ..., -0.5906, -1.1284,  0.4759]]]), tensor([[[ 0.1897,  0.3155, -0.3205,  ...,  0.0445, -0.6211, -0.0245],\n",
      "         [-0.5277,  0.4267, -1.0545,  ...,  0.9738, -0.0646, -0.5294],\n",
      "         [-0.3756,  0.2063,  0.1027,  ...,  1.1218, -2.9876, -0.9719],\n",
      "         ...,\n",
      "         [ 0.1199,  0.4664,  1.5785,  ...,  0.0315,  0.1680,  1.4248],\n",
      "         [-2.0089,  3.4767,  2.2171,  ..., -1.1279, -2.3210,  1.9302],\n",
      "         [-1.2504,  3.3843,  1.0933,  ..., -1.0512, -1.2884, -0.1392]]]), tensor([[[-0.4475,  1.3545, -0.6137,  ...,  0.1788, -0.0531,  0.3064],\n",
      "         [ 0.0149, -0.0477, -0.7075,  ...,  1.1375, -0.4238, -0.6128],\n",
      "         [-0.2335, -0.2991,  0.4946,  ...,  1.4792, -3.9328, -1.4876],\n",
      "         ...,\n",
      "         [ 0.0729, -0.0305,  1.6829,  ...,  0.6106, -0.3558,  1.0421],\n",
      "         [-1.8820,  3.0938,  2.7420,  ..., -0.8423, -3.1938,  1.4521],\n",
      "         [-1.0409,  3.0529,  0.9153,  ..., -0.6315, -1.7257, -0.2670]]]), tensor([[[-0.7844,  2.4187, -0.7710,  ...,  0.5041,  0.4723, -0.2954],\n",
      "         [ 0.6280,  0.0158, -0.7458,  ...,  1.3180, -0.4291, -0.7334],\n",
      "         [ 0.1725, -0.6851,  0.2948,  ...,  1.0713, -3.1548, -1.3083],\n",
      "         ...,\n",
      "         [ 0.5096, -0.4049,  2.1805,  ...,  0.6665, -0.5261,  0.9300],\n",
      "         [-1.3047,  1.9672,  2.3080,  ..., -0.9352, -2.3571,  1.1515],\n",
      "         [-0.3793,  2.5821,  0.4518,  ..., -1.0776, -1.4675, -0.2161]]])), attentions=None, cross_attentions=None)\n",
      "torch.Size([1, 19, 28896])\n",
      "33\n",
      "torch.Size([1, 19, 2560])\n"
     ]
    }
   ],
   "source": [
    "print(output_full)\n",
    "print(output_full.logits.size())\n",
    "print(len(output_full.hidden_states))\n",
    "print(output_full.hidden_states[-1].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BaseModelOutputWithPastAndCrossAttentions(last_hidden_state=tensor([[[-0.7844,  2.4187, -0.7710,  ...,  0.5041,  0.4723, -0.2954],\n",
      "         [ 0.6280,  0.0158, -0.7458,  ...,  1.3180, -0.4291, -0.7334],\n",
      "         [ 0.1725, -0.6851,  0.2948,  ...,  1.0713, -3.1548, -1.3083],\n",
      "         ...,\n",
      "         [ 0.5096, -0.4049,  2.1805,  ...,  0.6665, -0.5261,  0.9300],\n",
      "         [-1.3047,  1.9672,  2.3080,  ..., -0.9352, -2.3571,  1.1515],\n",
      "         [-0.3793,  2.5821,  0.4518,  ..., -1.0776, -1.4675, -0.2161]]]), past_key_values=None, hidden_states=(tensor([[[ 0.0443,  0.0031, -0.0161,  ..., -0.0163,  0.0185, -0.0165],\n",
      "         [-0.0081,  0.0122,  0.0081,  ...,  0.0247, -0.0038,  0.0047],\n",
      "         [-0.0087,  0.0375, -0.0105,  ...,  0.0159, -0.0046,  0.0343],\n",
      "         ...,\n",
      "         [-0.0233,  0.0070,  0.0253,  ...,  0.0025, -0.0032, -0.0032],\n",
      "         [-0.0114,  0.0267, -0.0103,  ...,  0.0066,  0.0012,  0.0394],\n",
      "         [-0.0088,  0.0064,  0.0056,  ..., -0.0088,  0.0268,  0.0490]]]), tensor([[[ 0.1545,  0.2476,  0.0524,  ..., -0.1642, -0.1271, -0.1993],\n",
      "         [-0.1212,  0.0724,  0.1808,  ...,  0.1564,  0.0681, -0.0606],\n",
      "         [-0.0172,  0.3444, -0.2111,  ...,  0.0387,  0.1054,  0.3402],\n",
      "         ...,\n",
      "         [ 0.1992,  0.1806,  0.2010,  ...,  0.1518,  0.1326,  0.2183],\n",
      "         [-0.0987,  0.1853, -0.0549,  ..., -0.0544,  0.1056,  0.1626],\n",
      "         [-0.0580, -0.0073,  0.0162,  ...,  0.0389,  0.1163,  0.1690]]]), tensor([[[ 0.1953,  0.2595, -0.0098,  ..., -0.2849, -0.1581, -0.3054],\n",
      "         [-0.3893,  0.1761,  0.2804,  ...,  0.2782,  0.0035, -0.0924],\n",
      "         [-0.0863,  0.6194, -0.3349,  ..., -0.0672,  0.0833,  0.2251],\n",
      "         ...,\n",
      "         [ 0.1239,  0.0925,  0.1577,  ..., -0.0657,  0.0463,  0.1193],\n",
      "         [-0.2425,  0.3881, -0.0218,  ..., -0.1344,  0.1472,  0.1787],\n",
      "         [-0.1243,  0.0915, -0.0180,  ...,  0.1607,  0.1050,  0.1663]]]), tensor([[[ 0.2485,  0.2154, -0.0359,  ..., -0.3955, -0.1557, -0.3881],\n",
      "         [-0.4198,  0.3495,  0.2262,  ...,  0.2277, -0.0391, -0.1154],\n",
      "         [ 0.0272,  0.5499, -0.2681,  ...,  0.0040,  0.1058, -0.0644],\n",
      "         ...,\n",
      "         [ 0.0598,  0.0669,  0.1153,  ..., -0.0706,  0.0267,  0.1342],\n",
      "         [-0.2722,  0.2854, -0.1108,  ..., -0.1433,  0.0538,  0.1627],\n",
      "         [-0.4158,  0.1234, -0.2477,  ...,  0.1200, -0.0189,  0.1290]]]), tensor([[[ 0.2877,  0.2071, -0.1163,  ..., -0.4367, -0.1814, -0.5685],\n",
      "         [-0.2539,  0.2611,  0.0071,  ...,  0.3841,  0.1059, -0.2402],\n",
      "         [-0.0240,  0.8109, -0.3001,  ...,  0.2179,  0.0848, -0.1052],\n",
      "         ...,\n",
      "         [-0.0288,  0.0087,  0.0568,  ..., -0.1081,  0.0878,  0.0795],\n",
      "         [-0.3305,  0.2662,  0.0354,  ..., -0.0428,  0.1342,  0.1204],\n",
      "         [-0.5006,  0.3022, -0.0933,  ...,  0.2573,  0.0298,  0.4019]]]), tensor([[[ 0.3272,  0.2677, -0.1784,  ..., -0.5198, -0.2167, -0.6849],\n",
      "         [-0.3093,  0.5827,  0.0216,  ...,  0.4053,  0.2512, -0.4865],\n",
      "         [ 0.2643,  1.0073, -0.3394,  ...,  0.2218,  0.3669, -0.1921],\n",
      "         ...,\n",
      "         [-0.3161,  0.1718, -0.0829,  ..., -0.1149, -0.1315,  0.1582],\n",
      "         [-0.1426,  0.3416, -0.0715,  ..., -0.1740,  0.1681,  0.0703],\n",
      "         [-0.7730,  0.1779,  0.0737,  ...,  0.0838,  0.0518,  0.1773]]]), tensor([[[ 0.3792,  0.2207, -0.2643,  ..., -0.6296, -0.3252, -0.7316],\n",
      "         [-0.2598,  0.4684, -0.1542,  ...,  0.6748,  0.2904, -0.5484],\n",
      "         [ 0.2327,  1.1390, -0.5852,  ...,  0.3697,  0.2869, -0.2363],\n",
      "         ...,\n",
      "         [-0.3287, -0.0241, -0.3206,  ..., -0.0432, -0.0029,  0.2099],\n",
      "         [-0.3337,  0.4100, -0.1409,  ..., -0.2451,  0.0392, -0.0913],\n",
      "         [-0.9027,  0.2769,  0.1189,  ...,  0.1465, -0.0633,  0.0780]]]), tensor([[[ 0.4645,  0.1621, -0.3335,  ..., -0.6847, -0.3461, -0.8046],\n",
      "         [-0.4571,  0.6006, -0.2634,  ...,  0.6041,  0.3042, -0.6043],\n",
      "         [ 0.3512,  1.2185, -0.6075,  ...,  0.2188,  0.0789, -0.2796],\n",
      "         ...,\n",
      "         [-0.7274,  0.0381,  0.0056,  ...,  0.0771,  0.0218,  0.1983],\n",
      "         [-0.7001,  0.3306,  0.1496,  ..., -0.2085, -0.2233,  0.0482],\n",
      "         [-1.1654,  0.4371,  0.4934,  ..., -0.0167, -0.2826,  0.0904]]]), tensor([[[ 0.5664,  0.0674, -0.3584,  ..., -0.7502, -0.4068, -0.8713],\n",
      "         [-0.3402,  0.4779, -0.5471,  ...,  0.5565,  0.3579, -0.4274],\n",
      "         [ 0.4253,  1.1563, -0.8006,  ...,  0.0791,  0.3180, -0.1372],\n",
      "         ...,\n",
      "         [-0.7614, -0.0290,  0.1951,  ...,  0.0722,  0.1054, -0.0168],\n",
      "         [-0.8090,  0.3033,  0.3702,  ..., -0.4600, -0.2893,  0.0357],\n",
      "         [-1.2909,  0.4896,  0.3743,  ..., -0.1545, -0.4729,  0.1552]]]), tensor([[[ 0.5895,  0.0090, -0.4289,  ..., -0.7966, -0.4411, -0.9000],\n",
      "         [-0.2543,  0.5127, -0.6852,  ...,  0.6363,  0.3161, -0.5772],\n",
      "         [ 0.3517,  1.2699, -0.8511,  ...,  0.1894,  0.3118,  0.0262],\n",
      "         ...,\n",
      "         [-0.3321, -0.2472,  0.2790,  ..., -0.1643,  0.1205, -0.1617],\n",
      "         [-0.7978,  0.0164,  0.3338,  ..., -0.7110,  0.2226, -0.1536],\n",
      "         [-1.1146,  0.0501,  0.6714,  ..., -0.2622, -0.2595,  0.1954]]]), tensor([[[ 0.5924, -0.0546, -0.4769,  ..., -0.8501, -0.4749, -0.9405],\n",
      "         [-0.3172,  0.5419, -0.7157,  ...,  0.7157,  0.4191, -0.5163],\n",
      "         [ 0.3978,  1.3083, -0.9773,  ...,  0.1743,  0.2632,  0.2171],\n",
      "         ...,\n",
      "         [-0.1992, -0.3450,  0.4541,  ..., -0.3991,  0.3128, -0.0335],\n",
      "         [-0.6399,  0.2540, -0.0276,  ..., -1.1495,  0.0321, -0.0882],\n",
      "         [-1.0733,  0.2867,  0.2917,  ..., -0.7442, -0.3415,  0.2051]]]), tensor([[[ 0.6033, -0.1236, -0.5242,  ..., -0.8985, -0.4615, -0.9703],\n",
      "         [-0.3690,  0.3520, -0.8672,  ...,  0.4809,  0.6118, -0.5362],\n",
      "         [ 0.3440,  1.0754, -1.0663,  ...,  0.0996,  0.1760,  0.4245],\n",
      "         ...,\n",
      "         [-0.3842, -0.4659,  0.3712,  ..., -0.3190,  0.2017,  0.0037],\n",
      "         [-0.6801,  0.1684,  0.1066,  ..., -1.2693,  0.0505,  0.0687],\n",
      "         [-1.0628,  0.1368,  0.6784,  ..., -0.6483, -0.4906,  0.5539]]]), tensor([[[ 0.6273, -0.1395, -0.5196,  ..., -0.9521, -0.4597, -1.0241],\n",
      "         [-0.3915,  0.6762, -0.9998,  ...,  0.3560,  0.6542, -0.4683],\n",
      "         [ 0.3798,  1.0843, -0.9671,  ..., -0.1481,  0.1413,  0.4011],\n",
      "         ...,\n",
      "         [-0.2167, -0.4140,  0.5765,  ..., -0.4575,  0.3169, -0.1404],\n",
      "         [-0.1967,  0.2928,  0.6300,  ..., -1.4225, -0.1142,  0.1871],\n",
      "         [-0.8140,  0.2204,  1.0407,  ..., -0.8753, -0.8626,  0.4921]]]), tensor([[[ 0.6436, -0.1856, -0.5488,  ..., -0.9769, -0.4612, -1.0205],\n",
      "         [-0.5237,  0.7236, -0.3732,  ...,  0.5350,  0.8186, -0.2877],\n",
      "         [ 0.5335,  0.7953, -0.8031,  ..., -0.1673,  0.2261,  0.3425],\n",
      "         ...,\n",
      "         [-0.1261, -0.8114,  0.5303,  ..., -0.4430,  0.0881, -0.1952],\n",
      "         [ 0.0744,  0.2151,  0.6544,  ..., -1.2903, -0.0425,  0.4207],\n",
      "         [-0.6666,  0.4811,  0.9866,  ..., -0.5257, -0.8210,  0.7500]]]), tensor([[[ 6.1601e-01, -2.4688e-01, -5.2352e-01,  ..., -9.7285e-01, -4.5430e-01, -9.8687e-01],\n",
      "         [-7.8080e-01,  7.1645e-01, -5.4910e-01,  ...,  3.2086e-01,  8.4692e-01, -1.9187e-02],\n",
      "         [ 2.7722e-01,  7.7235e-01, -8.4578e-01,  ..., -2.8881e-02,  2.5247e-04,  5.8810e-01],\n",
      "         ...,\n",
      "         [-1.9799e-01, -9.3689e-01,  6.6376e-01,  ..., -2.9208e-01,  2.5218e-01, -1.3285e-01],\n",
      "         [ 1.2271e-01,  3.0282e-01,  8.5532e-01,  ..., -8.0716e-01,  1.0806e-01,  4.0614e-01],\n",
      "         [-8.7997e-01,  8.1418e-01,  1.1273e+00,  ...,  4.6729e-02, -3.1976e-01,  4.7015e-01]]]), tensor([[[ 0.5531, -0.3041, -0.4386,  ..., -0.9715, -0.4453, -0.9832],\n",
      "         [-0.9447,  0.3064, -0.4732,  ...,  0.1825,  1.1567,  0.0090],\n",
      "         [ 0.3225,  0.8066, -0.8233,  ...,  0.0379, -0.0642,  0.2968],\n",
      "         ...,\n",
      "         [-0.1399, -1.2011,  0.9743,  ..., -0.1786,  0.0445, -0.2570],\n",
      "         [ 0.0030,  0.7352,  1.4632,  ..., -0.4844, -0.0090,  0.5992],\n",
      "         [-1.0456,  1.1383,  1.5448,  ..., -0.0571, -0.5145,  0.9382]]]), tensor([[[ 0.5694, -0.3672, -0.4462,  ..., -1.0274, -0.4219, -0.9341],\n",
      "         [-0.8164,  0.7951, -0.4835,  ...,  0.1752,  1.3334, -0.0380],\n",
      "         [ 0.3682,  1.0980, -0.9158,  ...,  0.1504, -0.2340,  0.6263],\n",
      "         ...,\n",
      "         [-0.2252, -1.3390,  1.1847,  ..., -0.0965, -0.1083, -0.3673],\n",
      "         [-0.2456,  1.3911,  1.2556,  ..., -0.2398,  0.1260,  0.8295],\n",
      "         [-1.5466,  1.7153,  1.6071,  ...,  0.2897, -0.6586,  1.0661]]]), tensor([[[ 0.5355, -0.4142, -0.4619,  ..., -1.0490, -0.4211, -0.8710],\n",
      "         [-1.1266,  0.5584, -0.9086,  ...,  0.4570,  1.5818,  0.1772],\n",
      "         [ 0.6895,  1.0499, -0.8284,  ...,  0.3432, -0.1715,  0.6942],\n",
      "         ...,\n",
      "         [-0.4695, -1.2343,  1.1749,  ...,  0.0175, -0.1481,  0.1522],\n",
      "         [-0.2523,  1.3544,  1.4006,  ...,  0.0760,  0.2730,  1.2890],\n",
      "         [-1.8876,  1.6602,  1.5191,  ...,  0.2087, -0.6006,  1.0651]]]), tensor([[[ 0.5185, -0.4491, -0.4045,  ..., -1.0850, -0.4142, -0.8329],\n",
      "         [-1.0821,  0.6036, -0.9263,  ...,  0.4585,  1.5300,  0.0990],\n",
      "         [ 0.3874,  1.0231, -0.7241,  ...,  0.1803, -0.5225,  0.5205],\n",
      "         ...,\n",
      "         [-0.1389, -1.1447,  1.3785,  ..., -0.1923, -0.0340,  0.7110],\n",
      "         [-0.4184,  1.3534,  1.4905,  ..., -0.2908,  0.8468,  1.3624],\n",
      "         [-2.1795,  1.5079,  1.6343,  ...,  0.0404, -0.4509,  0.8754]]]), tensor([[[ 0.4646, -0.4520, -0.3730,  ..., -1.1176, -0.3899, -0.7951],\n",
      "         [-1.2422,  0.6048, -0.6863,  ...,  0.7793,  1.2077,  0.4856],\n",
      "         [-0.1863,  1.2026, -0.3613,  ...,  0.9130, -0.7690,  0.5780],\n",
      "         ...,\n",
      "         [-0.3124, -1.1407,  1.6474,  ..., -0.3500,  0.0453,  1.1313],\n",
      "         [-0.7857,  1.6697,  1.5050,  ..., -0.3877,  0.7924,  1.3830],\n",
      "         [-2.5342,  1.7999,  1.7464,  ..., -0.2446, -0.5714,  0.6273]]]), tensor([[[ 0.4113, -0.4135, -0.3705,  ..., -1.1222, -0.4213, -0.7392],\n",
      "         [-1.2189,  0.8284, -0.9213,  ...,  0.7040,  1.1984, -0.0164],\n",
      "         [-0.0915,  1.1878, -0.4566,  ...,  0.6848, -0.8635,  0.3946],\n",
      "         ...,\n",
      "         [-0.4274, -1.1064,  2.0628,  ..., -0.2977, -0.3443,  1.4659],\n",
      "         [-1.1305,  1.8726,  1.2963,  ..., -0.0941,  0.5425,  2.2683],\n",
      "         [-2.8216,  1.8966,  1.6261,  ..., -0.4234, -1.0036,  0.6145]]]), tensor([[[ 0.4665, -0.3856, -0.2801,  ..., -1.0653, -0.4870, -0.7071],\n",
      "         [-1.0191,  1.0338, -1.0804,  ...,  0.9274,  0.9668, -0.2065],\n",
      "         [-0.0795,  1.1791, -0.4090,  ...,  0.8387, -0.9909,  0.4088],\n",
      "         ...,\n",
      "         [-0.3740, -0.6761,  2.0363,  ..., -0.4554, -0.2252,  1.6372],\n",
      "         [-1.2165,  2.5437,  1.4601,  ...,  0.0247,  0.4163,  2.2084],\n",
      "         [-3.1356,  2.6259,  1.5362,  ..., -0.4144, -0.8221,  0.4976]]]), tensor([[[ 0.4380, -0.3690, -0.2143,  ..., -1.0441, -0.5109, -0.6815],\n",
      "         [-1.0059,  0.8333, -0.9452,  ...,  0.7462,  0.8251, -0.3869],\n",
      "         [-0.1358,  0.9013, -0.3396,  ...,  0.6605, -1.3128,  0.2145],\n",
      "         ...,\n",
      "         [-0.6299, -0.6855,  2.0412,  ..., -0.7380, -0.1087,  1.6366],\n",
      "         [-1.2041,  2.7214,  1.2331,  ...,  0.2546,  0.5940,  2.5343],\n",
      "         [-3.3043,  2.9765,  1.1937,  ..., -0.2248, -0.5597,  0.7004]]]), tensor([[[ 0.3947, -0.3959, -0.1702,  ..., -0.9990, -0.4851, -0.6581],\n",
      "         [-1.1465,  0.8647, -0.8450,  ...,  1.0216,  0.6336, -0.7103],\n",
      "         [ 0.0337,  1.0478, -0.4118,  ...,  0.8971, -1.4251, -0.0540],\n",
      "         ...,\n",
      "         [-0.5264, -0.2483,  1.9843,  ..., -0.6205, -0.3659,  1.8125],\n",
      "         [-1.1016,  3.4490,  1.1244,  ...,  0.5651, -0.0724,  2.4552],\n",
      "         [-3.0092,  2.8288,  1.2143,  ..., -0.1158, -0.7407,  0.4927]]]), tensor([[[ 0.3336, -0.4010, -0.1294,  ..., -0.9285, -0.4733, -0.6097],\n",
      "         [-0.9460,  0.3522, -0.8508,  ...,  0.9366,  0.3555, -0.8273],\n",
      "         [-0.0406,  0.9606, -0.4324,  ...,  0.8604, -1.5315, -0.3364],\n",
      "         ...,\n",
      "         [-0.7105, -0.3024,  1.6444,  ..., -0.4724, -0.5842,  2.2394],\n",
      "         [-0.8678,  3.7737,  1.5179,  ...,  0.2188, -0.4710,  2.7354],\n",
      "         [-3.0275,  3.4704,  1.2771,  ..., -0.3595, -0.6976,  0.3218]]]), tensor([[[ 0.3155, -0.2936, -0.1198,  ..., -0.8943, -0.4905, -0.6112],\n",
      "         [-0.7439,  0.2878, -0.7812,  ...,  0.7752,  0.3859, -0.6748],\n",
      "         [ 0.2346,  1.1099, -0.1232,  ...,  0.5148, -1.9971, -0.5763],\n",
      "         ...,\n",
      "         [-0.7667, -0.2285,  1.4495,  ..., -0.6375, -0.1695,  2.2832],\n",
      "         [-0.6792,  4.2544,  1.7221,  ..., -0.1358, -0.9903,  2.1325],\n",
      "         [-2.9606,  3.8299,  1.0755,  ..., -0.2449, -0.8048,  0.1021]]]), tensor([[[ 2.6900e-01, -1.8996e-01, -1.5917e-01,  ..., -8.3117e-01, -5.1293e-01, -5.5311e-01],\n",
      "         [-1.0174e+00,  2.5467e-01, -1.1530e+00,  ...,  5.0426e-01,  6.3954e-01, -5.9657e-01],\n",
      "         [ 3.4531e-01,  1.0850e+00,  6.7146e-02,  ...,  5.3003e-01, -2.1641e+00, -3.8127e-01],\n",
      "         ...,\n",
      "         [-8.3908e-01,  4.2479e-04,  1.3601e+00,  ..., -4.4470e-01, -1.8504e-01,  2.1330e+00],\n",
      "         [-1.0739e+00,  4.3629e+00,  2.2739e+00,  ..., -1.5456e-01, -1.4280e+00,  2.5366e+00],\n",
      "         [-3.0107e+00,  3.9630e+00,  1.3614e+00,  ..., -4.3711e-01, -1.0672e+00,  6.0940e-01]]]), tensor([[[ 0.2689, -0.1307, -0.2131,  ..., -0.6647, -0.5190, -0.4504],\n",
      "         [-1.2299,  0.1335, -1.0285,  ...,  0.1448,  0.7749, -0.6223],\n",
      "         [ 0.3408,  0.9619, -0.1713,  ...,  0.8906, -2.0026, -0.5520],\n",
      "         ...,\n",
      "         [-0.6844,  0.1477,  1.0435,  ..., -0.5704,  0.1739,  1.8928],\n",
      "         [-1.5199,  4.0063,  2.3372,  ..., -0.3483, -1.8184,  2.0491],\n",
      "         [-3.1792,  4.0364,  1.3641,  ..., -0.1785, -0.9574,  0.0111]]]), tensor([[[ 0.1470, -0.0899, -0.1434,  ..., -0.5372, -0.6023, -0.4502],\n",
      "         [-0.8003,  0.1126, -0.9592,  ...,  0.2249,  0.4064, -0.4423],\n",
      "         [-0.0140,  0.9252, -0.0322,  ...,  1.1973, -2.3401, -0.8476],\n",
      "         ...,\n",
      "         [-0.3233, -0.1691,  1.2843,  ..., -0.3857,  0.2971,  1.5747],\n",
      "         [-1.4672,  3.4196,  2.0753,  ..., -0.2738, -1.6300,  2.2782],\n",
      "         [-2.4790,  3.3632,  0.9688,  ..., -0.3788, -0.9527,  0.4266]]]), tensor([[[ 0.0713, -0.0296, -0.1968,  ..., -0.3802, -0.5066, -0.3118],\n",
      "         [-0.5022,  0.0870, -0.6917,  ...,  0.7791,  0.3016, -0.2338],\n",
      "         [-0.2135,  0.5661,  0.2120,  ...,  1.3508, -2.4085, -0.9974],\n",
      "         ...,\n",
      "         [-0.1998,  0.1054,  1.3638,  ...,  0.0153,  0.6688,  1.3418],\n",
      "         [-1.9327,  3.2932,  2.3466,  ..., -0.6968, -1.9342,  2.5276],\n",
      "         [-1.5930,  3.2727,  1.2980,  ..., -0.5906, -1.1284,  0.4759]]]), tensor([[[ 0.1897,  0.3155, -0.3205,  ...,  0.0445, -0.6211, -0.0245],\n",
      "         [-0.5277,  0.4267, -1.0545,  ...,  0.9738, -0.0646, -0.5294],\n",
      "         [-0.3756,  0.2063,  0.1027,  ...,  1.1218, -2.9876, -0.9719],\n",
      "         ...,\n",
      "         [ 0.1199,  0.4664,  1.5785,  ...,  0.0315,  0.1680,  1.4248],\n",
      "         [-2.0089,  3.4767,  2.2171,  ..., -1.1279, -2.3210,  1.9302],\n",
      "         [-1.2504,  3.3843,  1.0933,  ..., -1.0512, -1.2884, -0.1392]]]), tensor([[[-0.4475,  1.3545, -0.6137,  ...,  0.1788, -0.0531,  0.3064],\n",
      "         [ 0.0149, -0.0477, -0.7075,  ...,  1.1375, -0.4238, -0.6128],\n",
      "         [-0.2335, -0.2991,  0.4946,  ...,  1.4792, -3.9328, -1.4876],\n",
      "         ...,\n",
      "         [ 0.0729, -0.0305,  1.6829,  ...,  0.6106, -0.3558,  1.0421],\n",
      "         [-1.8820,  3.0938,  2.7420,  ..., -0.8423, -3.1938,  1.4521],\n",
      "         [-1.0409,  3.0529,  0.9153,  ..., -0.6315, -1.7257, -0.2670]]]), tensor([[[-0.7844,  2.4187, -0.7710,  ...,  0.5041,  0.4723, -0.2954],\n",
      "         [ 0.6280,  0.0158, -0.7458,  ...,  1.3180, -0.4291, -0.7334],\n",
      "         [ 0.1725, -0.6851,  0.2948,  ...,  1.0713, -3.1548, -1.3083],\n",
      "         ...,\n",
      "         [ 0.5096, -0.4049,  2.1805,  ...,  0.6665, -0.5261,  0.9300],\n",
      "         [-1.3047,  1.9672,  2.3080,  ..., -0.9352, -2.3571,  1.1515],\n",
      "         [-0.3793,  2.5821,  0.4518,  ..., -1.0776, -1.4675, -0.2161]]])), attentions=None, cross_attentions=None)\n",
      "torch.Size([1, 19, 2560])\n",
      "33\n",
      "torch.Size([1, 19, 2560])\n"
     ]
    }
   ],
   "source": [
    "print(output_base)\n",
    "print(output_base.last_hidden_state.size())\n",
    "print(len(output_base.hidden_states))\n",
    "print(output_base.hidden_states[-1].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 19, 28896])\n",
      "tensor([12555,   293,     9,    59,   198,  1512,   273,   380,   678,    12,  1761,  9438,  9814,   319,   198,  3117,    25, 20933,   198])\n",
      "presenting*\\\n",
      " aim of that but-to pleural effusion with\n",
      "mediate: Ple\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logits_before_softmax = output_full.logits\n",
    "#print(logits_before_softmax)\n",
    "print(logits_before_softmax.size())\n",
    "prediction = logits_before_softmax[0].argmax(axis=-1)\n",
    "print(prediction)\n",
    "print(tokenizer2.decode(prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using pipeline for Text Generation ##\n",
    "Using pipeline to generate impressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xformers is not installed correctly. If you want to use memory_efficient_attention to accelerate training use the following command to install Xformers\n",
      "pip install xformers.\n"
     ]
    }
   ],
   "source": [
    "generation_pipeline = pipeline('text-generation', model=full_model2, tokenizer=tokenizer2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:28895 for open-end generation.\n",
      "/home/users/pranav.rao/miniconda3/envs/TutorialCuda/lib/python3.11/site-packages/transformers/generation/utils.py:1369: UserWarning: Using `max_length`'s default (50) to control the generation length. This behaviour is deprecated and will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "output_pipeline = generation_pipeline(masked_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'generated_text': 'Report: \\nThe report shows small right-sided pleural effusion\\n Impression: \\nCT scans of the patient revealed small right-sided pleural effusion and atelectasis of the right lower lobe. There was small nodule in the right'}]\n"
     ]
    }
   ],
   "source": [
    "print(output_pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:28895 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:28895 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:28895 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:28895 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "batched_reports = [summarization_prompt_gpt.replace('<REPORT>', report) for report in [dataset1_template, dataset1_pleural_issue, dataset2_template, dataset3_template]]\n",
    "output_pipeline2 = generation_pipeline(batched_reports, max_new_tokens=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[{'generated_text': 'Report: \\nxr- chest pa  view\\nfindings\\nlungs: normal.\\ntrachea: normal.\\ncarina: normal.\\nright and left main bronchi: normal.\\npleura: normal.\\nheart: normal.\\nright heart border: normal.\\nleft heart border: normal.\\npulmonary bay: normal.\\npulmonary hila: normal.\\naorta: normal.\\nthoracic spine: normal.\\nother visualized bones: normal.\\nvisualized soft tissues: normal.\\ndiaphragm: normal.\\nvisualized abdomen:  normal.\\nvisualized neck: normal.\\n Impression: \\\\`This patient has a 3rd degree tear, but no loss of substance is seen to the right eye. The conjunctiva is intact and red.'}], [{'generated_text': 'Report: \\n\\nxr- chest pa view\\nfindings\\nlungs: normal.\\ntrachea: normal.\\ncarina: normal.\\nright and left main bronchi: normal.\\npleura: left costophrenic angle is blunted with thin stripe of homogenous opacity along left lateral chest wall.\\nheart: normal.\\nright heart border: normal.\\nleft heart border: normal.\\npulmonary bay: normal.\\npulmonary hila: normal.\\naorta: normal.\\nthoracic spine: normal.\\nother visualized bones: normal.\\nvisualized soft tissues: normal.\\ndiaphragm: normal.\\nvisualized abdomen:  normal.\\nvisualized neck: normal.\\n Impression: \\\\*LEG DIAM: Normal \\\\*SUPRAMAX: Normal \\\\*HUM AND ADRENA LEFT'}], [{'generated_text': 'Report: \\n6191206|3862169|x-ray chest pa/ap view of 09-feb-2018:\\nresults:\\npost cabg status.\\nno focal lesion seen in the lung parenchyma.\\ncp angles and domes of the diaphragm are normal.\\nboth hila are normal. pulmonary vasculature is normal.\\ncardiac size and configuration is normal.\\ntrachea is central; no mediastinal shift is seen.\\nbony thorax and soft tissues of the chest wall are normal.\\nimpression: no abnormality detected in the view obtained.\\n\\n Impression:  Cardiomediastinal widening and slight right-sided cardiomegaly with flattening of the left ventricle may be present. The contour of the'}], [{'generated_text': 'Report: \\n\\nx-ray chest (pa view)\\nthe cardio thoracic ratio is normal.\\nthe heart size and configuration are within normal limits.\\nthe aortic arch is normal.\\nthe lung fields show normal broncho-vascular markings.\\nboth the pulmonary hila are normal in size.\\nthe costophrenic and cardiophrenic recesses and the domes of\\ndiaphragm are normal.\\nthe bones and soft tissues of the chest wall show no abnormality.\\nimpression : normal study.\\ndr.shakthi kumar\\nradiologist\\nss\\n________________________________________________________\\n\\n Impression: \\\\textsc {The} study demonstrates a normal study.If you would like to share with us our opinions as radiologists regarding the use of'}]]\n"
     ]
    }
   ],
   "source": [
    "print(output_pipeline2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TutorialCuda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
