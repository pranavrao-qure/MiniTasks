{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine-tuning RadBert #\n",
    "Full parameter fine tuning of RadBERT model (RadBERT-RoBERTa-4m model from the RadBERT paper). Fine tuning carried out on the multi-label muti-class classification of reports, where each report can have multiple labels (For ex, a report can havel label consolidation-right and consolidation-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/users/pranav.rao/miniconda3/envs/TutorialCuda/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time, datetime\n",
    "import codecs\n",
    "from itertools import product\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "import transformers\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Seeding everything for reproducibility\n",
    "def seed_everything(seed: int):    \n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "seed_everything(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 50)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.max_colwidth', 200)\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "torch.set_printoptions(linewidth=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "# Get cpu, gpu or mps device for training.\n",
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "device='cuda:1'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forward pass ##\n",
    "Implementing RadBERTMultiClassMulti Label PyTorch Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RadBERTMultiClassMultiLabel(nn.Module):\n",
    "    \"\"\"\n",
    "    RadBERTMultiClassMultiLabel: Model expects batches of natural language sentences, will\n",
    "    classify reports with multiple label\n",
    "    \"\"\"\n",
    "    def __init__(self, num_classes, checkpoint, device):\n",
    "        super().__init__()\n",
    "        self.num_classes = num_classes\n",
    "        self.checkpoint = checkpoint\n",
    "        self.device = device\n",
    "\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(self.checkpoint)\n",
    "        self.transformer_encoder = AutoModel.from_pretrained(self.checkpoint)\n",
    "        self.transformer_encoder_hidden_size = self.transformer_encoder.config.hidden_size\n",
    "        self.linear_classifier = nn.Linear(self.transformer_encoder_hidden_size, self.num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        tokenized_inp = self.tokenizer(x, padding=True, truncation=True, return_tensors='pt').to(self.device)\n",
    "        encoder_out = self.transformer_encoder(**tokenized_inp)\n",
    "        logits = self.linear_classifier(encoder_out.last_hidden_state[:, 0, :])\n",
    "        return logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = 'UCSD-VA-health/RadBERT-RoBERTa-4m'\n",
    "labels_subset = \"normal tuberculosis opacity bronchialdilation density parenchymalopacity ett aorticenlargement mediastinalwidening mediastinalmass\\\n",
    "        copd prominentbronchovascularmarkings bronchitis markings vascularprominence interval interstitiallungdisease bluntedcp effusion cardiomegaly\\\n",
    "        consolidation subtle_normal peffusion lineandtube thickening haziness hilarprominence hilar inhomogenousopacity rotation\\\n",
    "        calcification unfoldedaorta bandlikeopacity aorticcalcification aorticknucklecalcification fibrosis suture cardiacshift degenspine nodule\\\n",
    "        pneumonia inspiration fracture pneumonitis justfibrosis lesion nonaorticcalcification tuberculosispure pleuralthickening feedingtube\".split()\n",
    "num_classes = len(labels_subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "radbert_multi_model = RadBERTMultiClassMultiLabel(num_classes, checkpoint, device).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(radbert_multi_model)\n",
    "print(list(map(lambda x : x.shape, radbert_multi_model.parameters())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Loss function ##\n",
    "Custom loss function for multi class multi label classification to handle uncertain tags (tags have value 0 -> absent, 1 -> present, -100 -> uncertain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiClassMultiLabel(nn.Module):\n",
    "    def __init__(self, uncertain_label):\n",
    "        super(MultiClassMultiLabel, self).__init__()\n",
    "        self.uncertain_label = uncertain_label\n",
    "    \n",
    "    def forward(self, output, target):\n",
    "        certain_mask = (target != self.uncertain_label)\n",
    "        loss_func = nn.MultiLabelSoftMarginLoss(weight=certain_mask.type(torch.float))\n",
    "        return loss_func(output, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multiclass_multilabel_loss = MultiClassMultiLabel(-100).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing MultiClassMultiLabel loss function ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logit_tensor = torch.Tensor([[-1.0, 2.0, 1.0, 5.0, -3.0], [4.0, -2.0, 1.0, -1.0, 2.5]]).to(device)\n",
    "target_tensor_act = torch.Tensor([[0, 1, -100, 0, 0], [1, -100, 0, 0, 1]]).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#certain_mask = (target_tensor_act != -100)\n",
    "#print(certain_mask.type(torch.float))\n",
    "#loss_func = nn.MultiLabelSoftMarginLoss(weight=(certain_mask).type(torch.float))\n",
    "#print(loss_func(logit_tensor, target_tensor_act))\n",
    "print(multiclass_multilabel_loss(logit_tensor, target_tensor_act))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from math import log, exp\n",
    "\n",
    "def log_sigmoid(x):\n",
    "    return log(1/(1+exp(-1*x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss1 = -1 * (1.0 * log_sigmoid(1.0) + 1.0 * log_sigmoid(2.0) + 0.0 * log_sigmoid(-1.0) + 1.0 * log_sigmoid(-5.0) + 1.0 * log_sigmoid(3.0)) / 5.0\n",
    "loss2 = -1 * (1.0 * log_sigmoid(4.0) + 0.0 * log_sigmoid(2.0) + 1.0 * log_sigmoid(-1.0) + 1.0 * log_sigmoid(1.0) + 1.0 * log_sigmoid(2.5)) / 5.0\n",
    "\n",
    "print(loss1)\n",
    "print(loss2)\n",
    "print((loss1 + loss2)/2.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom DataLoader and Dataset ##\n",
    "Read csv file, get the report from path and prepare the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReportTagsDataset(Dataset):\n",
    "    def __init__(self, tags_csv_file, report_base_path, labels_subset=None, text_transform=None, target_transform=None):\n",
    "        self.report_base_path = report_base_path\n",
    "        self.tags_csv_file = tags_csv_file\n",
    "\n",
    "        self.tags_df = pd.read_csv(self.tags_csv_file)\n",
    "        self.column_names = list(self.tags_df.columns.values)\n",
    "        self.column_names[0] = 'filename'\n",
    "        self.tags_df.columns = self.column_names\n",
    "\n",
    "        self.labels_subset = labels_subset\n",
    "        self.text_transform = text_transform\n",
    "        self.target_transform = target_transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.tags_df.shape[0]\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        report_path = os.path.join(self.report_base_path, self.tags_df.iloc[index, 0].split('/')[-1] + '.txt')\n",
    "        #report_text = open(report_path).read()\n",
    "        report_text = codecs.open(report_path, 'r', encoding='utf-8', errors='ignore').read()\n",
    "        if self.labels_subset is None:\n",
    "            target_list = torch.Tensor(list(self.tags_df.iloc[index][1:]))\n",
    "        else:\n",
    "            target_list = torch.Tensor(list(self.tags_df[self.labels_subset].iloc[index]))\n",
    "        return report_text, target_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#report_base_path = \"/models_common_e2e/cxr_data/reports/training\"\n",
    "train_reports_base_path = '/home/users/pranav.rao/MiniTasks/Radbert/data/train'\n",
    "test_reports_base_path = '/home/users/pranav.rao/MiniTasks/Radbert/data/test'\n",
    "train_tags_file = '/home/users/pranav.rao/Downloads/report_tags_25k_train.csv'\n",
    "test_tags_file = '/home/users/pranav.rao/Downloads/report_tags_25k_test.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = ReportTagsDataset(train_tags_file, train_reports_base_path, labels_subset=labels_subset)\n",
    "test_data = ReportTagsDataset(test_tags_file, test_reports_base_path, labels_subset=labels_subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_data, batch_size=32, shuffle=True, num_workers=2)\n",
    "test_dataloader = DataLoader(test_data, batch_size=32, shuffle=True, num_workers=2)\n",
    "#train_dataloader = DataLoader(train_data, batch_size=32, shuffle=True)\n",
    "#test_dataloader = DataLoader(test_data, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing Dataset and DataLoader ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display image and label.\n",
    "train_features, train_labels = next(iter(train_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_features)\n",
    "print(train_labels)\n",
    "print(f\"Feature batch shape: {len(train_features)}\")\n",
    "print(f\"Labels batch shape: {len(train_labels)}\")\n",
    "report_text = train_features[0]\n",
    "print(report_text)\n",
    "label = train_labels[0]\n",
    "print(f\"Label: {label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    logit_tensor = radbert_multi_model(train_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(logit_tensor)\n",
    "print(logit_tensor.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine Tuning ##\n",
    "Fine tuning the RadBERT model for tags prediction task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adam Optimizer ###\n",
    "Using Adam optimizer with learning rate 3e-5, beta1 = 0.9, beta2 = 0.99, l2 weight decay of 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 3e-5\n",
    "beta1 = 0.9\n",
    "beta2 = 0.99\n",
    "l2_weight_decay = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(radbert_multi_model.parameters(), lr=lr, betas=(beta1, beta2), weight_decay=l2_weight_decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(epoch_index, tb_writer):\n",
    "    running_loss = 0.\n",
    "    last_loss = 0.\n",
    "\n",
    "    for i, data in enumerate(train_dataloader):\n",
    "        inputs, labels = data\n",
    "        labels = labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = radbert_multi_model(inputs)\n",
    "\n",
    "        # Compute the loss and its gradients\n",
    "        loss = multiclass_multilabel_loss(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Gather data and report\n",
    "        running_loss += loss.item()\n",
    "        if i % 50 == 49:\n",
    "            last_loss = running_loss / 50 # loss per batch\n",
    "            print('  batch {} loss: {}'.format(i + 1, last_loss))\n",
    "            tb_x = epoch_index * len(train_dataloader) + i + 1\n",
    "            tb_writer.add_scalar('Loss/train', last_loss, tb_x)\n",
    "            running_loss = 0.\n",
    "\n",
    "    return last_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The full fine-tuning loog ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_epochs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing in a separate cell so we can easily add more epochs to the same run\n",
    "timestamp = datetime.datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "writer = SummaryWriter('runs/fashion_trainer_{}'.format(timestamp))\n",
    "\n",
    "for epoch in range(total_epochs):\n",
    "    # Make sure gradient tracking is on, and do a pass over the data\n",
    "    print('EPOCH {}:'.format(epoch + 1))\n",
    "    radbert_multi_model.train(True)\n",
    "    avg_loss = train_one_epoch(epoch, writer)\n",
    "    model_path = '/home/users/pranav.rao/MiniTasks/Radbert/ModelPool/model_{}_{}'.format(timestamp, epoch)\n",
    "    torch.save(radbert_multi_model.state_dict(), model_path)\n",
    "\n",
    "    # Set the model to evaluation mode, disabling dropout and using population, statistics for batch normalization\n",
    "    running_vloss = 0.0\n",
    "    radbert_multi_model.eval()\n",
    "\n",
    "    # Disable gradient computation and reduce memory consumption.\n",
    "    with torch.no_grad():\n",
    "        for i, vdata in enumerate(test_dataloader):\n",
    "            vinputs, vlabels = vdata\n",
    "            vlabels = vlabels.to(device)\n",
    "            voutputs = radbert_multi_model(vinputs)\n",
    "            vloss = multiclass_multilabel_loss(voutputs, vlabels)\n",
    "            running_vloss += vloss\n",
    "\n",
    "    avg_vloss = running_vloss / (i + 1)\n",
    "    print('LOSS train {} valid {}'.format(avg_loss, avg_vloss))\n",
    "\n",
    "    # Log the running loss averaged per batch for both training and validation\n",
    "    writer.add_scalars('Training vs. Validation Loss',\n",
    "                    { 'Training' : avg_loss, 'Validation' : avg_vloss },\n",
    "                    epoch + 1)\n",
    "    writer.flush()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyzing fine-tuned models ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_list = [\"The report shows small right-sided pleural effusion\", \"The report shows small left-sided pleural effusion\",\\\n",
    "    \"The report shows large right-sided pleural effusion\", \"The report shows large left-sided pleural effusion\",\\\n",
    "    \"There are no abnormalities in the report\",\\\n",
    "    \"There is severe consolidation in the left side\",\"There is severe consolidation in the right side\",\\\n",
    "    \"There is mild consolidation in the right side\", \"There is mild consolidation in the left side\"\n",
    "]\n",
    "\n",
    "sentence1_base = \"A <SizeModifier> <AbnormalReport> can be seen in the report in the <LocationModifier> part\"\n",
    "sentence2_base = \"The report shows a <SizeModifier> <LocationModifier> <AbnormalReport>\"\n",
    "size_modifiers = ['small', 'large']\n",
    "loc_modifiers = ['upper-left', 'lower-left', 'right-sided', 'left-sided']\n",
    "abnormal_report = ['pleural effusion']\n",
    "\n",
    "l1 = [sentence1_base.replace('<SizeModifier>', size_mod).replace('<LocationModifier>', loc_mod).replace('<AbnormalReport>', ab_rep) for size_mod, loc_mod, ab_rep in product(size_modifiers, loc_modifiers, abnormal_report)]\n",
    "l2 = [sentence2_base.replace('<SizeModifier>', size_mod).replace('<LocationModifier>', loc_mod).replace('<AbnormalReport>', ab_rep) for size_mod, loc_mod, ab_rep in product(size_modifiers, loc_modifiers, abnormal_report)]\n",
    "\n",
    "negative_sentences = ['The report shows no pleural effusion', 'The report shows no consolidation on any side']\n",
    "all_sentence_list = l1 + l2 + negative_sentences + sentence_list[4:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A small pleural effusion can be seen in the report in the upper-left part\n",
      "A small pleural effusion can be seen in the report in the lower-left part\n",
      "A small pleural effusion can be seen in the report in the right-sided part\n",
      "A small pleural effusion can be seen in the report in the left-sided part\n",
      "A large pleural effusion can be seen in the report in the upper-left part\n",
      "A large pleural effusion can be seen in the report in the lower-left part\n",
      "A large pleural effusion can be seen in the report in the right-sided part\n",
      "A large pleural effusion can be seen in the report in the left-sided part\n",
      "The report shows a small upper-left pleural effusion\n",
      "The report shows a small lower-left pleural effusion\n",
      "The report shows a small right-sided pleural effusion\n",
      "The report shows a small left-sided pleural effusion\n",
      "The report shows a large upper-left pleural effusion\n",
      "The report shows a large lower-left pleural effusion\n",
      "The report shows a large right-sided pleural effusion\n",
      "The report shows a large left-sided pleural effusion\n",
      "The report shows no pleural effusion\n",
      "The report shows no consolidation on any side\n",
      "There are no abnormalities in the report\n",
      "There is severe consolidation in the left side\n",
      "There is severe consolidation in the right side\n",
      "There is mild consolidation in the right side\n",
      "There is mild consolidation in the left side\n"
     ]
    }
   ],
   "source": [
    "print('\\n'.join(all_sentence_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentence_embeddings(model, input):\n",
    "    with torch.no_grad():\n",
    "        tokenized_inp = model.tokenizer(input, padding=True, truncation=True, return_tensors='pt').to(device)\n",
    "        encoder_out = model.transformer_encoder(**tokenized_inp)\n",
    "    return encoder_out.last_hidden_state[:, 0, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_cosine_sim_matrix(sentence_embeddings):\n",
    "    cosine_sim_matrix = F.cosine_similarity(sentence_embeddings.unsqueeze(1), sentence_embeddings.unsqueeze(0), dim=2)\n",
    "    return cosine_sim_matrix.cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at UCSD-VA-health/RadBERT-RoBERTa-4m and are newly initialized: ['roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_path = '/home/users/pranav.rao/MiniTasks/Radbert/ModelPool/model_20230914_160336_0'\n",
    "radbert_multi_model = RadBERTMultiClassMultiLabel(num_classes, checkpoint, device).to(device)\n",
    "radbert_multi_model.load_state_dict(torch.load(model_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_embeddings = get_sentence_embeddings(radbert_multi_model, all_sentence_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 2.8910e-01, -5.2085e-01,  2.6253e-01,  ..., -1.8994e+00,  1.7182e-01,  1.3341e-02],\n",
      "        [ 2.8928e-01, -5.4022e-01,  2.6898e-01,  ..., -1.9484e+00,  1.8694e-01,  2.6540e-03],\n",
      "        [ 2.5743e-01, -5.3418e-01,  2.6586e-01,  ..., -1.8983e+00,  2.0071e-01, -5.6288e-02],\n",
      "        ...,\n",
      "        [ 4.0400e-01, -4.9373e-01, -2.8056e-01,  ..., -1.2606e+00, -4.3174e-03, -5.0392e-01],\n",
      "        [ 4.3134e-01, -4.1540e-01, -2.8964e-01,  ..., -1.2568e+00, -1.1965e-03, -5.4829e-01],\n",
      "        [ 4.4349e-01, -4.3328e-01, -2.7744e-01,  ..., -1.2366e+00,  4.1675e-02, -5.2168e-01]], device='cuda:1')\n",
      "torch.Size([23, 768])\n"
     ]
    }
   ],
   "source": [
    "print(all_embeddings)\n",
    "print(all_embeddings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999362</td>\n",
       "      <td>0.998332</td>\n",
       "      <td>0.998653</td>\n",
       "      <td>0.997801</td>\n",
       "      <td>0.998091</td>\n",
       "      <td>0.995831</td>\n",
       "      <td>0.996154</td>\n",
       "      <td>0.983204</td>\n",
       "      <td>0.979679</td>\n",
       "      <td>0.979361</td>\n",
       "      <td>0.980066</td>\n",
       "      <td>0.982224</td>\n",
       "      <td>0.980238</td>\n",
       "      <td>0.978228</td>\n",
       "      <td>0.978952</td>\n",
       "      <td>0.835743</td>\n",
       "      <td>0.546055</td>\n",
       "      <td>0.377079</td>\n",
       "      <td>0.851285</td>\n",
       "      <td>0.846197</td>\n",
       "      <td>0.839327</td>\n",
       "      <td>0.845008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.999362</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998027</td>\n",
       "      <td>0.998405</td>\n",
       "      <td>0.996324</td>\n",
       "      <td>0.997885</td>\n",
       "      <td>0.994678</td>\n",
       "      <td>0.995062</td>\n",
       "      <td>0.983346</td>\n",
       "      <td>0.981498</td>\n",
       "      <td>0.979830</td>\n",
       "      <td>0.980501</td>\n",
       "      <td>0.981407</td>\n",
       "      <td>0.981093</td>\n",
       "      <td>0.977705</td>\n",
       "      <td>0.978427</td>\n",
       "      <td>0.839366</td>\n",
       "      <td>0.548812</td>\n",
       "      <td>0.378454</td>\n",
       "      <td>0.848724</td>\n",
       "      <td>0.843807</td>\n",
       "      <td>0.838068</td>\n",
       "      <td>0.843557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.998332</td>\n",
       "      <td>0.998027</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999480</td>\n",
       "      <td>0.996540</td>\n",
       "      <td>0.997042</td>\n",
       "      <td>0.997856</td>\n",
       "      <td>0.997323</td>\n",
       "      <td>0.983783</td>\n",
       "      <td>0.980915</td>\n",
       "      <td>0.983602</td>\n",
       "      <td>0.983302</td>\n",
       "      <td>0.983361</td>\n",
       "      <td>0.981940</td>\n",
       "      <td>0.982964</td>\n",
       "      <td>0.982605</td>\n",
       "      <td>0.837907</td>\n",
       "      <td>0.548808</td>\n",
       "      <td>0.380906</td>\n",
       "      <td>0.852061</td>\n",
       "      <td>0.848010</td>\n",
       "      <td>0.840563</td>\n",
       "      <td>0.845241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.998653</td>\n",
       "      <td>0.998405</td>\n",
       "      <td>0.999480</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.996919</td>\n",
       "      <td>0.997489</td>\n",
       "      <td>0.997374</td>\n",
       "      <td>0.997885</td>\n",
       "      <td>0.984088</td>\n",
       "      <td>0.981301</td>\n",
       "      <td>0.982959</td>\n",
       "      <td>0.983830</td>\n",
       "      <td>0.983676</td>\n",
       "      <td>0.982357</td>\n",
       "      <td>0.982280</td>\n",
       "      <td>0.983130</td>\n",
       "      <td>0.837925</td>\n",
       "      <td>0.546504</td>\n",
       "      <td>0.380839</td>\n",
       "      <td>0.850527</td>\n",
       "      <td>0.845046</td>\n",
       "      <td>0.837743</td>\n",
       "      <td>0.843712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.997801</td>\n",
       "      <td>0.996324</td>\n",
       "      <td>0.996540</td>\n",
       "      <td>0.996919</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999346</td>\n",
       "      <td>0.998370</td>\n",
       "      <td>0.998721</td>\n",
       "      <td>0.981196</td>\n",
       "      <td>0.976589</td>\n",
       "      <td>0.977573</td>\n",
       "      <td>0.978383</td>\n",
       "      <td>0.984514</td>\n",
       "      <td>0.981260</td>\n",
       "      <td>0.980614</td>\n",
       "      <td>0.981406</td>\n",
       "      <td>0.828108</td>\n",
       "      <td>0.539589</td>\n",
       "      <td>0.376278</td>\n",
       "      <td>0.856504</td>\n",
       "      <td>0.850981</td>\n",
       "      <td>0.837227</td>\n",
       "      <td>0.843240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.998091</td>\n",
       "      <td>0.997885</td>\n",
       "      <td>0.997042</td>\n",
       "      <td>0.997489</td>\n",
       "      <td>0.999346</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.997928</td>\n",
       "      <td>0.998356</td>\n",
       "      <td>0.982041</td>\n",
       "      <td>0.979062</td>\n",
       "      <td>0.978660</td>\n",
       "      <td>0.979453</td>\n",
       "      <td>0.984260</td>\n",
       "      <td>0.982671</td>\n",
       "      <td>0.980580</td>\n",
       "      <td>0.981401</td>\n",
       "      <td>0.832623</td>\n",
       "      <td>0.542873</td>\n",
       "      <td>0.377468</td>\n",
       "      <td>0.854485</td>\n",
       "      <td>0.849156</td>\n",
       "      <td>0.836687</td>\n",
       "      <td>0.842494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.995831</td>\n",
       "      <td>0.994678</td>\n",
       "      <td>0.997856</td>\n",
       "      <td>0.997374</td>\n",
       "      <td>0.998370</td>\n",
       "      <td>0.997928</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999473</td>\n",
       "      <td>0.981284</td>\n",
       "      <td>0.977302</td>\n",
       "      <td>0.981292</td>\n",
       "      <td>0.981076</td>\n",
       "      <td>0.985090</td>\n",
       "      <td>0.982373</td>\n",
       "      <td>0.984784</td>\n",
       "      <td>0.984471</td>\n",
       "      <td>0.829851</td>\n",
       "      <td>0.542189</td>\n",
       "      <td>0.379882</td>\n",
       "      <td>0.857028</td>\n",
       "      <td>0.852585</td>\n",
       "      <td>0.838364</td>\n",
       "      <td>0.843347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.996154</td>\n",
       "      <td>0.995062</td>\n",
       "      <td>0.997323</td>\n",
       "      <td>0.997885</td>\n",
       "      <td>0.998721</td>\n",
       "      <td>0.998356</td>\n",
       "      <td>0.999473</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.981551</td>\n",
       "      <td>0.977648</td>\n",
       "      <td>0.980607</td>\n",
       "      <td>0.981573</td>\n",
       "      <td>0.985344</td>\n",
       "      <td>0.982731</td>\n",
       "      <td>0.984031</td>\n",
       "      <td>0.984946</td>\n",
       "      <td>0.829844</td>\n",
       "      <td>0.539733</td>\n",
       "      <td>0.379700</td>\n",
       "      <td>0.855425</td>\n",
       "      <td>0.849545</td>\n",
       "      <td>0.835537</td>\n",
       "      <td>0.841809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.983204</td>\n",
       "      <td>0.983346</td>\n",
       "      <td>0.983783</td>\n",
       "      <td>0.984088</td>\n",
       "      <td>0.981196</td>\n",
       "      <td>0.982041</td>\n",
       "      <td>0.981284</td>\n",
       "      <td>0.981551</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998734</td>\n",
       "      <td>0.997494</td>\n",
       "      <td>0.997905</td>\n",
       "      <td>0.997682</td>\n",
       "      <td>0.997897</td>\n",
       "      <td>0.994989</td>\n",
       "      <td>0.995401</td>\n",
       "      <td>0.881359</td>\n",
       "      <td>0.592676</td>\n",
       "      <td>0.418623</td>\n",
       "      <td>0.845569</td>\n",
       "      <td>0.840733</td>\n",
       "      <td>0.833136</td>\n",
       "      <td>0.838781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.979679</td>\n",
       "      <td>0.981498</td>\n",
       "      <td>0.980915</td>\n",
       "      <td>0.981301</td>\n",
       "      <td>0.976589</td>\n",
       "      <td>0.979062</td>\n",
       "      <td>0.977302</td>\n",
       "      <td>0.977648</td>\n",
       "      <td>0.998734</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.996861</td>\n",
       "      <td>0.997200</td>\n",
       "      <td>0.995149</td>\n",
       "      <td>0.997864</td>\n",
       "      <td>0.993045</td>\n",
       "      <td>0.993392</td>\n",
       "      <td>0.885705</td>\n",
       "      <td>0.597680</td>\n",
       "      <td>0.421948</td>\n",
       "      <td>0.841118</td>\n",
       "      <td>0.836497</td>\n",
       "      <td>0.830509</td>\n",
       "      <td>0.835895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.979361</td>\n",
       "      <td>0.979830</td>\n",
       "      <td>0.983602</td>\n",
       "      <td>0.982959</td>\n",
       "      <td>0.977573</td>\n",
       "      <td>0.978660</td>\n",
       "      <td>0.981292</td>\n",
       "      <td>0.980607</td>\n",
       "      <td>0.997494</td>\n",
       "      <td>0.996861</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999273</td>\n",
       "      <td>0.995555</td>\n",
       "      <td>0.996352</td>\n",
       "      <td>0.997796</td>\n",
       "      <td>0.997031</td>\n",
       "      <td>0.882449</td>\n",
       "      <td>0.597828</td>\n",
       "      <td>0.424707</td>\n",
       "      <td>0.848117</td>\n",
       "      <td>0.844687</td>\n",
       "      <td>0.837462</td>\n",
       "      <td>0.841748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.980066</td>\n",
       "      <td>0.980501</td>\n",
       "      <td>0.983302</td>\n",
       "      <td>0.983830</td>\n",
       "      <td>0.978383</td>\n",
       "      <td>0.979453</td>\n",
       "      <td>0.981076</td>\n",
       "      <td>0.981573</td>\n",
       "      <td>0.997905</td>\n",
       "      <td>0.997200</td>\n",
       "      <td>0.999273</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.996072</td>\n",
       "      <td>0.996822</td>\n",
       "      <td>0.997123</td>\n",
       "      <td>0.997854</td>\n",
       "      <td>0.881959</td>\n",
       "      <td>0.594092</td>\n",
       "      <td>0.424421</td>\n",
       "      <td>0.847063</td>\n",
       "      <td>0.841923</td>\n",
       "      <td>0.834860</td>\n",
       "      <td>0.840694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.982224</td>\n",
       "      <td>0.981407</td>\n",
       "      <td>0.983361</td>\n",
       "      <td>0.983676</td>\n",
       "      <td>0.984514</td>\n",
       "      <td>0.984260</td>\n",
       "      <td>0.985090</td>\n",
       "      <td>0.985344</td>\n",
       "      <td>0.997682</td>\n",
       "      <td>0.995149</td>\n",
       "      <td>0.995555</td>\n",
       "      <td>0.996072</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998733</td>\n",
       "      <td>0.997544</td>\n",
       "      <td>0.998001</td>\n",
       "      <td>0.870615</td>\n",
       "      <td>0.582113</td>\n",
       "      <td>0.415852</td>\n",
       "      <td>0.851035</td>\n",
       "      <td>0.845756</td>\n",
       "      <td>0.831414</td>\n",
       "      <td>0.837355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.980238</td>\n",
       "      <td>0.981093</td>\n",
       "      <td>0.981940</td>\n",
       "      <td>0.982357</td>\n",
       "      <td>0.981260</td>\n",
       "      <td>0.982671</td>\n",
       "      <td>0.982373</td>\n",
       "      <td>0.982731</td>\n",
       "      <td>0.997897</td>\n",
       "      <td>0.997864</td>\n",
       "      <td>0.996352</td>\n",
       "      <td>0.996822</td>\n",
       "      <td>0.998733</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.996829</td>\n",
       "      <td>0.997257</td>\n",
       "      <td>0.876257</td>\n",
       "      <td>0.587768</td>\n",
       "      <td>0.419144</td>\n",
       "      <td>0.847764</td>\n",
       "      <td>0.842700</td>\n",
       "      <td>0.830206</td>\n",
       "      <td>0.835898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.978228</td>\n",
       "      <td>0.977705</td>\n",
       "      <td>0.982964</td>\n",
       "      <td>0.982280</td>\n",
       "      <td>0.980614</td>\n",
       "      <td>0.980580</td>\n",
       "      <td>0.984784</td>\n",
       "      <td>0.984031</td>\n",
       "      <td>0.994989</td>\n",
       "      <td>0.993045</td>\n",
       "      <td>0.997796</td>\n",
       "      <td>0.997123</td>\n",
       "      <td>0.997544</td>\n",
       "      <td>0.996829</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999216</td>\n",
       "      <td>0.871267</td>\n",
       "      <td>0.586815</td>\n",
       "      <td>0.421193</td>\n",
       "      <td>0.853612</td>\n",
       "      <td>0.849802</td>\n",
       "      <td>0.836035</td>\n",
       "      <td>0.840584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.978952</td>\n",
       "      <td>0.978427</td>\n",
       "      <td>0.982605</td>\n",
       "      <td>0.983130</td>\n",
       "      <td>0.981406</td>\n",
       "      <td>0.981401</td>\n",
       "      <td>0.984471</td>\n",
       "      <td>0.984946</td>\n",
       "      <td>0.995401</td>\n",
       "      <td>0.993392</td>\n",
       "      <td>0.997031</td>\n",
       "      <td>0.997854</td>\n",
       "      <td>0.998001</td>\n",
       "      <td>0.997257</td>\n",
       "      <td>0.999216</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.871259</td>\n",
       "      <td>0.583699</td>\n",
       "      <td>0.421267</td>\n",
       "      <td>0.852595</td>\n",
       "      <td>0.847072</td>\n",
       "      <td>0.833581</td>\n",
       "      <td>0.839667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.835743</td>\n",
       "      <td>0.839366</td>\n",
       "      <td>0.837907</td>\n",
       "      <td>0.837925</td>\n",
       "      <td>0.828108</td>\n",
       "      <td>0.832623</td>\n",
       "      <td>0.829851</td>\n",
       "      <td>0.829844</td>\n",
       "      <td>0.881359</td>\n",
       "      <td>0.885705</td>\n",
       "      <td>0.882449</td>\n",
       "      <td>0.881959</td>\n",
       "      <td>0.870615</td>\n",
       "      <td>0.876257</td>\n",
       "      <td>0.871267</td>\n",
       "      <td>0.871259</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.791332</td>\n",
       "      <td>0.654633</td>\n",
       "      <td>0.685575</td>\n",
       "      <td>0.686118</td>\n",
       "      <td>0.698785</td>\n",
       "      <td>0.699601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.546055</td>\n",
       "      <td>0.548812</td>\n",
       "      <td>0.548808</td>\n",
       "      <td>0.546504</td>\n",
       "      <td>0.539589</td>\n",
       "      <td>0.542873</td>\n",
       "      <td>0.542189</td>\n",
       "      <td>0.539733</td>\n",
       "      <td>0.592676</td>\n",
       "      <td>0.597680</td>\n",
       "      <td>0.597828</td>\n",
       "      <td>0.594092</td>\n",
       "      <td>0.582113</td>\n",
       "      <td>0.587768</td>\n",
       "      <td>0.586815</td>\n",
       "      <td>0.583699</td>\n",
       "      <td>0.791332</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.803640</td>\n",
       "      <td>0.627644</td>\n",
       "      <td>0.633764</td>\n",
       "      <td>0.653857</td>\n",
       "      <td>0.649462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.377079</td>\n",
       "      <td>0.378454</td>\n",
       "      <td>0.380906</td>\n",
       "      <td>0.380839</td>\n",
       "      <td>0.376278</td>\n",
       "      <td>0.377468</td>\n",
       "      <td>0.379882</td>\n",
       "      <td>0.379700</td>\n",
       "      <td>0.418623</td>\n",
       "      <td>0.421948</td>\n",
       "      <td>0.424707</td>\n",
       "      <td>0.424421</td>\n",
       "      <td>0.415852</td>\n",
       "      <td>0.419144</td>\n",
       "      <td>0.421193</td>\n",
       "      <td>0.421267</td>\n",
       "      <td>0.654633</td>\n",
       "      <td>0.803640</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.393651</td>\n",
       "      <td>0.397461</td>\n",
       "      <td>0.408729</td>\n",
       "      <td>0.405719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.851285</td>\n",
       "      <td>0.848724</td>\n",
       "      <td>0.852061</td>\n",
       "      <td>0.850527</td>\n",
       "      <td>0.856504</td>\n",
       "      <td>0.854485</td>\n",
       "      <td>0.857028</td>\n",
       "      <td>0.855425</td>\n",
       "      <td>0.845569</td>\n",
       "      <td>0.841118</td>\n",
       "      <td>0.848117</td>\n",
       "      <td>0.847063</td>\n",
       "      <td>0.851035</td>\n",
       "      <td>0.847764</td>\n",
       "      <td>0.853612</td>\n",
       "      <td>0.852595</td>\n",
       "      <td>0.685575</td>\n",
       "      <td>0.627644</td>\n",
       "      <td>0.393651</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998409</td>\n",
       "      <td>0.985642</td>\n",
       "      <td>0.988353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.846197</td>\n",
       "      <td>0.843807</td>\n",
       "      <td>0.848010</td>\n",
       "      <td>0.845046</td>\n",
       "      <td>0.850981</td>\n",
       "      <td>0.849156</td>\n",
       "      <td>0.852585</td>\n",
       "      <td>0.849545</td>\n",
       "      <td>0.840733</td>\n",
       "      <td>0.836497</td>\n",
       "      <td>0.844687</td>\n",
       "      <td>0.841923</td>\n",
       "      <td>0.845756</td>\n",
       "      <td>0.842700</td>\n",
       "      <td>0.849802</td>\n",
       "      <td>0.847072</td>\n",
       "      <td>0.686118</td>\n",
       "      <td>0.633764</td>\n",
       "      <td>0.397461</td>\n",
       "      <td>0.998409</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.988591</td>\n",
       "      <td>0.988372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.839327</td>\n",
       "      <td>0.838068</td>\n",
       "      <td>0.840563</td>\n",
       "      <td>0.837743</td>\n",
       "      <td>0.837227</td>\n",
       "      <td>0.836687</td>\n",
       "      <td>0.838364</td>\n",
       "      <td>0.835537</td>\n",
       "      <td>0.833136</td>\n",
       "      <td>0.830509</td>\n",
       "      <td>0.837462</td>\n",
       "      <td>0.834860</td>\n",
       "      <td>0.831414</td>\n",
       "      <td>0.830206</td>\n",
       "      <td>0.836035</td>\n",
       "      <td>0.833581</td>\n",
       "      <td>0.698785</td>\n",
       "      <td>0.653857</td>\n",
       "      <td>0.408729</td>\n",
       "      <td>0.985642</td>\n",
       "      <td>0.988591</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.998598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.845008</td>\n",
       "      <td>0.843557</td>\n",
       "      <td>0.845241</td>\n",
       "      <td>0.843712</td>\n",
       "      <td>0.843240</td>\n",
       "      <td>0.842494</td>\n",
       "      <td>0.843347</td>\n",
       "      <td>0.841809</td>\n",
       "      <td>0.838781</td>\n",
       "      <td>0.835895</td>\n",
       "      <td>0.841748</td>\n",
       "      <td>0.840694</td>\n",
       "      <td>0.837355</td>\n",
       "      <td>0.835898</td>\n",
       "      <td>0.840584</td>\n",
       "      <td>0.839667</td>\n",
       "      <td>0.699601</td>\n",
       "      <td>0.649462</td>\n",
       "      <td>0.405719</td>\n",
       "      <td>0.988353</td>\n",
       "      <td>0.988372</td>\n",
       "      <td>0.998598</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6         7         8         9         10        11        12        13        14        15        16        17        18        19        20        21        22\n",
       "0   1.000000  0.999362  0.998332  0.998653  0.997801  0.998091  0.995831  0.996154  0.983204  0.979679  0.979361  0.980066  0.982224  0.980238  0.978228  0.978952  0.835743  0.546055  0.377079  0.851285  0.846197  0.839327  0.845008\n",
       "1   0.999362  1.000000  0.998027  0.998405  0.996324  0.997885  0.994678  0.995062  0.983346  0.981498  0.979830  0.980501  0.981407  0.981093  0.977705  0.978427  0.839366  0.548812  0.378454  0.848724  0.843807  0.838068  0.843557\n",
       "2   0.998332  0.998027  1.000000  0.999480  0.996540  0.997042  0.997856  0.997323  0.983783  0.980915  0.983602  0.983302  0.983361  0.981940  0.982964  0.982605  0.837907  0.548808  0.380906  0.852061  0.848010  0.840563  0.845241\n",
       "3   0.998653  0.998405  0.999480  1.000000  0.996919  0.997489  0.997374  0.997885  0.984088  0.981301  0.982959  0.983830  0.983676  0.982357  0.982280  0.983130  0.837925  0.546504  0.380839  0.850527  0.845046  0.837743  0.843712\n",
       "4   0.997801  0.996324  0.996540  0.996919  1.000000  0.999346  0.998370  0.998721  0.981196  0.976589  0.977573  0.978383  0.984514  0.981260  0.980614  0.981406  0.828108  0.539589  0.376278  0.856504  0.850981  0.837227  0.843240\n",
       "5   0.998091  0.997885  0.997042  0.997489  0.999346  1.000000  0.997928  0.998356  0.982041  0.979062  0.978660  0.979453  0.984260  0.982671  0.980580  0.981401  0.832623  0.542873  0.377468  0.854485  0.849156  0.836687  0.842494\n",
       "6   0.995831  0.994678  0.997856  0.997374  0.998370  0.997928  1.000000  0.999473  0.981284  0.977302  0.981292  0.981076  0.985090  0.982373  0.984784  0.984471  0.829851  0.542189  0.379882  0.857028  0.852585  0.838364  0.843347\n",
       "7   0.996154  0.995062  0.997323  0.997885  0.998721  0.998356  0.999473  1.000000  0.981551  0.977648  0.980607  0.981573  0.985344  0.982731  0.984031  0.984946  0.829844  0.539733  0.379700  0.855425  0.849545  0.835537  0.841809\n",
       "8   0.983204  0.983346  0.983783  0.984088  0.981196  0.982041  0.981284  0.981551  1.000000  0.998734  0.997494  0.997905  0.997682  0.997897  0.994989  0.995401  0.881359  0.592676  0.418623  0.845569  0.840733  0.833136  0.838781\n",
       "9   0.979679  0.981498  0.980915  0.981301  0.976589  0.979062  0.977302  0.977648  0.998734  1.000000  0.996861  0.997200  0.995149  0.997864  0.993045  0.993392  0.885705  0.597680  0.421948  0.841118  0.836497  0.830509  0.835895\n",
       "10  0.979361  0.979830  0.983602  0.982959  0.977573  0.978660  0.981292  0.980607  0.997494  0.996861  1.000000  0.999273  0.995555  0.996352  0.997796  0.997031  0.882449  0.597828  0.424707  0.848117  0.844687  0.837462  0.841748\n",
       "11  0.980066  0.980501  0.983302  0.983830  0.978383  0.979453  0.981076  0.981573  0.997905  0.997200  0.999273  1.000000  0.996072  0.996822  0.997123  0.997854  0.881959  0.594092  0.424421  0.847063  0.841923  0.834860  0.840694\n",
       "12  0.982224  0.981407  0.983361  0.983676  0.984514  0.984260  0.985090  0.985344  0.997682  0.995149  0.995555  0.996072  1.000000  0.998733  0.997544  0.998001  0.870615  0.582113  0.415852  0.851035  0.845756  0.831414  0.837355\n",
       "13  0.980238  0.981093  0.981940  0.982357  0.981260  0.982671  0.982373  0.982731  0.997897  0.997864  0.996352  0.996822  0.998733  1.000000  0.996829  0.997257  0.876257  0.587768  0.419144  0.847764  0.842700  0.830206  0.835898\n",
       "14  0.978228  0.977705  0.982964  0.982280  0.980614  0.980580  0.984784  0.984031  0.994989  0.993045  0.997796  0.997123  0.997544  0.996829  1.000000  0.999216  0.871267  0.586815  0.421193  0.853612  0.849802  0.836035  0.840584\n",
       "15  0.978952  0.978427  0.982605  0.983130  0.981406  0.981401  0.984471  0.984946  0.995401  0.993392  0.997031  0.997854  0.998001  0.997257  0.999216  1.000000  0.871259  0.583699  0.421267  0.852595  0.847072  0.833581  0.839667\n",
       "16  0.835743  0.839366  0.837907  0.837925  0.828108  0.832623  0.829851  0.829844  0.881359  0.885705  0.882449  0.881959  0.870615  0.876257  0.871267  0.871259  1.000000  0.791332  0.654633  0.685575  0.686118  0.698785  0.699601\n",
       "17  0.546055  0.548812  0.548808  0.546504  0.539589  0.542873  0.542189  0.539733  0.592676  0.597680  0.597828  0.594092  0.582113  0.587768  0.586815  0.583699  0.791332  1.000000  0.803640  0.627644  0.633764  0.653857  0.649462\n",
       "18  0.377079  0.378454  0.380906  0.380839  0.376278  0.377468  0.379882  0.379700  0.418623  0.421948  0.424707  0.424421  0.415852  0.419144  0.421193  0.421267  0.654633  0.803640  1.000000  0.393651  0.397461  0.408729  0.405719\n",
       "19  0.851285  0.848724  0.852061  0.850527  0.856504  0.854485  0.857028  0.855425  0.845569  0.841118  0.848117  0.847063  0.851035  0.847764  0.853612  0.852595  0.685575  0.627644  0.393651  1.000000  0.998409  0.985642  0.988353\n",
       "20  0.846197  0.843807  0.848010  0.845046  0.850981  0.849156  0.852585  0.849545  0.840733  0.836497  0.844687  0.841923  0.845756  0.842700  0.849802  0.847072  0.686118  0.633764  0.397461  0.998409  1.000000  0.988591  0.988372\n",
       "21  0.839327  0.838068  0.840563  0.837743  0.837227  0.836687  0.838364  0.835537  0.833136  0.830509  0.837462  0.834860  0.831414  0.830206  0.836035  0.833581  0.698785  0.653857  0.408729  0.985642  0.988591  1.000000  0.998598\n",
       "22  0.845008  0.843557  0.845241  0.843712  0.843240  0.842494  0.843347  0.841809  0.838781  0.835895  0.841748  0.840694  0.837355  0.835898  0.840584  0.839667  0.699601  0.649462  0.405719  0.988353  0.988372  0.998598  1.000000"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_sim = calc_cosine_sim_matrix(all_embeddings)\n",
    "pd.DataFrame(cosine_sim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysing the predictions ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictions(model, input):\n",
    "    with torch.no_grad():\n",
    "        tokenized_inp = model.tokenizer(input, padding=True, truncation=True, return_tensors='pt').to(device)\n",
    "        encoder_out = model.transformer_encoder(**tokenized_inp)\n",
    "        logits = model.linear_classifier(encoder_out.last_hidden_state[:, 0, :])\n",
    "        return logits.cpu().detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyse_predictions(prediction_list, sentence_list):\n",
    "    cols = ['Sentence', 'Best label', 'Best label score', 'Positive label']\n",
    "    values = list()\n",
    "    for (report, pred) in zip(sentence_list, prediction_list.numpy()):\n",
    "        best_label = labels_subset[pred.argmax()]\n",
    "        best_label_score = pred.max()\n",
    "        positive_label = ','.join([labels_subset[i] for i, e in enumerate(pred) if e > 0.0])\n",
    "        values.append([report, best_label, best_label_score, positive_label])\n",
    "    return pd.DataFrame(values, columns=cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = get_predictions(radbert_multi_model, all_sentence_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-2.0112,  1.7688,  0.9222,  ..., -1.5026, -0.9682, -1.3388],\n",
      "        [-2.0314,  1.7700,  0.9226,  ..., -1.5127, -0.9895, -1.3558],\n",
      "        [-1.9688,  1.7081,  0.8782,  ..., -1.4596, -0.9512, -1.2824],\n",
      "        ...,\n",
      "        [-2.6790,  1.9450,  1.5734,  ..., -1.4788, -1.4831, -1.8072],\n",
      "        [-2.5836,  1.7072,  1.3661,  ..., -1.5444, -1.5293, -1.7637],\n",
      "        [-2.6173,  1.7095,  1.4057,  ..., -1.5698, -1.5230, -1.7579]])\n",
      "torch.Size([23, 50])\n"
     ]
    }
   ],
   "source": [
    "print(predictions)\n",
    "print(predictions.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Best label</th>\n",
       "      <th>Best label score</th>\n",
       "      <th>Positive label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A small pleural effusion can be seen in the report in the upper-left part</td>\n",
       "      <td>tuberculosis</td>\n",
       "      <td>1.768771</td>\n",
       "      <td>tuberculosis,opacity,bronchialdilation,parenchymalopacity,effusion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A small pleural effusion can be seen in the report in the lower-left part</td>\n",
       "      <td>tuberculosis</td>\n",
       "      <td>1.769983</td>\n",
       "      <td>tuberculosis,opacity,parenchymalopacity,effusion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A small pleural effusion can be seen in the report in the right-sided part</td>\n",
       "      <td>tuberculosis</td>\n",
       "      <td>1.708109</td>\n",
       "      <td>tuberculosis,opacity,parenchymalopacity,effusion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A small pleural effusion can be seen in the report in the left-sided part</td>\n",
       "      <td>tuberculosis</td>\n",
       "      <td>1.683801</td>\n",
       "      <td>tuberculosis,opacity,parenchymalopacity,effusion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A large pleural effusion can be seen in the report in the upper-left part</td>\n",
       "      <td>tuberculosis</td>\n",
       "      <td>1.807574</td>\n",
       "      <td>tuberculosis,opacity,bronchialdilation,parenchymalopacity,effusion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>A large pleural effusion can be seen in the report in the lower-left part</td>\n",
       "      <td>tuberculosis</td>\n",
       "      <td>1.812663</td>\n",
       "      <td>tuberculosis,opacity,parenchymalopacity,effusion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>A large pleural effusion can be seen in the report in the right-sided part</td>\n",
       "      <td>tuberculosis</td>\n",
       "      <td>1.749918</td>\n",
       "      <td>tuberculosis,opacity,parenchymalopacity,effusion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>A large pleural effusion can be seen in the report in the left-sided part</td>\n",
       "      <td>tuberculosis</td>\n",
       "      <td>1.725523</td>\n",
       "      <td>tuberculosis,opacity,parenchymalopacity,effusion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>The report shows a small upper-left pleural effusion</td>\n",
       "      <td>tuberculosis</td>\n",
       "      <td>1.423523</td>\n",
       "      <td>tuberculosis,opacity,effusion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>The report shows a small lower-left pleural effusion</td>\n",
       "      <td>tuberculosis</td>\n",
       "      <td>1.397375</td>\n",
       "      <td>tuberculosis,opacity,effusion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>The report shows a small right-sided pleural effusion</td>\n",
       "      <td>tuberculosis</td>\n",
       "      <td>1.330004</td>\n",
       "      <td>tuberculosis,opacity,effusion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>The report shows a small left-sided pleural effusion</td>\n",
       "      <td>tuberculosis</td>\n",
       "      <td>1.312971</td>\n",
       "      <td>tuberculosis,opacity,effusion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>The report shows a large upper-left pleural effusion</td>\n",
       "      <td>tuberculosis</td>\n",
       "      <td>1.477113</td>\n",
       "      <td>tuberculosis,opacity,effusion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>The report shows a large lower-left pleural effusion</td>\n",
       "      <td>tuberculosis</td>\n",
       "      <td>1.450409</td>\n",
       "      <td>tuberculosis,opacity,effusion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>The report shows a large right-sided pleural effusion</td>\n",
       "      <td>tuberculosis</td>\n",
       "      <td>1.383832</td>\n",
       "      <td>tuberculosis,opacity,effusion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>The report shows a large left-sided pleural effusion</td>\n",
       "      <td>tuberculosis</td>\n",
       "      <td>1.368801</td>\n",
       "      <td>tuberculosis,opacity,effusion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>The report shows no pleural effusion</td>\n",
       "      <td>tuberculosis</td>\n",
       "      <td>-0.697367</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>The report shows no consolidation on any side</td>\n",
       "      <td>normal</td>\n",
       "      <td>-0.647226</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>There are no abnormalities in the report</td>\n",
       "      <td>normal</td>\n",
       "      <td>0.901292</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>There is severe consolidation in the left side</td>\n",
       "      <td>tuberculosis</td>\n",
       "      <td>1.943538</td>\n",
       "      <td>tuberculosis,opacity,bronchialdilation,parenchymalopacity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>There is severe consolidation in the right side</td>\n",
       "      <td>tuberculosis</td>\n",
       "      <td>1.945042</td>\n",
       "      <td>tuberculosis,opacity,bronchialdilation,parenchymalopacity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>There is mild consolidation in the right side</td>\n",
       "      <td>tuberculosis</td>\n",
       "      <td>1.707197</td>\n",
       "      <td>tuberculosis,opacity,bronchialdilation,parenchymalopacity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>There is mild consolidation in the left side</td>\n",
       "      <td>tuberculosis</td>\n",
       "      <td>1.709512</td>\n",
       "      <td>tuberculosis,opacity,bronchialdilation,parenchymalopacity</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                      Sentence    Best label  Best label score                                                      Positive label\n",
       "0    A small pleural effusion can be seen in the report in the upper-left part  tuberculosis          1.768771  tuberculosis,opacity,bronchialdilation,parenchymalopacity,effusion\n",
       "1    A small pleural effusion can be seen in the report in the lower-left part  tuberculosis          1.769983                    tuberculosis,opacity,parenchymalopacity,effusion\n",
       "2   A small pleural effusion can be seen in the report in the right-sided part  tuberculosis          1.708109                    tuberculosis,opacity,parenchymalopacity,effusion\n",
       "3    A small pleural effusion can be seen in the report in the left-sided part  tuberculosis          1.683801                    tuberculosis,opacity,parenchymalopacity,effusion\n",
       "4    A large pleural effusion can be seen in the report in the upper-left part  tuberculosis          1.807574  tuberculosis,opacity,bronchialdilation,parenchymalopacity,effusion\n",
       "5    A large pleural effusion can be seen in the report in the lower-left part  tuberculosis          1.812663                    tuberculosis,opacity,parenchymalopacity,effusion\n",
       "6   A large pleural effusion can be seen in the report in the right-sided part  tuberculosis          1.749918                    tuberculosis,opacity,parenchymalopacity,effusion\n",
       "7    A large pleural effusion can be seen in the report in the left-sided part  tuberculosis          1.725523                    tuberculosis,opacity,parenchymalopacity,effusion\n",
       "8                         The report shows a small upper-left pleural effusion  tuberculosis          1.423523                                       tuberculosis,opacity,effusion\n",
       "9                         The report shows a small lower-left pleural effusion  tuberculosis          1.397375                                       tuberculosis,opacity,effusion\n",
       "10                       The report shows a small right-sided pleural effusion  tuberculosis          1.330004                                       tuberculosis,opacity,effusion\n",
       "11                        The report shows a small left-sided pleural effusion  tuberculosis          1.312971                                       tuberculosis,opacity,effusion\n",
       "12                        The report shows a large upper-left pleural effusion  tuberculosis          1.477113                                       tuberculosis,opacity,effusion\n",
       "13                        The report shows a large lower-left pleural effusion  tuberculosis          1.450409                                       tuberculosis,opacity,effusion\n",
       "14                       The report shows a large right-sided pleural effusion  tuberculosis          1.383832                                       tuberculosis,opacity,effusion\n",
       "15                        The report shows a large left-sided pleural effusion  tuberculosis          1.368801                                       tuberculosis,opacity,effusion\n",
       "16                                        The report shows no pleural effusion  tuberculosis         -0.697367                                                                    \n",
       "17                               The report shows no consolidation on any side        normal         -0.647226                                                                    \n",
       "18                                    There are no abnormalities in the report        normal          0.901292                                                              normal\n",
       "19                              There is severe consolidation in the left side  tuberculosis          1.943538           tuberculosis,opacity,bronchialdilation,parenchymalopacity\n",
       "20                             There is severe consolidation in the right side  tuberculosis          1.945042           tuberculosis,opacity,bronchialdilation,parenchymalopacity\n",
       "21                               There is mild consolidation in the right side  tuberculosis          1.707197           tuberculosis,opacity,bronchialdilation,parenchymalopacity\n",
       "22                                There is mild consolidation in the left side  tuberculosis          1.709512           tuberculosis,opacity,bronchialdilation,parenchymalopacity"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analyse_predictions(predictions, all_sentence_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bigger reports ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset1_template = \"\"\"xr- chest pa  view\n",
    "findings\n",
    "lungs: normal.\n",
    "trachea: normal.\n",
    "carina: normal.\n",
    "right and left main bronchi: normal.\n",
    "pleura: normal.\n",
    "heart: normal.\n",
    "right heart border: normal.\n",
    "left heart border: normal.\n",
    "pulmonary bay: normal.\n",
    "pulmonary hila: normal.\n",
    "aorta: normal.\n",
    "thoracic spine: normal.\n",
    "other visualized bones: normal.\n",
    "visualized soft tissues: normal.\n",
    "diaphragm: normal.\n",
    "visualized abdomen:  normal.\n",
    "visualized neck: normal.\"\"\"\n",
    "\n",
    "dataset1_pleural_issue=\"\"\"\n",
    "xr- chest pa view\n",
    "findings\n",
    "lungs: normal.\n",
    "trachea: normal.\n",
    "carina: normal.\n",
    "right and left main bronchi: normal.\n",
    "pleura: left costophrenic angle is blunted with thin stripe of homogenous opacity along left lateral chest wall.\n",
    "heart: normal.\n",
    "right heart border: normal.\n",
    "left heart border: normal.\n",
    "pulmonary bay: normal.\n",
    "pulmonary hila: normal.\n",
    "aorta: normal.\n",
    "thoracic spine: normal.\n",
    "other visualized bones: normal.\n",
    "visualized soft tissues: normal.\n",
    "diaphragm: normal.\n",
    "visualized abdomen:  normal.\n",
    "visualized neck: normal.\"\"\"\n",
    "\n",
    "dataset2_template=\"\"\"6191206|3862169|x-ray chest pa/ap view of 09-feb-2018:\n",
    "results:\n",
    "post cabg status.\n",
    "no focal lesion seen in the lung parenchyma.\n",
    "cp angles and domes of the diaphragm are normal.\n",
    "both hila are normal. pulmonary vasculature is normal.\n",
    "cardiac size and configuration is normal.\n",
    "trachea is central; no mediastinal shift is seen.\n",
    "bony thorax and soft tissues of the chest wall are normal.\n",
    "impression: no abnormality detected in the view obtained.\n",
    "\"\"\"\n",
    "\n",
    "dataset3_template=\"\"\"\n",
    "x-ray chest (pa view)\n",
    "the cardio thoracic ratio is normal.\n",
    "the heart size and configuration are within normal limits.\n",
    "the aortic arch is normal.\n",
    "the lung fields show normal broncho-vascular markings.\n",
    "both the pulmonary hila are normal in size.\n",
    "the costophrenic and cardiophrenic recesses and the domes of\n",
    "diaphragm are normal.\n",
    "the bones and soft tissues of the chest wall show no abnormality.\n",
    "impression : normal study.\n",
    "dr.shakthi kumar\n",
    "radiologist\n",
    "ss\n",
    "________________________________________________________\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_embeddings2 = get_sentence_embeddings(radbert_multi_model, [dataset1_template, dataset1_pleural_issue, dataset2_template, dataset3_template])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.4996,  0.5371, -0.7925,  ..., -1.3068,  0.1698, -0.7473],\n",
      "        [ 0.7888, -0.7633,  0.0157,  ..., -2.0855,  0.2804, -1.2100],\n",
      "        [ 0.3844,  0.1055, -0.9388,  ..., -1.5859,  0.3282, -1.0624],\n",
      "        [ 0.4478,  0.2891, -0.8577,  ..., -1.7261,  0.2003, -1.0294]], device='cuda:1')\n",
      "torch.Size([4, 768])\n"
     ]
    }
   ],
   "source": [
    "print(all_embeddings2)\n",
    "print(all_embeddings2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.612040</td>\n",
       "      <td>0.969163</td>\n",
       "      <td>0.839009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.612040</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.612884</td>\n",
       "      <td>0.508108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.969163</td>\n",
       "      <td>0.612884</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.852399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.839009</td>\n",
       "      <td>0.508108</td>\n",
       "      <td>0.852399</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3\n",
       "0  1.000000  0.612040  0.969163  0.839009\n",
       "1  0.612040  1.000000  0.612884  0.508108\n",
       "2  0.969163  0.612884  1.000000  0.852399\n",
       "3  0.839009  0.508108  0.852399  1.000000"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_sim2 = calc_cosine_sim_matrix(all_embeddings2)\n",
    "pd.DataFrame(cosine_sim2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions2 = get_predictions(radbert_multi_model, [dataset1_template, dataset1_pleural_issue, dataset2_template, dataset3_template])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 2.1747, -4.1587, -3.8791, -4.1505, -3.3335, -4.2148, -3.4409, -2.8449, -3.6764, -3.8710, -4.1954, -4.1398, -4.2942, -4.3024, -4.2388, -3.4118, -4.1029, -4.0680, -4.3708, -3.6305, -4.1921,\n",
      "         -3.3833, -4.2908, -3.7445, -4.1937, -4.2991, -4.1057, -4.4298, -4.4533, -3.3358, -4.2838, -3.8641, -4.5122, -4.4124, -4.3368, -4.5680, -3.9125, -4.1258, -3.7593, -4.5899, -4.8654, -4.1373,\n",
      "         -4.0339, -4.6261, -4.3576, -4.6067, -4.4585, -4.9090, -4.2935, -4.3236],\n",
      "        [-2.4192,  0.6862,  0.2971, -1.0279, -3.1733, -1.1821, -2.8068, -2.4515, -2.7679, -2.5183, -3.0565, -3.2350, -3.3700, -3.3302, -3.6279, -3.0913, -2.2964, -1.8721, -1.9511, -2.4879, -2.6331,\n",
      "         -3.0002, -2.1385, -2.1943, -2.7402, -2.5382, -3.4318, -3.2625, -2.7020, -2.8953, -3.1516, -3.5908, -3.1563, -3.7074, -3.5619, -3.5425, -3.2412, -3.4141, -3.8322, -3.8570, -4.0342, -3.6987,\n",
      "         -3.6917, -3.7528, -3.4903, -4.0536, -3.6648, -4.1839, -3.6998, -3.8443],\n",
      "        [ 1.7726, -3.9808, -4.0443, -4.2974, -3.0514, -4.2380, -3.7259, -2.7263, -3.5395, -3.7027, -4.4951, -4.4255, -4.4824, -4.5904, -4.4151, -3.3157, -4.1464, -4.3070, -4.4963, -3.6353, -4.3286,\n",
      "         -3.2821, -4.3140, -3.7895, -4.1257, -4.3446, -4.2510, -4.4563, -4.4658, -3.5721, -4.2411, -3.8546, -4.5948, -4.4175, -4.4307, -4.5461, -3.9030, -4.3684, -3.8919, -4.7500, -4.9260, -4.2816,\n",
      "         -4.0524, -4.5830, -4.4627, -4.5841, -4.5012, -4.7899, -4.3322, -4.3656],\n",
      "        [-0.1567, -4.1930, -4.3617, -2.9630, -2.9492, -4.0942, -3.3268, -0.5451, -3.4113, -3.4418, -2.9641, -2.8202, -2.4788, -2.8389, -3.3292, -3.6380, -3.7818, -4.1632, -4.5805, -3.3116, -4.3303,\n",
      "         -3.2468, -4.3753, -3.7703, -3.7022, -4.3010, -3.7355, -4.0018, -4.5547, -3.7842, -3.8209, -3.4625, -4.1640, -3.8553, -4.1456, -4.2546, -3.8511, -4.0948, -3.6107, -4.3259, -4.7582, -4.0199,\n",
      "         -4.0415, -4.5254, -4.2641, -4.4797, -4.2824, -4.6159, -4.1501, -4.2692]])\n",
      "torch.Size([4, 50])\n"
     ]
    }
   ],
   "source": [
    "print(predictions2)\n",
    "print(predictions2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Best label</th>\n",
       "      <th>Best label score</th>\n",
       "      <th>Positive label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>xr- chest pa  view\\nfindings\\nlungs: normal.\\ntrachea: normal.\\ncarina: normal.\\nright and left main bronchi: normal.\\npleura: normal.\\nheart: normal.\\nright heart border: normal.\\nleft heart bord...</td>\n",
       "      <td>normal</td>\n",
       "      <td>2.174707</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\\nxr- chest pa view\\nfindings\\nlungs: normal.\\ntrachea: normal.\\ncarina: normal.\\nright and left main bronchi: normal.\\npleura: left costophrenic angle is blunted with thin stripe of homogenous op...</td>\n",
       "      <td>tuberculosis</td>\n",
       "      <td>0.686188</td>\n",
       "      <td>tuberculosis,opacity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6191206|3862169|x-ray chest pa/ap view of 09-feb-2018:\\nresults:\\npost cabg status.\\nno focal lesion seen in the lung parenchyma.\\ncp angles and domes of the diaphragm are normal.\\nboth hila are n...</td>\n",
       "      <td>normal</td>\n",
       "      <td>1.772599</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\\nx-ray chest (pa view)\\nthe cardio thoracic ratio is normal.\\nthe heart size and configuration are within normal limits.\\nthe aortic arch is normal.\\nthe lung fields show normal broncho-vascular ...</td>\n",
       "      <td>normal</td>\n",
       "      <td>-0.156686</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                  Sentence    Best label  Best label score        Positive label\n",
       "0  xr- chest pa  view\\nfindings\\nlungs: normal.\\ntrachea: normal.\\ncarina: normal.\\nright and left main bronchi: normal.\\npleura: normal.\\nheart: normal.\\nright heart border: normal.\\nleft heart bord...        normal          2.174707                normal\n",
       "1  \\nxr- chest pa view\\nfindings\\nlungs: normal.\\ntrachea: normal.\\ncarina: normal.\\nright and left main bronchi: normal.\\npleura: left costophrenic angle is blunted with thin stripe of homogenous op...  tuberculosis          0.686188  tuberculosis,opacity\n",
       "2  6191206|3862169|x-ray chest pa/ap view of 09-feb-2018:\\nresults:\\npost cabg status.\\nno focal lesion seen in the lung parenchyma.\\ncp angles and domes of the diaphragm are normal.\\nboth hila are n...        normal          1.772599                normal\n",
       "3  \\nx-ray chest (pa view)\\nthe cardio thoracic ratio is normal.\\nthe heart size and configuration are within normal limits.\\nthe aortic arch is normal.\\nthe lung fields show normal broncho-vascular ...        normal         -0.156686                      "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analyse_predictions(predictions2, [dataset1_template, dataset1_pleural_issue, dataset2_template, dataset3_template])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TutorialCuda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
